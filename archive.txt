{"data": [{"semester": "Spring", "year": "2022", "date": "2022-02-03", "speaker": "Swetasudha Panda", "website": "https://swetapanda.github.io", "title": "Addressing Biases in Pre-Trained Language Models", "affiliation": "Oracle", "sponsor": "Oracle Labs", "video": "", "abstract": "Large-scale pre-trained Language Models (LMs) have seen enormous success across many NLP tasks. However, there is evidence that these models reflect societal biases in the learned representations and the downstream applications. We find that de-biasing approaches in the contextual  embeddings space can be ineffective at the downstream task level, since biases can be re-introduced during fine-tuning. We investigate whether biases internalized by large LMs during pre-training affect downstream behavior after fine-tuning. For two classification tasks, we find that reducing representation bias with interventions before fine-tuning has little impact on task-specific predictions (after fine-tuning). In fact, downstream disparities are better explained by biases in the fine-tuning dataset. Motivated by these observations, we present a de-biasing approach based on stochastic word dropout. Our approach acts on the task-specific data during fine-tuning and it selectively attenuates contribution from words which are highly correlated with words indicative of societal biases. Our approach encourages practitioners to focus more on the task-specific dataset and the context-specific harms.", "bio": "Swetasudha (Sweta) Panda is a research scientist at the Machine Learning Research Group of Oracle Labs located in Burlington, MA. Previously, she received a Ph.D. in Computer Science from Vanderbilt University, working with Yevgeniy Vorobeychik. She graduated with B.Tech. in Electrical Engineering from Indian Institute of Technology, Kharagpur. Her research interests span fairness-aware ML and NLP, algorithms for social good, stochastic planning and computational game theory.", "area": "ML Fairness, NLP, Game Theory", "key": "SwetasudhaPanda", "prettyDate": "February 03"}, {"semester": "Spring", "year": "2022", "date": "2022-02-10", "speaker": "Varun Jampani", "website": "https://varunjampani.github.io", "title": "Practical 3D Object Understanding from Image Collections and Videos", "affiliation": "Google Research", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=7wVmUloh18g", "abstract": "Much of computer vision is understanding objects around us. In this talk, I will give an overview of our research works on understanding 3D object properties from 2D image collections and videos. Annotating several of the 3D object properties such as 3D shape, material properties, etc. is very labor-intensive and can not easily scale to large-scale datasets and new object categories. So, techniques that can estimate these object properties with minimal supervision are important for practical purposes.   In the first part of the talk, I will present an overview of our research works that can simultaneously learn object shape and material properties i.e., estimating re-lightable 3D assets from an image collection of an object that is captured under unconstrained variable lighting environments. In the second part, I will present techniques to estimate articulated 3D object shape given a single monocular video of a moving object. These works are category-agnostic and only assume a weak form of 2D supervision (object segmentations), thereby providing important steps towards practical 3D object understanding from the 2D world imagery.", "bio": "Varun Jampani is a researcher at Google Research in Cambridge, US. Prior to that, he was a researcher at NVIDIA. He works in the areas of machine learning and computer vision and his main research interests include content-adaptive neural networks, self-supervised visual discovery and novel view synthesis. He obtained his PhD with highest honors at Max Planck Institute for Intelligent Systems (MPI) and the University of T\u00fcbingen in T\u00fcbingen, Germany. He obtained his BTech and MS from the International Institute of Information Technology, Hyderabad (IIIT-H), India, where he was a gold medalist. His work on 'SplatNet' has received 'Best Paper Honorable Mention' award at CVPR'18.", "area": "Computer Vision", "key": "VarunJampani", "prettyDate": "February 10"}, {"semester": "Spring", "year": "2022", "date": "2022-02-17", "speaker": "Anjalie Field", "website": "https://www.cs.cmu.edu/~anjalief/", "title": "NLP, Ethics, and Society", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=uIjyesqBbTY&t=10s", "abstract": "While rapid advances in technology and data availability have greatly increased the practical usability of natural language processing (NLP) models, current failures to center people in NLP research has contributed to an ethical crisis: models are liable to amplify stereotypes, spread misinformation, and perpetuate discrimination. These potential harms are difficult to identify and mitigate in data and models, because they are often subjective, subtle, dependent on social context, and cannot be reduced to supervised classification tasks. In this talk, I will discuss two projects focused on developing distantly-supervised NLP models to detect and mitigate these potential harms in text. The first exposes subtle media manipulation strategies in a state-influenced Russian newspaper by comparing media coverage with economic indicators, combining algorithms for processing text and economic data with frameworks from political science. The second develops a model to identify systemic differences in social media comments addressed towards men and women by training a model to predict the gender of the addressee and incorporating propensity matching and adversarial training to surface subtle features indicative of bias. This approach allows us to identify comments likely to contain bias without needing explicit bias annotations. Overall, our work aims to develop NLP models that facilitate text processing in diverse hard-to-annotate settings, provide insights into social-oriented questions, and advance the equity and fairness of NLP systems.", "bio": "Anjalie Field is a PhD candidate at the Language Technologies Institute at Carnegie Mellon University and a visiting student at the University of Washington, where she is advised by Yulia Tsvtekov. Her work focuses on social-oriented natural language processing, specifically identifying and mitigating potential harms in text and text processing systems. This interdisciplinary work involves developing machine learning models to examine social issues like propaganda, stereotypes, and prejudice in complex real-world data sets, as well as exploring their amplification and ethical impacts in AI systems. Anjalie has published her work in NLP and interdisciplinary conferences, receiving a nomination for best paper at SocInfo 2020, and she is also the recipient of a NSF graduate research fellowship and a Google PhD fellowship. Prior to graduate school, Anjalie received her undergraduate degree in computer science, with minors in Latin and ancient Greek, from Princeton University.", "area": "NLP, AI Ethics", "key": "AnjalieField", "prettyDate": "February 17"}, {"semester": "Spring", "year": "2022", "date": "2022-02-24", "speaker": "Gautam Kamath", "website": "http://www.gautamkamath.com/", "title": "Differentially Private Fine-tuning of Language Models", "affiliation": "University of Waterloo", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=-O51glX48QM&t=85s", "abstract": "We give simpler, sparser, and faster algorithms for differentially private fine-tuning of large-scale pre-trained language models, which achieve the state-of-the-art privacy versus utility tradeoffs on many standard NLP tasks. We propose a meta-framework for this problem, inspired by the recent success of highly parameter-efficient methods for fine-tuning. Our experiments show that differentially private adaptations of these approaches outperform previous private algorithms in three important dimensions: utility, privacy, and the computational and memory cost of private training. On many commonly studied datasets, the utility of private models approaches that of non-private models. For example, on the MNLI dataset we achieve an accuracy of 87.8% using RoBERTa-Large and 83.5% using RoBERTa-Base with a privacy budget of \u03f5=6.7. In comparison, absent privacy constraints, RoBERTa-Large achieves an accuracy of 90.2%. Our findings are similar for natural language generation tasks. Privately fine-tuning with DART, GPT-2-Small, GPT-2-Medium, GPT-2-Large, and GPT-2-XL achieve BLEU scores of 38.5, 42.0, 43.1, and 43.8 respectively (privacy budget of \u03f5=6.8,\u03b4= 1e-5) whereas the non-private baseline is 48.1. All our experiments suggest that larger models are better suited for private fine-tuning: while they are well known to achieve superior accuracy non-privately, we find that they also better maintain their accuracy when privacy is introduced.   No knowledge of differential privacy will be assumed. Based on joint work with Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Huseyin A. Inan, Janardhan Kulkarni, Yin Tat Lee, Andre Manoel, Lukas Wutschitz, Sergey Yekhanin, and Huishuai Zhang. Paper to appear in ICLR 2022, and available on arXiv (https://arxiv.org/abs/2110.06500).", "bio": "Gautam Kamath is an Assistant Professor at the David R. Cheriton School of Computer Science at the University of Waterloo, and a faculty affiliate at the Vector Institute. He has a B.S. in Computer Science and Electrical and Computer Engineering from Cornell University, and an M.S. and Ph.D. in Computer Science from the Massachusetts Institute of Technology. His research interests lie in methods for statistics and machine learning, with a focus on challenges related to trustworthy machine learning, including data privacy and robustness. He was a Microsoft Research Fellow, as a part of the Simons-Berkeley Research Fellowship Program at the Simons Institute for the Theory of Computing. He is recipient of an NSERC Discovery Accelerator Supplement, and was awarded the Best Student Presentation Award at the ACM Symposium on Theory of Computing in 2012.", "area": "Privacy, ML Security, ML Theory", "key": "GautamKamath", "prettyDate": "February 24"}, {"semester": "Spring", "year": "2022", "date": "2022-03-03", "speaker": "Colin Raffel", "website": "https://colinraffel.com/", "title": "A call to build models like we build open-source software", "affiliation": "UNC Chapel Hill", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=ksSrScLNnIs&t=57s", "abstract": "Large pre-trained models have become a cornerstone of modern ML pipelines thanks to the fact that they facilitate improved performance with less labeled data on downstream tasks. However, these models are typically created by a resource-rich research group that unilaterally decides how a given model should be built, trained, and released, after which point it is left as-is until a better pre-trained model comes along to completely supplant it. In contrast, open-source development has proven that it is possible for a distributed community of contributors to work together to iteratively build complex and widely-used software. This kind of large-scale distributed collaboration is made possible through a mature set of tools including version control, continuous integration, merging, and more. In this talk, I will present a vision for building machine learning models in the way that open-source software is developed, including preliminary work from my lab on \"merging\" and \"patching\" models. I will also give some insight into the future work required to make this vision a reality.", "bio": "Colin Raffel is an assistant professor at UNC Chapel Hill. He also spends one day a week as a faculty researcher at Hugging Face.", "area": "NLP, Machine Learning", "key": "ColinRaffel", "prettyDate": "March 03"}, {"semester": "Spring", "year": "2022", "date": "2022-03-10", "speaker": "Marine Carpuat", "website": "http://www.cs.umd.edu/~marine/", "title": "Toward Human-Centered Machine Translation", "affiliation": "UMD College Park", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=bXflHC4dFNw", "abstract": "In this talk, I will describe current research directions in my group that revisit the steps of the Machine Translation (MT) research and development lifecycle to design systems that help people communicate across language barriers. These range from methods to better characterize the degree of parallelism in the data that powers MT systems, new models such as a non-autoregressive Transformer that enable flexible conditional language generation, and new framings of machine translation tasks and evaluation to center human factors.", "bio": "Marine Carpuat is an Associate Professor in Computer Science at the University of Maryland. Her research focuses on multilingual natural language processing and machine translation. Before joining the faculty at Maryland, she was a Research Scientist at the National Research Council Canada. She received a PhD in Computer Science and a MPhil in Electrical Engineering from the Hong Kong University of Science & Technology, and a Diplome d'Ingenieur from the French Grande Ecole Supelec. She is the recipient of an NSF CAREER award, research awards from Google and Amazon, best paper awards at *SEM and TALN, and an Outstanding Teaching Award.", "area": "NLP", "key": "MarineCarpuat", "prettyDate": "March 10"}, {"semester": "Spring", "year": "2022", "date": "2022-03-24", "speaker": "Despoina Paschalidou", "website": "https://paschalidoud.github.io/", "title": "Learning Compositional Representations for Understanding and Generating 3D Environments with Minimal Supervision and Maximum Controllability", "affiliation": "MPI / ETH Zurich", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=mf1N016UzLs", "abstract": "Within the first year of our life, we develop a common-sense understanding of the physical behavior of the world, which relies heavily on our ability to properly reason about the arrangement of objects in a scene. While this seems to be a fairly easy task for the human brain, computer vision algorithms struggle to form such high-level reasoning. Therefore, the research community shifted their attention to the development of primitive-based methods that seek to represent objects as semantically consistent part arrangements. However, due to the simplicity of existing primitive representations, these methods fail to accurately reconstruct 3D shapes using a small number of primitives/parts.   In the first part of my talk, I will address the trade-off between reconstruction quality and number of parts and present Neural Parts, a novel 3D primitive representation that defines primitives using an Invertible Neural Network (INN) which implements homeomorphic mappings between a sphere and the target object. Since a homeomorphism does not impose any constraints on the primitive shape, our model effectively decouples geometric accuracy from parsimony and as a result captures complex geometries with an order of magnitude fewer primitives. In the second part of my talk, we will look into the problem of inferring and subsequently also generating semantically meaningful object arrangements to populate 3D scenes conditioned on the room shape. In particular, I will present ATISS, a novel autoregressive transformer architecture for creating diverse and plausible synthetic indoor environments as unordered sets of objects. Our unordered set formulation allows us to use the same trained model for a variety of interactive applications such general scene completion, partial room rearrangement with any objects specified by the user, as well as object suggestions for any partial room. This is an important step towards fully automatic content creation.", "bio": "Despoina Paschalidou is a PostDoc at Stanford University working with Prof. Leo Guibas at the Geometric Computation Group. Prior to this, she did her PhD at the Max Planck Institute for Intelligent Systems in Tubingen and the Computer Vision Lab in ETH Zurich, under the guidance of Prof. Andreas Geiger and Prof. Luc van Gool. She received her Diploma in Electrical and Computer Engineering from the Aristotle University of Thessaloniki, in 2015. Her research interests revolve around semantic and interpretable representations of 3D objects and scenes. She spent 1 year working with Prof. Sanja Fidler at NVIDIA Research on developing interactive tools for content creation. Moreover, she spent 6 months at FAIR working with Prof. Andrea Vedaldi and David Novotny on unsupervised 3D reconstruction from video data.", "area": "Computer Vision", "key": "DespoinaPaschalidou", "prettyDate": "March 24"}, {"semester": "Spring", "year": "2022", "date": "2022-04-01", "speaker": "Vinodkumar Prabhakaran", "website": "https://www.cs.stanford.edu/~vinod/", "title": "NLP and Society: Undesirable Societal Biases as Barriers to Those in the Margins", "affiliation": "Google Research", "sponsor": "Oracle Labs", "video": "", "abstract": "As natural language processing (NLP) techniques are increasingly being used in various day-to-day applications, there is growing awareness that the decisions we as researchers and developers make about our data, methods, and algorithms have immense impact in shaping our social lives. In this talk, I will outline a growing body of research on ethical implications of NLP technologies, especially around fairness failures along various axes. I will discuss ways in which machine learned NLP models may reflect, propagate, and sometimes amplify social stereotypes about people, potentially harming already marginalized groups. I will cover research from our team at Google, as well as the larger research community on ways to detect and address these issues, and discuss the open challenges in this space.", "bio": "Vinodkumar Prabhakaran is a Senior Research Scientist at Google working on issues around ethics, fairness and transparency in machine learning and natural language processing. Prior to Google, he was a postdoctoral researcher at Stanford University, and obtained his PhD in computer science from Columbia University. His prior research focused on building scalable ways using NLP to identify and address large-scale societal issues such as racial disparities in policing, workplace incivility, and online abuse. He has published over 40 articles in top-tier venues such as the PNAS, ACL, TACL, NAACL, EMNLP, and FAccT.", "area": "NLP, AI Ethics", "key": "VinodkumarPrabhakaran", "prettyDate": "April 01"}, {"semester": "Spring", "year": "2022", "date": "2022-04-07", "speaker": "Gauri Joshi", "website": "https://www.andrew.cmu.edu/user/gaurij/", "title": "Tackling Computational Heterogeneity in Federated Learning", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=dnBTsp5Mxl4&t=13s", "abstract": "The future of machine learning lies in moving both data collection as well as model training to the edge. The emerging area of federated learning seeks to achieve this goal by orchestrating distributed model training using a large number of resource-constrained mobile devices that collect data from their environment. Due to limited communication capabilities as well as privacy concerns, the data collected by these devices cannot be sent to the cloud for centralized processing. Instead, the nodes perform local training updates and only send the resulting model to the cloud. A key aspect that sets federated learning apart from data-center-based distributed training is the inherent heterogeneity in data and local computation at the edge clients. In this talk, I will present our recent work on tackling computational heterogeneity in federated optimization, firstly in terms of heterogeneous local updates made by the edge clients, and secondly in terms of intermittent client availability.", "bio": "Gauri Joshi is an assistant professor in the ECE department at Carnegie Mellon University since September 2017. Previously, she worked as a Research Staff Member at IBM T. J. Watson Research Center. Gauri completed her Ph.D. from MIT EECS in June 2016, advised by Prof. Gregory Wornell. She received her B.Tech and M.Tech in Electrical Engineering from the Indian Institute of Technology (IIT) Bombay in 2010. Her awards and honors include the NSF CAREER Award (2021), ACM Sigmetrics Best Paper Award (2020), NSF CRII Award (2018), IBM Faculty Research Award (2017), Best Thesis Prize in Computer science at MIT (2012), and Institute Gold Medal of IIT Bombay (2010).", "area": "Distributed ML, Parallel Computing, Federated Learning", "key": "GauriJoshi", "prettyDate": "April 07"}, {"semester": "Spring", "year": "2022", "date": "2022-04-14", "speaker": "Andrea Tagliasacchi", "website": "https://taiya.github.io/", "title": "Neural fields beyond novel view synthesis", "affiliation": "Google Research / Simon Fraser", "sponsor": "Oracle Labs", "video": "", "abstract": "Neural 3D representations have unlocked the potential to achieve 3D perception solely from 2D supervision. Yet target problem space is relatively restricted: we assume images to be equipped with near-perfect camera poses, rather than generalizing we generally overfit to a single-scene, and we evaluate results mostly from a novel-view synthesis perspective, generally ignoring how to integrate other sources of informations (e.g. user annotations and/or other 3D sensing mechanisms). In this talk I will discuss how we address these shortcomings in recently published work (links below), in particular with applications to faces and environments.", "bio": "Andrea Tagliasacchi is a staff research scientist at Google Brain and an adjunct faculty in the computer science department at the University of Toronto. Starting August 2022, he will join Simon Fraser University (SFU) as an Associate Professor and Visual Visual Computing Research Chair. His research focuses on 3D perception, which lies at the intersection of computer vision, computer graphics and machine learning. In 2018, he was invited to join Google Daydream as a visiting faculty and eventually joined Google full time in 2019. Before joining Google, he was an assistant professor at the University of Victoria (2015-2017), where he held the Industrial Research Chair in 3D Sensing. His alma mater include EPFL (postdoc) SFU (PhD, NSERC Alexander Graham Bell fellow) and Politecnico di Milano (MSc, gold medalist). His research has won several awards including the CVPR 2021 best student paper award, and the SGP 2015 best paper award.", "area": "Computer Vision", "key": "AndreaTagliasacchi", "prettyDate": "April 14"}, {"semester": "Spring", "year": "2022", "date": "2022-04-21", "speaker": "Georgios Pavlakos", "website": "https://geopavlakos.github.io/", "title": "Reconstructing and Tracking 3D Humans from Video", "affiliation": "UC Berkeley", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=yW2W6nMvE-I", "abstract": "The majority of the visual content we capture and have access to focuses on humans. In order to build AI systems that can understand and learn from this content, it is crucial to enable perception of humans from these visual observations. Despite the advances of 2D perception, we ultimately want our systems to also allow for the 3D perception of humans.  In this talk, I will present our recent works on automatic perception of 3D humans from images and videos. First, I will explore the use of large scale movie sequences to train systems for 3D human reconstruction. Despite the rich nature of movie data (i.e., large variety of behaviors and interactions, long range video), the fragmentation of movies in \"shots\" can complicate their analysis. Instead of treating this fragmentation as noise, I will describe how we leverage this multi-shot continuity as supervisory signal for 3D reconstruction. Then, I will discuss our recent work that uses the resulting 3D human reconstruction models to lift people to 3D and then track them over video sequences. I will identify the importance of extracting rich 3D human representations and highlight the benefits over traditional tracking on the 2D image plane.", "bio": "Georgios Pavlakos is a Postdoctoral Researcher at UC Berkeley, advised by Angjoo Kanazawa and Jitendra Malik. His research interests include computer vision, machine learning, and robotics. He completed his PhD in Computer Science at the University of Pennsylvania with his advisor, Kostas Daniilidis. He has spent time at Max Planck Institute with Michael Black and at Facebook Reality Labs. His PhD dissertation received the Morris and Dorothy Rubinoff Award for the Best Computer Science Dissertation at UPenn.", "area": "Computer Vision", "key": "GeorgiosPavlakos", "prettyDate": "April 21"}, {"semester": "Fall", "year": "2021", "date": "2021-09-16", "speaker": "Trapit Bansal", "website": "https://trapitbansal.com", "title": "Few-Shot Natural Language Processing via Self-Supervised Meta-Learning", "affiliation": "UMass", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=Ek0-boGpg5E", "abstract": "Humans show a remarkable capability to accurately solve a wide range of problems efficiently -- utilizing a limited amount of computation and experience. Deep learning models, by stark contrast, can be trained to be highly accurate on a narrow task while being highly inefficient in terms of the amount of compute and data required to reach that accuracy. Few-shot learning considers this problem of learning models that generalize to new tasks with very little supervision. Natural language processing (NLP) has seen recent breakthroughs with unsupervised pre-training of large models that can be applied to many NLP tasks, however, few-shot learning of new tasks is still inefficient. In this talk, I will present a sequence of work on meta-learning for improving few-shot learning of NLP tasks. Meta-learning, or learning to learn, treats the learning process itself as a learning problem from data, to learn systems that can generalize to new tasks efficiently. However, meta-learning requires a distribution over tasks with relevant labeled data that can be difficult to obtain, severely limiting the practical utility of meta-learning methods. I will present solutions that construct task distributions from unlabeled text data to enable large-scale meta-learning. The resulting self-supervised meta-learning methods optimize the pre-training directly for future fine-tuning with few examples, which leads to improved few-shot learning of new tasks. By providing useful training tasks for meta-learning, these approaches help lift a pertinent bottleneck for training meta-learning methods and should enable many future applications of meta-learning in NLP, such as hyper-parameter optimization, continual learning, neural architecture search, and more.", "bio": "Trapit is a Ph.D. student advised by Prof. Andrew McCallum at UMass Amherst. His recent research focuses on improving the generalization of natural language processing models with limited human-labeled data through meta-learning, self-supervised learning, and multi-task learning. In the past, he has also worked on machine learning methods for recommendation systems, information extraction, knowledge representation, and reinforcement learning for multi-agent systems. During his Ph.D., he has interned at Facebook, OpenAI, Google Research, and Microsoft Research. His work has also received a best paper award at ICLR 2018. Before starting his Ph.D., he obtained a B.S. and M.S. in Mathematics from the Indian Institute of Technology, Kanpur.", "area": "Meta-learning", "key": "TrapitBansal", "prettyDate": "September 16"}, {"semester": "Fall", "year": "2021", "date": "2021-09-23", "speaker": "Antonio Khalil Moretti", "website": "http://www.cs.columbia.edu/~amoretti/", "title": "Variational Combinatorial Sequential Monte Carlo Methods for Bayesian Phylogenetic Inference", "affiliation": "Columbia University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=eV3IXFAp1Qg ", "abstract": "Bayesian phylogenetic inference is often conducted via local or sequential search over topologies and branch lengths using algorithms such as random-walk Markov chain Monte Carlo (MCMC) or Combinatorial Sequential Monte Carlo (CSMC). However, when MCMC is used for evolutionary parameter learning, convergence requires long runs with inefficient exploration of the state space. We introduce Variational Combinatorial Sequential Monte Carlo (VCSMC), a powerful framework that establishes variational sequential search to learn distributions over intricate combinatorial structures. We then develop nested CSMC, an efficient proposal distribution for CSMC and prove that nested CSMC is an exact approximation to the (intractable) locally optimal proposal. We use nested CSMC to define a second objective, VNCSMC which yields tighter lower bounds than VCSMC. We show that VCSMC and VNCSMC are computationally efficient and explore higher probability spaces than existing methods on a range of tasks.", "bio": "Antonio is currently a senior data scientist on the search algorithm team at Walmart Labs using machine learning to improve customer experience. Antonio recently completed a PhD in the Computer Science Department at Columbia University in the lab of Itsik Pe'er. He has developed a number of variational Bayesian inference methods for open problems in computational biology. At the heart of these questions has been a curiosity about how information is naturally encoded or represented in living systems, through neuronal firing activity or through the molecular sequences comprising the genome. To address these questions, his research has focused on the development of expressive statistical methodologies along with tractable inference algorithms for fast approximate inference on structured sequential data.", "area": "Bayesian Inference, Computational Biology", "key": "AntonioKhalilMoretti", "prettyDate": "September 23"}, {"semester": "Fall", "year": "2021", "date": "2021-09-30", "speaker": "Jean Honorio", "website": "https://www.cs.purdue.edu/homes/jhonorio/", "title": "Fair Sparse Regression with Clustering: An Invex Relaxation for a Combinatorial Problem", "affiliation": "Purdue ", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=6wiJQ8zX0K4", "abstract": "We study the problem of fair sparse regression on a biased dataset where bias depends upon a hidden binary attribute. The presence of a hidden attribute adds an extra layer of complexity to the problem by combining sparse regression and clustering with unknown binary labels. The corresponding optimization problem is combinatorial but we propose a continuous relaxation, resulting in an invex optimization problem. To the best of our knowledge, this is the first invex relaxation for a combinatorial problem. We show that our method recovers the correct support of the regression parameter vector, as well as the exact value of the hidden attribute for each sample. The above theoretical guarantees hold as long as the number of samples is logarithmic in terms of the dimension of the regression parameter vector.  The result above serves as a gentle introduction to a unifying framework, which uses the power of continuous relaxations (beyond convexity), Karush-Kuhn-Tucker conditions, primal-dual certificates and concentration inequalities. This framework has allowed us to produce novel algorithms for several NP-hard combinatorial problems, such as learning Bayesian networks, graphical games, inference in structured prediction, and community detection.", "bio": "Jean Honorio is an Assistant Professor in the Computer Science Department at Purdue University, as well as in the Statistics Department (by courtesy). Prior to joining Purdue, Jean was a postdoctoral associate at MIT, working with Tommi Jaakkola. His Erd\u0151s number is 3. His work has been partially funded by NSF. He is an editorial board reviewer of JMLR, and has served as area chair of NeurIPS, senior PC member of IJCAI and AAAI, PC member of NeurIPS, ICML, AISTATS among other conferences and journals.", "area": "Combinatorial Learning and Inference", "key": "JeanHonorio", "prettyDate": "September 30"}, {"semester": "Fall", "year": "2021", "date": "2021-10-07", "speaker": "Rose Yu", "website": "https://roseyu.com", "title": "Towards Generalizable Deep Dynamics Learning ", "affiliation": "UC San Diego", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=TPziJOJ3r1E", "abstract": "Deep learning holds great promise in accelerating the prediction of physical dynamics relative to numerical solvers. However, current deep learning models for dynamics forecasting struggle with generalization. They only work in a specific domain and fail when applied to systems with different parameters, external forces, or boundary conditions. In this talk, I will demonstrate our efforts in improving the generalization of deep learning for forecasting physical dynamics. I will introduce (1) Equivariant-Net: a model that is inherently equivariant to groups of symmetries and thus generalizes automatically across groups. (2) DyAd: a model-based meta-learning method which can generalize across heterogeneous domains with latent task inference. I will showcase the advantage of our approaches on forecasting Rayleigh B\u00e9nard convection, real-world ocean currents, and temperatures.", "bio": "Dr. Rose Yu is an assistant professor at the University of California San Diego, Department of Computer Science and Engineering. She was a Postdoctoral Fellow at the California Institute of Technology.  Her research focuses on advancing machine learning techniques for large-scale spatiotemporal data analysis, with applications to sustainability, health, and physical sciences. A particular emphasis of her research is on physics-guided AI which aims to integrate first-principles with data-driven models. Among her awards, she has won Faculty Research Award from Facebook, Google, Amazon, and Adobe, Several Best Paper Awards, Best Dissertation Award in USC, and was nominated as one of the \u2019MIT Rising Stars in EECS\u2019. ", "area": "Deep learning, optimization, spatiotemporal reasoning", "key": "RoseYu", "prettyDate": "October 07"}, {"semester": "Fall", "year": "2021", "date": "2021-10-14", "speaker": "Zhou Yu", "website": "http://www.cs.columbia.edu/~zhouyu/", "title": "Building dialog systems with fewer data and less supervision", "affiliation": "Columbia University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=dFWkyhQNSuc", "abstract": "Neural network-based models have shown good performance on various NLP tasks. However, they require a lot of data to train. Thus, how to train dialog models with fewer data and less supervision is a practical problem. This talk will introduce some work that utilizes meta-learning, semi-supervised learning, and zero-shot learning algorithms for task-oriented dialog system training.", "bio": "Zhou Yu joined the CS department at Columbia University in Jan 2021 as an Assistant Professor (http://www.cs.columbia.edu/~zhouyu/). Before that, she was an Assistant Professor at UC Davis. She obtained her Ph.D. from Carnegie Mellon University in 2017.  Zhou has built various dialog systems that have a real impact, such as a job interview training system, a depression screening system, and a second language learning system. Her research interest includes dialog systems, language understanding and generation, vision and language, human-computer interaction, and social robots. Zhou received an ACL 2019 best paper nomination, featured in Forbes 2018 30 under 30 in Science, and won the 2018 Amazon Alexa Prize.", "area": "NLP", "key": "ZhouYu", "prettyDate": "October 14"}, {"semester": "Fall", "year": "2021", "date": "2021-10-21", "speaker": "Ji Hou", "website": "https://sekunde.github.io", "title": "Color and Geometry Learning in 3D Scene Understanding", "affiliation": "TUM", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=mGWBJIV7CQ0", "abstract": "3D Scene Understanding aims to better understand our 3D environments/surroundings. Tasks, such as 3D detection, semantic segmentation and instance segmentation, enable a variety of important computer vision applications, such as autonomous robotics and VR/AR. Primarily, geometry signals are widely used in scene understanding tasks, such as TSDF or point cloud. The backbones like PointNet/PointNet++ and SparseConvNet are invented to extract network representations/features from voxels and points. To better use RGB-D Data for scene understanding tasks, such as ScanNet, where both RGB and depth images are provided, our research tries to find better ways of jointly learning from color and geometry in scene understanding. In this talk, I will present our work on how to jointly learn color and geometry features in specific downstream tasks, such as instance segmentation and completion, as well as for better representation learning, such as leveraging 3D priors for 2D scene understanding tasks.", "bio": "Mr. Hou is currently a Ph.D. Candidate in Technical University of Munich with Prof. Matthias Niessner. He was a research intern at Facebook AI Research (FAIR). His research focuses on 3D Scene Understanding in terms of specific tasks, such as 3D detection or instance segmentation as well as 3D Transfer Learning, including data-efficient learning, and 3D priors for 2D tasks. He has published his research works on top-tier computer vision and machine learning conferences, such as CVPR/ICCV/NeurIPS and served as reviewers of top-tier journals, such as TPAMI and IJCV.", "area": "Vision", "key": "JiHou", "prettyDate": "October 21"}, {"semester": "Fall", "year": "2021", "date": "2021-11-04", "speaker": "Kaichun Mo", "website": "https://cs.stanford.edu/~kaichun/", "title": "Learning 3D Shape Structure and Semantics", "affiliation": "Stanford University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=Z3V60LPPTxo&t=15s", "abstract": "Humans accomplish everyday tasks by perceiving, modeling, and interacting with a wide range of 3D objects, with diverse geometry, rich semantics, and complicated structures. One fundamental goal of computational visual perception is to equip intelligent agents with similar capabilities to understand the 3D world. In this talk, I will introduce my research on learning complicated structures and actionable semantics of 3D shapes, which can benefit various downstream applications in computer graphics, vision, and robotics, including shape part segmentation, shape generation, shape editing, robotic part assembly, and robotic manipulation.", "bio": "Kaichun Mo is a sixth-year and final-year Ph.D. Student in Computer Science at Stanford University, advised by Prof. Leonidas Guibas. Before that, he received his BS.E. degree from the ACM Honored Class at Shanghai Jiao Tong University. His research interests focus on understanding 3D shape structure and semantics for various applications in 3D vision, graphics, and robotic manipulation. He has interned at Adobe Research, Autodesk Research (AI Lab), and Facebook AI Research. He has published papers at CVPR, ICCV, ECCV, NeurIPS, ICLR, Siggraph Asia, AAAI, CoRL. His webpage: https://cs.stanford.edu/~kaichun", "area": "VIsion", "key": "KaichunMo", "prettyDate": "November 04"}, {"semester": "Fall", "year": "2021", "date": "2021-12-02", "speaker": "Jonathan Spencer", "website": "https://jspencer12.github.io", "title": "Learning from Humans: Enabling a Scalable and Efficient Future of Robotics", "affiliation": "Princeton University", "sponsor": "Oracle Labs", "video": "", "abstract": "Humans have deep expertise on an incredible array of skill sets. Increasingly robots are being trained to assist in performing some of these tasks, however robot learning is often limited in two major ways. First, increasingly complex tasks limit the human\u2019s ability to explicitly define task success. Second, modern methods of learning by imitation require a prohibitively large number of samples. We show how new methods of learning from interventions can overcome these hurdles and unlock flexible methods for learning from all types of human interaction.", "bio": "Jonathan Spencer is a final year PhD candidate at Princeton University. He is especially interested in techniques for learning from humans and modeling human behavior and his work focuses on imitation learning and robotics. He is very passionate about the potential that robotics and autonomous driving have to save lives and serve the elderly and other communities with less access to transportation. Jonathan is an avid runner, cyclist, and baker, and hopes that one day robots will finally take over the world so he can do more running, biking, and baking.", "area": "Imitiation learning", "key": "JonathanSpencer", "prettyDate": "December 02"}, {"semester": "Spring", "year": "2021", "date": "2021-02-11", "speaker": "Tamara Broderick", "website": "https://people.csail.mit.edu/tbroderick/", "title": "An Automatic Finite-Sample Robustness Metric: Can Dropping a Little Data Change Conclusions?", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=w8OX0lK1CKo", "abstract": "We propose a method to assess the sensitivity of data analyses to the removal of a small fraction of the data set. Analyzing all possible data subsets of a certain size is computationally prohibitive, so we provide a finite-data metric to approximately compute the number (or fraction) of observations that has the greatest influence on a given result when dropped. We call our resulting metric the Approximate Maximum Influence Perturbation. Our approximation is automatically computable and works for common estimators (including OLS, IV, GMM, MLE, and variational Bayes). We provide explicit finite-sample error bounds on our approximation for linear and instrumental variables regressions. At minimal computational cost, our metric provides an exact finite-sample lower bound on sensitivity for any estimator, so any non-robustness our metric finds is conclusive. We demonstrate that the Approximate Maximum Influence Perturbation is driven by the signal-to-noise ratio in the inference problem, is not reflected in standard errors, does not disappear asymptotically, and is not a product of misspecification. We focus on econometric analyses in our applications. Several empirical applications show that even 2-parameter linear regression analyses of randomized trials can be highly sensitive. While we find some applications are robust, in others the sign of a treatment effect can be changed by dropping less than 1% of the sample even when standard errors are small.", "bio": "Tamara Broderick is an Associate Professor in the Department of Electrical Engineering and Computer Science at MIT. She is a member of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL), the MIT Statistics and Data Science Center, and the Institute for Data, Systems, and Society (IDSS). She completed her Ph.D. in Statistics at the University of California, Berkeley in 2014. Previously, she received an AB in Mathematics from Princeton University (2007), a Master of Advanced Study for completion of Part III of the Mathematical Tripos from the University of Cambridge (2008), an MPhil by research in Physics from the University of Cambridge (2009), and an MS in Computer Science from the University of California, Berkeley (2013). Her recent research has focused on developing and analyzing models for scalable Bayesian machine learning. She has been awarded an Early Career Grant (ECG) from the Office of Naval Research (2020), an AISTATS Notable Paper Award (2019), an NSF CAREER Award (2018), a Sloan Research Fellowship (2018), an Army Research Office Young Investigator Program (YIP) award (2017), Google Faculty Research Awards, an Amazon Research Award, the ISBA Lifetime Members Junior Researcher Award, the Savage Award (for an outstanding doctoral dissertation in Bayesian theory and methods), the Evelyn Fix Memorial Medal and Citation (for the Ph.D. student on the Berkeley campus showing the greatest promise in statistical research), the Berkeley Fellowship, an NSF Graduate Research Fellowship, a Marshall Scholarship, and the Phi Beta Kappa Prize (for the graduating Princeton senior with the highest academic average).", "area": "ML Theory", "key": "TamaraBroderick", "prettyDate": "February 11"}, {"semester": "Spring", "year": "2021", "date": "2021-02-18", "speaker": "Vered Shwartz", "website": "https://vered1986.github.io/", "title": "Commonsense Knowledge and Reasoning in Natural Language", "affiliation": "AI2", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=0RGhK8_uQWo", "abstract": "Natural language understanding models are trained on a sample of the real-world situations they may encounter. Commonsense and world knowledge, language, and reasoning skills can help them address unknown situations sensibly.\u00a0 In this talk I will present two lines of work addressing commonsense knowledge and reasoning in natural language. I will first present a method for discovering relevant knowledge which is unstated but may be required for solving a particular problem, e.g., to correctly resolve \"Children need to eat more vegetables because they [children / vegetables] are healthy\" one needs to know that \"vegetables are healthy\". Such knowledge is discovered through a process of asking information seeking clarification questions (e.g. \"what is the purpose of vegetables?\") and answering them (\"to provide nutrients\"). I will then discuss nonmonotonic reasoning in natural language, a core human reasoning ability that has been studied in classical AI but mostly overlooked in modern NLP. I will talk about several recent papers addressing abductive reasoning (reasoning about plausible explanations), counterfactual reasoning (what if?) and defeasible reasoning (updating beliefs given additional information). Finally, I will discuss open problems in language, knowledge, and reasoning. ", "bio": "Vered Shwartz is a postdoctoral researcher at the Allen Institute for AI (AI2) and the Paul G. Allen School of Computer Science & Engineering at the University of Washington. Previously, she completed her PhD in Computer Science from Bar-Ilan University, under the supervision of Prof. Ido Dagan. Her research interests include commonsense reasoning, lexical and compositional semantics.", "area": "NLP", "key": "VeredShwartz", "prettyDate": "February 18"}, {"semester": "Spring", "year": "2021", "date": "2021-02-25", "speaker": "Samory Kpotufe", "website": "http://www.columbia.edu/~skk2175/", "title": "Some Recent Insights on Transfer-Learning", "affiliation": "Columbia University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=1kpHC9HZXVQ", "abstract": "A common situation in Machine Learning is one where training data is not fully representative of a target population due to bias in the sampling mechanism or due to prohibitive target sampling costs. In such situations, we aim to \u2019transfer\u2019 relevant information from the training data (a.k.a. source data) to the target application. How much information is in the source data about the target application? Would some amount of target data improve transfer? These are all practical questions that depend crucially on 'how far' the source domain is from the target. However, how to properly measure 'distance' between source and target domains remains largely unclear.  In this talk we will argue that much of the traditional notions of 'distance' (e.g. KL-divergence, extensions of TV such as D_A discrepancy, density-ratios, Wasserstein distance) can yield an over-pessimistic picture of transferability. Instead, we show that some new notions of 'relative dimension' between source and target (which we simply term 'transfer-exponents') capture a continuum from easy to hard transfer. Transfer-exponents uncover a rich set of situations where transfer is possible even at fast rates; they encode relative benefits of source and target samples, and have interesting implications for related problems such as 'multi-task or multi-source learning'. In particular, in the case of transfer from multiple sources, we will discuss (if time permits) a strong dichotomy between minimax and adaptive rates: no adaptive procedure exists that can achieve the same rates as minimax (oracle) procedures.\u00a0 The talk is based on earlier work with Guillaume Martinet, and ongoing work with Steve Hanneke.", "bio": "I graduated (Sept 2010) in Computer Science at the University of California, San Diego, advised by Sanjoy Dasgupta. I then was a researcher at the Max Planck Institute for Intelligent Systems. At the MPI I worked in the department of Bernhard Schoelkopf, in the learning theory group of Ulrike von Luxburg. Following this, I spent a couple years as an Assistant Research Professor at the Toyota Technological Institute at Chicago. I then spent 4 years at ORFE, Princeton University as an Assistant Professor. Recently I was a visiting member at the Institute of Advanced Study from January to July 2020.", "area": "ML Theory", "key": "SamoryKpotufe", "prettyDate": "February 25"}, {"semester": "Spring", "year": "2021", "date": "2021-03-04", "speaker": "Nima Hamidi", "website": "http://stanford.edu/~hamidi/", "title": "On Worst-case Regret of Linear Thompson Sampling", "affiliation": "Stanford University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=VAET8L9mRZU", "abstract": "In this paper, we consider the worst-case regret of Linear Thompson Sampling (LinTS) for the linear bandit problem. Russo and Van Roy (2014) show that the Bayesian regret of LinTS is bounded above by $\\widetilde{\\mathcal{O}}(d\\sqrt{T})$ where $T$ is the time horizon and $d$ is the number of parameters. While this bound matches the minimax lower-bounds for this problem up to logarithmic factors, the existence of a similar worst-case regret bound is still unknown. The only known worst-case regret bound for LinTS, due to Agrawal and Goyal (2013b); Abeille et al. (2017), is $\\widetilde{\\mathcal{O}}(d\\sqrt{dT})$ which requires the posterior variance to be inflated by a factor of $\\widetilde{\\mathcal{O}}(\\sqrt{d})$. While this bound is far from the minimax optimal rate by a factor of $\\sqrt{d}$, in this paper we show that it is the best possible one can get, settling an open problem stated in Russo et al. (2018). Specifically, we construct examples to show that, without the inflation, LinTS can incur linear regret up to time $\\exp(\\mathcal{O}(d))$. We then demonstrate that, under mild conditions, a slightly modified version of LinTS requires only an $\\widetilde{\\mathcal{O}}(1)$ inflation where the constant depends on the diversity of the optimal arm.", "bio": "Nima Hamidi is a sixth year Ph.D. student in the Stanford Department of Statistics. He received a B.Sc. degree in Software Engineering and Pure Mathematics and a M.Sc. degree in Pure Mathematics from Sharif University. His research interests include multi-armed bandit experiments and low-rank matrix estimation.", "area": "ML Theory", "key": "NimaHamidi", "prettyDate": "March 04"}, {"semester": "Spring", "year": "2021", "date": "2021-03-11", "speaker": "Marinka Zitnik", "website": "https://dbmi.hms.harvard.edu/people/marinka-zitnik", "title": "Advances in graph neural networks and their applications to the development of therapeutics", "affiliation": "Harvard Medical School", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=NPLOM-dYGW8", "abstract": "The success of machine learning depends heavily on the choice of representations used for downstream tasks. Graph neural networks have emerged as a predominant choice for learning representations of networked data. In this talk, I describe our efforts to expand the scope and ease the applicability of graph representation learning. First, I outline SubGNN, a subgraph neural network for learning disentangled subgraph representations. Second, I will describe G-Meta, a novel meta-learning approach for graphs. G-Meta uses subgraphs to generalize to completely new graphs and never-before-seen labels using only a handful of nodes or edges. G-Meta is theoretically justified and scales to orders of magnitude larger datasets than prior work. Finally, I will discuss applications in the development of safe and effective therapeutics. The new methods have enabled the repurposing of drugs for emerging diseases, including COVID-19, where our predictions were experimentally verified in the wet laboratory. Further, our knowledge graph methods enabled discovering dozens of combinations of drugs safe for patients with considerably fewer unwanted side effects than today's treatments. Lastly, I describe our efforts in learning actionable representations that allow users of our models to receive predictions that can be interpreted meaningfully. ", "bio": "Marinka Zitnik (https://zitniklab.hms.harvard.edu) is an Assistant Professor at Harvard University with appointments in the Department of Biomedical Informatics, Broad Institute of MIT and Harvard, and Harvard Data Science. Dr. Zitnik is a computer scientist studying machine learning, focusing on challenges brought forward by data in science, medicine, and health. Before Harvard, she was a postdoctoral fellow in Computer Science at Stanford and also a member of the Chan Zuckerberg Biohub. Dr. Zitnik has published extensively in top ML venues (e.g., NeurIPS, ICLR, ICML) and leading interdisciplinary journals (e.g., Nature Methods, Nature Communications, PNAS). She has organized numerous workshops and tutorials in the nexus of AI, deep learning, drug discovery, and medical AI at leading conferences (NeurIPS, ICLR, ICML, ISMB, AAAI, WWW), where she is also in the organizing committees. She also organized the National Symposium on drugs for future pandemics on behalf of the NSF. Her research won Bayer Early Excellence in Science Award and numerous best paper and research awards from the International Society for Computational Biology. She was named a Rising Star in Electrical Engineering and Computer Science (EECS) by MIT and also a Next Generation in Biomedicine by Broad Institute of MIT and Harvard, being the only young scientist who received such recognition in both EECS and Biomedicine.", "area": "Biomedical Informatics", "key": "MarinkaZitnik", "prettyDate": "March 11"}, {"semester": "Spring", "year": "2021", "date": "2021-03-25", "speaker": "Gedas Bertasius", "website": "https://gberta.github.io/", "title": "Video Understanding with Modern Language Models", "affiliation": "Facebook AI", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=Apsw9HSh3EU", "abstract": "Humans understand the world by processing signals from both vision and language. Similarly, we believe that language understanding can be beneficial for developing better video understanding systems. In this talk, I will present several of our proposed video understanding frameworks that incorporate models from the language domain. First, I will introduce TimeSformer, the first convolution-free architecture for video modeling built exclusively with self-attention. It achieves the best reported numbers on major action recognition benchmarks, and it is also more efficient than the state-of-the-art 3D CNNs. Afterwards, I will present COBE, a new large-scale framework for learning contextualized object representations in settings involving human-object interactions. Our approach exploits automatically-transcribed speech narrations from instructional YouTube videos, and it does not require manual annotations. Lastly, I will introduce a multi-modal video-based text generation framework Vx2Text, which outperforms state-of-the-art on three video based text-generation tasks: captioning, question answering and dialoguing.", "bio": "Gedas Bertasius is a postdoctoral researcher at Facebook AI working on computer vision and machine learning problems. His current research focuses on topics of video understanding, first-person vision, and multi-modal deep learning. He received his Bachelors Degree in Computer Science from Dartmouth College, and a Ph.D. in Computer Science from the University of Pennsylvania. His recent work was nominated for the CVPR 2020 best paper award.", "area": "Vision", "key": "GedasBertasius", "prettyDate": "March 25"}, {"semester": "Spring", "year": "2021", "date": "2021-04-08", "speaker": "He He", "website": "https://hhexiy.github.io/", "title": "Guarding Against Spurious Correlations in Natural Language Understanding", "affiliation": "NYU", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=kogfp0WnGgA", "abstract": "While we have made great progress in natural language understanding, transferring the success from benchmark datasets to real applications has not always been smooth. Notably, models sometimes make mistakes that are confusing and unexpected to humans. In this talk, I will discuss shortcuts in NLP tasks and present our recent works on guarding against spurious correlations in natural language understanding tasks (e.g. textual entailment and paraphrase identification) from the perspectives of both robust learning algorithms and better data coverage. Motivated by the observation that our data often contains a small amount of \"unbiased\" examples that do not exhibit spurious correlations, we present new learning algorithms that better exploit these minority examples. On the other hand, we may want to directly augment such \"unbiased\" examples. While recent works along this line are promising, we show several pitfalls in the data augmentation approach.", "bio": "He He is an assistant professor in the Center for Data Science and Courant Institute at New York University. Before joining NYU, she spent a year at Amazon Web Services and was a postdoc at Stanford University. She received her PhD from University of Maryland, College Park. She is broadly interested in machine learning and natural language processing. Her current research interests include text generation, dialogue systems, and robust language understanding.", "area": "NLP", "key": "HeHe", "prettyDate": "April 08"}, {"semester": "Spring", "year": "2021", "date": "2021-04-15", "speaker": "Luciana Benotti", "website": "https://twitter.com/lucianabenotti?lang=enn", "title": "Two types of grounding in dialogue", "affiliation": "Universidad Nacional de C\u00f3rdoba", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=Sg9Z1NDyCZo", "abstract": "In 1991, Brennan asked: Why is it that natural language has yet to become a widely used modality of human/computer interaction? Almost 30 years later de Vries (2020) and colleagues ask the same question again. In this talk I will argue that a fundamental limitation of dialogue systems is that they cannot ground language into the world in a human-like way. I will distinguish two types of different but related kinds of grounding: perceptual and collaborative.\u00a0 First, I will describe our work on perceptual grounding [1]. I will show recent advances on referential dialogue adapting multimodal architectures for visual question answering. I will discuss the limitations of treating dialogue as question answering.\u00a0\u00a0 Second, I will present a recent opinion piece and state of the art survey on collaborative grounding [2]. Our central claim is that current dialogue systems try to avoid mistakes at all costs and this approach misses the key point that errors are a crucial mechanism in dialogue; for it is the ability to recover from them that makes dialogue such a robust process.\u00a0 [1] Answering Different Visual Questions Requires Different Grounding Strategies. Alberto Testoni, Claudio Greco, Tobias Bianchi, Mauricio Mazuecos, Agata Marcante, Raffaella Bernardi. Proceedings of the International Workshop on Spatial Language Understanding. EMNLP 2020. https://www.aclweb.org/anthology/2020.splu-1.4/ [2] Grounding as a Collaborative Process. Luciana Benotti & Patrick Blackburn. Long paper accepted at the 16th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2021. 19 to 23 April 2021. ", "bio": "Luciana Benotti is an Associate Professor at the Department of Computer Science in the Universidad Nacional de C\u00f3rdoba, from Argentina. Her research interests include different aspects of situated dialogue systems, including the study of misunderstandings, clarification requests and grounding. She has an Erasmus Mundus MSc, and a PhD in Computer Science completed at INRIA Nancy Grand Est in France. She received an IBM SUR award for her work on robust conversational interfaces, and a Google RISE award for her outreach efforts in developing AI-based technology for education. She has been an invited scholar at the University of Trento (2019), Stanford University (2018), Roskilde University (2014), University of Lorraine (2013), Universidad de Costa Rica (2012), and University of Southern California (2010). She regularly serves under different roles in the Association for Computational Linguistics (ACL) community. She has been a volunteer during conferences, a reviewer since 2010, an area chair for dialogue and interactive systems several times, and a member of the executive board of SIGDIAL and SIGSEM. She is currently an elected member of the executive board of the North American Chapter of the ACL. ", "area": "NLP", "key": "LucianaBenotti", "prettyDate": "April 15"}, {"semester": "Spring", "year": "2021", "date": "2021-04-29", "speaker": "Adam Dziedzic", "website": "https://adam-dziedzic.github.io/", "title": "CaPC Learning: Confidential and Private Collaborative Learning", "affiliation": "the Vector Institute and the University of Toronto", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=YA2DxGfRMKg", "abstract": "Machine learning benefits from large training datasets, which may not always be possible to collect by any single entity, especially when using privacy-sensitive data. In many contexts, such as healthcare and finance, separate parties may wish to collaborate and learn from each other's data but are prevented from doing so due to privacy regulations. Some regulations prevent explicit sharing of data between parties by joining datasets in a central location (confidentiality). Others also limit implicit sharing of data, e.g., through model predictions (privacy). There is currently no method that enables machine learning in such a setting, where both confidentiality and privacy need to be preserved, to prevent both explicit and implicit sharing of data. Federated learning only provides confidentiality, not privacy, since gradients shared still contain private information. Differentially private learning assumes unreasonably large datasets. Furthermore, both of these learning paradigms produce a central model whose architecture was previously agreed upon by all parties rather than enabling collaborative learning where each party learns and improves their own local model. We introduce Confidential and Private Collaborative (CaPC) learning, the first method provably achieving both confidentiality and privacy in a collaborative setting. We leverage secure multi-party computation (MPC), homomorphic encryption (HE), and other techniques in combination with privately aggregated teacher models. We demonstrate how CaPC allows participants to collaborate without having to explicitly join their training sets or train a central model. Each party is able to improve the accuracy and fairness of their model, even in settings where each party has a model that performs well on their own dataset or when datasets are not IID and model architectures are heterogeneous across parties.", "bio": "Adam is a postdoctoral researcher at the Vector Institute and the University of Toronto, advised by Prof. Nicolas Papernot. He earned his PhD at the University of Chicago, where he was advised by Prof. Sanjay Krishnan and carried out research on the Band-Limited convolutional neural networks as well as the out-of-distribution robustness of pre-trained transformers. Adam obtained his Bachelor's and Master's degrees from Warsaw University of Technology in Poland. He also studied at DTU (Technical University of Denmark) and carried out research on databases in the DIAS group at EPFL, Switzerland. He was a PhD intern at Microsoft Research and worked on recommendation of hybrid physical designs (B+ trees and Columnstores) for SQL Server. He also had internships at CERN (Geneva, Switzerland), Barclays Investment Bank (London, UK), and Google (Madison, USA).", "area": "ML security", "key": "AdamDziedzic", "prettyDate": "April 29"}, {"semester": "Fall", "year": "2020", "date": "2020-09-24", "speaker": "John Wieting", "website": "https://www.cs.cmu.edu/~jwieting/", "title": "Learning and Applications of Paraphrastic Representations for Natural Language", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=tQc1i4mgH-A", "abstract": "Representation learning has had a tremendous impact in machine learning and natural language processing (NLP), especially in recent years. Learned representations provide useful features needed for downstream tasks, allowing models to incorporate knowledge from billions of tokens of text. The result is better performance and generalization on many important problems of interest. This talk focuses on the problem of learning paraphrastic representations for units of language spanning from sub-words to full sentences \u2013 the latter being a focal point. Our primary goal is to learn models that can encode arbitrary word sequences into a vector with the property that sequences with similar semantics are near each other in the learned vector space, and that this property transfers across domains. We first show several simple, but effective, models to learn word and sentence representations on noisy paraphrases automatically extracted from bilingual corpora. These models outperform contemporary models on a variety of semantic evaluations. We then propose techniques to enable deep networks to learn effective semantic representations, addressing a limitation of our prior work. We also automatically construct a large paraphrase corpus that improves the performance of all our studied models, especially those using deep architectures, and has found uses for a variety of generation tasks such as paraphrase generation and style-transfer. We next propose models for multilingual paraphrastic sentence representations. Again, we first propose a simple and effective approach that outperforms more complicated methods on cross-lingual sentence similarity and mining bitext. We then propose a generative model that concentrates semantic information into a single interlingua representations and pushes information responsible for linguistic variation to separate language-specific representations. We show that this model has improved performance on both monolingual and cross-lingual tasks over prior work and successfully disentangles these two sources of information. Finally, we apply our representations to the task of fine-tuning neural machine translation systems using minimum risk training. The conventional approach is to use BLEU (Papineni et al., 2002), since that is commonly used for evaluation. However, we found that using an embedding model to evaluate similarity allows the range of possible scores to be continuous and, as a result, introduces fine-grained distinctions between similar translations. The result is better performance on both human evaluations and BLEU score, along with faster convergence during training.", "bio": "John Wieting is a recent PhD graduate of the Language Technology Institute at Carnegie Mellon University, where he was supervised by Graham Neubig and Taylor Berg-Kirkpatrick. He currently is a research scientist at Google Research. Previously he worked with Kevin Gimpel at the Toyota Technological Institute-Chicago, and completed his MS under the guidance of Dan Roth at the University of Illinois Urbana-Champaign. His research focuses on representation learning and its applications for natural language processing. He is also interested in language generation, with a particular interest in paraphrasing and related tasks.", "area": "NLP", "key": "JohnWieting", "prettyDate": "September 24"}, {"semester": "Fall", "year": "2020", "date": "2020-10-01", "speaker": "David Harwath", "website": "https://people.csail.mit.edu/dharwath/", "title": "Learning Spoken Language Through Vision", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=xIr1W9eHr14", "abstract": "Humans learn spoken language and visual perception at an early age by being immersed in the world around them. Why can't computers do the same? In this talk, I will describe our work to develop methodologies for grounding continuous speech signals at the raw waveform level to natural image scenes. I will first present self-supervised models capable of jointly discovering spoken words and the visual objects to which they refer, all without conventional annotations in either modality. I will show how the representations learned by these models implicitly capture meaningful linguistic structure directly from the speech signal. Finally, I will demonstrate that these models can be applied across multiple languages, and that the visual domain can function as an \"interlingua,\" enabling the discovery of word-level semantic translations at the waveform level.", "bio": "David Harwath is an assistant professor in the computer science department at The University of Texas at Austin. Prior to joining UT, he was a research scientist in the Spoken Language Systems group at the MIT Computer Science and Artificial Intelligence Lab (CSAIL). His research focuses on multi-modal learning algorithms for speech, audio, vision, and text. His work has been published at venues such as NeurIPS, ACL, ICASSP, ECCV, and CVPR, and was nominated for a best paper award at ASRU 2015. Under the supervision of James Glass, his doctoral thesis introduced models for the joint perception of speech and vision. This work was awarded the 2018 George M. Sprowls Award for the best Ph.D. thesis in computer science at MIT. He holds a Ph.D. in computer science from MIT (2018), a S.M. in computer science from MIT (2013), and a\u00a0 B.S. in electrical engineering from UIUC (2010).", "area": "Multimodal perception", "key": "DavidHarwath", "prettyDate": "October 01"}, {"semester": "Fall", "year": "2020", "date": "2020-10-08", "speaker": "Yunzhu Li", "website": "https://people.csail.mit.edu/liyunzhu/", "title": "Learning-based Dynamics Modeling for Physical Inference and Model-based Control", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=uFlL6cd-RLk", "abstract": "Humans have a strong intuitive understanding of physics. From visual observations, we can predict how the environment would change if we apply a specific action. This ability applies to objects of different materials, including rigid bodies, deformable objects, and fluids, which enables a tremendous amount of manipulation skills that are far beyond the reach of the current robot. It is desirable to help the robot learn from its interactions and better understand the dynamics. In this talk, I will present our attempt to model the dynamics of the environment from observational data by combining learning with different state representations and model class, aiming to capture the compositional nature of the objects and introduce the desired inductive bias. Using the learned simulators, robots can infer the physical properties and the relational structure within a dynamic environment and have achieved success in complex manipulation tasks, such as manipulating a pile of boxes, a cup of water, and a deformable foam. I will also present our work on building a scalable tactile glove to learn the patterns in human-object interaction and discuss how it can contribute to a multi-modal perception system that can facilitate human activities learning and dynamics understanding.", "bio": "Yunzhu Li is a Ph.D. student at MIT, advised by Prof. Antonio Torralba and Prof. Russ Tedrake. He works on the intersection of computer vision, machine learning, and robotics. He is particularly interested in enabling robots to better perceive and interact with the world via learning-based dynamics modeling and multimodal perception. Yunzhu is a recipient of the Adobe Research Fellowship. His research was published in top journals and conferences, including Nature, NeurIPS, CVPR, ICRA, etc., and has been featured by CNN, BBC, Forbes, The Economist, MIT Technology Review, WIRED, and other media outlets. Before coming to MIT, he received a B.S. degree from Peking University. He has also spent time at Stanford AI Lab and NVIDIA Robotics Research Lab.", "area": "Vision/Robotics", "key": "YunzhuLi", "prettyDate": "October 08"}, {"semester": "Fall", "year": "2020", "date": "2020-10-15", "speaker": "Fatemeh Mireshghallah", "website": "https://cseweb.ucsd.edu/~fmireshg/", "title": "Privacy and Fairness in Deep Neural Network Inference", "affiliation": "UCSD", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=nbFjjOHLvHQ", "abstract": "Cloud-based execution of machine learning models is becoming increasingly prevalent. Futuristic mixed or augmented reality and robotic applications rely on remote cloud localization services. Consumers also use these services to perform mundane everyday tasks such as simply applying filters on images, or calling smart home devices or virtual assistants. Their personal information is collected and sent to a service-provider on the cloud where a machine learning task is executed and the query is responded to. This execution model could have enormous privacy ramifications when consumers use it in their home or private industrial setup. In this talk, I will talk about two methods that we proposed (Shredder and Cloak) to address the privacy and latency issues in the aforementioned setup. These methods do not rely on encryption and aims to reduce the information content of the query with as little as possible compromise on the inference accuracy by adding noise to the query sent to the cloud. I will conclude the talk by discussing the effects that different privacy mitigations have on the fairness of the deployed models.", "bio": "Fatemehsadat Mireshghallah is a 3rd year CS Ph.D. student at UC San Diego. She received her B.Sc. in Computer Engineering with honors from Sharif University of Technology in 2018 and she is a recipient of the National Center for Women & IT (NCWIT) Aspirations in Computing Collegiate award in 2020, for her work on light-weight privacy-preserving ML. Her thesis research at UCSD is focused on designing practical and low-overhead privacy-preserving solutions for deployed cloud-based deep learning models. She was a research intern at Microsoft Research AI in summer 2020 where she worked on privacy-preserving text generation.", "area": "Privacy for ML", "key": "FatemehMireshghallah", "prettyDate": "October 15"}, {"semester": "Fall", "year": "2020", "date": "2020-10-22", "speaker": "Marcus Gualtieri", "website": "https://www.ccs.neu.edu/home/mgualti/", "title": "Learning Robotic Pick-Place with Uncertain Object Shapes", "affiliation": "Northeastern University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=KNyHbM0PcZU", "abstract": "Pick-place is the problem of rearranging objects by fixing them one-by-one in the hand and placing them stably. In open environments, such as households, hospitals, or grocery stores, objects are noisily and partially observed by the robot's sensors. Calculating grasps that are likely to fix objects and placements that are likely to be stable is not, in this setting, straight-forward. In this talk I will discuss how machine learning has influenced approaches to this problem and how this problem has motivated machine learning research. There have been two main approaches to pick-place with uncertain object shapes. First, reinforcement learning has been used to jointly learn perception and control. One major challenge with this approach is the 6-dimensional, continuous action space that robots encounter, i.e., part of the \"curse of dimensionality\". I will discuss how we addressed this challenge by learning hierarchical attention. Second, several modular systems have been proposed, where perception is handled by machine learning and control by geometric planning algorithms, and each module is designed separately. Challenges that arise here include (i) most established pick-place planners require the full geometry of the objects and (ii) these planners do not consider uncertainty in the shape of the objects. I will discuss how 3D point-based object instance segmentation and shape completion have recently been used to address these challenges. Hopefully this discussion will highlight how machine learning has enabled robots to work in increasingly open environments and what gaps still remain.", "bio": "Marcus Gualtieri is a PhD student in computer science at Northeastern University who studies robotic manipulation and is advised by Robert Platt. Previous to this, he developed simulation and control software for adaptive optics research in Dayton, Ohio. Marcus received an M.S. in computer science from Northeastern and a B.S. in software engineering from Florida Tech.", "area": "Deep RL", "key": "MarcusGualtieri", "prettyDate": "October 22"}, {"semester": "Fall", "year": "2020", "date": "2020-10-29", "speaker": "Kalesha Bullard", "website": "https://www.kaleshabullard.com/", "title": "Learning through Interaction in Multi-Agent Systems", "affiliation": "FAIR", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=Em4rgAn9ecM", "abstract": "Effective communication is an important skill for enabling information exchange and cooperation in multi-agent settings. My talk will present research that investigates methods for enabling agents to learn to achieve shared goals through interactions with other agents. In particular, the talk will focus on my ongoing work within Multi-Agent Reinforcement Learning, on Emergent Communication for embodied agent populations. Indeed, emergent communication is now a vibrant field of research, with common settings involving discrete cheap-talk channels. One limitation of this setting is that it does not allow for the emergent protocols to generalize beyond the training partners. Furthermore, so far emergent communication has primarily focused on the use of symbolic channels (via discrete symbols, e.g. words). In the work presented, we extend this line of work to a new modality, by studying agents that learn to communicate via actuating their joints in a 3D simulated environment. We show that under realistic assumptions, a non-uniform distribution over intents and a common-knowledge energy cost, agents can learn communication protocols that generalize to novel partners. We also explore and analyze specific difficulties associated with finding globally optimal solutions in practice. Overall, while there are many interesting open challenges that remain, this work opens up exciting avenues for exploring continuous action communication protocols in virtually or physically embodied agents.", "bio": "Kalesha Bullard is a postdoctoral researcher at Facebook AI Research. She completed her PhD in Computer Science at Georgia Institute of Technology in 2019, where her research lied at the intersection of human-robot interaction and machine learning, in interactive robot learning. During her postdoc, Kalesha has expanded her research to explore the space of multi-agent reinforcement learning, currently investigating how to enable embodied multi-agent populations to learn general communication protocols. More broadly, Kalesha\u2019s research interests span the space of autonomous reasoning and decision making for artificial agents in multi-agent settings. To date, her research has focused on models and algorithms for enabling agents to learn through interaction with other agents (human or artificial). Kalesha has also participated in a number of service roles throughout her research career. She currently serves as a member of the organizing committee for the NeurIPS 2020 Workshop on Zero-Shot Emergent Communication and on the program committee for the NeurIPS 2020 Cooperative AI Workshop. And recent prior appointments include serving as an Area Chair for the 2019 NeurIPS Women in Machine Learning Workshop, a Program Committee (PC) member for the 2019 International Conference on Autonomous Agents and Multi-Agent Systems, and PC Co-Chair for the 2017 AAAI Fall Symposium on Artificial Intelligence for Human-Robot Interaction.", "area": "Multi-Agent Reinforcement Learning", "key": "KaleshaBullard", "prettyDate": "October 29"}, {"semester": "Fall", "year": "2020", "date": "2020-11-05", "speaker": "Ankur Parikh", "website": "https://research.google/people/104995/", "title": "Towards High Precision Text Generation", "affiliation": "Google", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=tG0ixUpUgpo", "abstract": "Despite large advances in neural text generation in terms of fluency, existing generation techniques are prone to hallucination and often produce output that is unfaithful or irrelevant to the source text. In this talk, we take a multi-faceted approach to this problem from 3 aspects: data, evaluation, and modeling. From the data standpoint, we propose ToTTo, a tables-to-text-dataset with high quality annotator revised references that we hope can serve as a benchmark for high precision text generation task. While the dataset is challenging, existing n-gram based evaluation metrics are often insufficient to detect hallucinations. To this end, we propose BLEURT, a fully learnt end-to-end metric based on transfer learning that can quickly adapt to measure specific evaluation criteria. Finally, we propose a model based on confidence decoding to mitigate hallucinations. Collaborators: This is joint work with Thibault Sellam, Ran Tian, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, and Dipanjan Das.", "bio": "Ankur Parikh is a senior research scientist at Google NYC and adjunct assistant professor at NYU. His research interests are in natural language processing and machine learning with a recent focus on high precision text generation. Ankur received his PhD from Carnegie Mellon in 2015 and has received a best paper runner up award at EMNLP 2014 and a best paper in translational bioinformatics at ISMB 2011.", "area": "NLP", "key": "AnkurParikh", "prettyDate": "November 05"}, {"semester": "Fall", "year": "2020", "date": "2020-11-19", "speaker": "Kelsey Allen", "website": "https://web.mit.edu/krallen/www/", "title": "Learning to act and predict with objects, physics and modes", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=29mNrNqjCKs", "abstract": "The world is structured in countless ways. When cognitive and machine models respect these structures, by factorizing their modules and parameters, they can achieve remarkable accuracy and generalization. For instance, the spatial factorization of convolutional networks (inspired by visual neuroscience), has led to enormous progress in machine abilities to transform and recognize visual input. In this talk, I will discuss our work investigating the factorizations of objects, physics, and events/modes in both humans and machines. I will show how to harness object and relational structure in the form of graph networks to improve machine generalization, how to harness physics to better explain creative human tool-use in a novel physical problem-solving environment, and how to harness events/modes to enable a robotic agent to plan with tools. To go from harnessing structure to discovering it, I will then talk about our initial steps into how event/mode structures can be learned -- leading to improvements in few-shot learning and compositional dynamics modelling. By combining general structures that are true of the world with general-purpose methods for statistical learning, we can develop more robust and data-efficient machine agents, and better explain how natural intelligence learns so much from so little.", "bio": "Kelsey Allen is a PhD student at MIT advised by Josh Tenenbaum in the department of brain and cognitive sciences. She is a member of the Center for Brains, Minds and Machines. Her work has been awarded with the NSERC PGS doctoral fellowship and a Best Paper award from Robotics: Science and Systems. Before coming to MIT, she studied physics at UBC where she contributed to papers on particle physics at the LHC and collective intelligence in ant colonies.", "area": "Robotics", "key": "KelseyAllen", "prettyDate": "November 19"}, {"semester": "Fall", "year": "2020", "date": "2020-11-12", "speaker": "Maria De-Arteaga", "website": "https://mariadearteaga.com/", "title": "A Case for Humans-in-the-Loop: Decisions in the Presence of Erroneous Algorithmic Scores", "affiliation": "UT Austin", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=aaqSgOe1mDs", "abstract": "The increased use of algorithmic predictions in sensitive domains has been accompanied by both enthusiasm and concern. To understand the opportunities and risks of these technologies, it is key to study how experts alter their decisions when using such tools. In this paper, we study the adoption of an algorithmic tool used to assist child maltreatment hotline screening decisions. We focus on the question: Are humans capable of identifying cases in which the machine is wrong, and of overriding those recommendations? We first show that humans do alter their behavior when the tool is deployed. Then, we show that humans are less likely to adhere to the machine's recommendation when the score displayed is an incorrect estimate of risk, even when overriding the recommendation requires supervisory approval. These results highlight the risks of full automation and the importance of designing decision pipelines that provide humans with autonomy.", "bio": "Maria De-Arteaga is an Assistant Professor at the Information, Risk and Operations Management Department at the University of Texas at Austin, where she is also a core faculty member of the Machine Learning Laboratory. She received a joint PhD in Machine Learning and Public Policy from Carnegie Mellon University. Her research focuses on the risks and opportunities of using machine learning for decision support in high-stakes settings. Her work has been awarded the Best Thematic Paper Award at NAACL\u201919, the Innovation Award on Data Science at Data for Policy\u201916, and has been featured by UN Women and Global Pulse in their report Gender Equality and Big Data: Making Gender Data Visible. She is a recipient of a 2020 Google Award for Inclusion Research, a 2018 Microsoft Research Dissertation Grant, and was named an EECS 2019 Rising Star. In 2017 she co-founded the Machine Learning for the Developing World (ML4D) Workshop series at NeurIPS.", "area": "Human-centered ML", "key": "MariaDe-Arteaga", "prettyDate": "November 12"}, {"semester": "Spring", "year": "2020", "date": "2020-04-02", "speaker": "Yonatan Belinkov", "website": "https://people.csail.mit.edu/belinkov/", "title": "Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=ew-P4vU-2yI", "abstract": "The success of neural network models in various tasks, coupled with their opaque nature, has led to much interest in interpreting and analyzing such models. Common analysis methods for interpreting neural models in natural language processing typically examine either their structure (for example, probing classifiers) or their behavior (challenge sets, saliency methods), but not both. In this talk, I will propose a new methodology grounded in the theory of causal mediation analysis for interpreting which parts of a model are causally implicated in its behavior. This methodology enables us to analyze the mechanisms by which information flows from input to output through various model components, known as mediators. I will demonstrate an application of this methodology to analyzing gender bias in pre-trained Transformer language models. In particular, we study the role of individual neurons and attention heads in mediating gender bias across three datasets designed to gauge a model\u2019s sensitivity to gender bias. Our mediation analysis reveals that gender bias effects are (i) sparse, concentrated in a small part of the network; (ii) synergistic, amplified or repressed by different components; and (iii) de-composable into effects flowing directly from the input and indirectly through the mediators. I will conclude by laying out a few ideas for future work on analyzing neural NLP models. ", "bio": "Yonatan Belinkov is a Postdoctoral Fellow at the Harvard School of Engineering and Applied Sciences (SEAS) and the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). His research focuses on interpretability and robustness of neural network models of human language. His research has been published at various NLP/ML venues. His PhD dissertation at MIT analyzed internal language representations in deep learning models, with applications to machine translation and speech recognition. He is a Harvard Mind, Brain, and Behavior Fellow. He will be joining the Technion Computer Science department in Fall 2020.", "area": "NLP", "key": "YonatanBelinkov", "prettyDate": "April 02"}, {"semester": "Spring", "year": "2020", "date": "2020-03-26", "speaker": "Kate Saenko", "website": "https://www.bu.edu/cs/profiles/kate-saenko/", "title": "Postponed to Fall 2020 due to COVID-19", "affiliation": "BU", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "Vision", "key": "KateSaenko", "prettyDate": "March 26"}, {"semester": "Spring", "year": "2020", "date": "2020-03-12", "speaker": "Hsiao-Yu (Fish) Tung", "website": "https://sfish0101.bitbucket.io/", "title": "Postponed to Fall 2020 due to COVID-19", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "", "abstract": "Current state-of-the-art CNNs can localize and name objects in internet photos, yet, they miss the basic knowledge that a two-year-old toddler has possessed: objects persist over time despite changes in the camera view, they have 3D extent, they do not 3D intersect, and so on. In this talk, I will introduce neural architectures that learn to parse video streams of a static scene into world-centric 3D feature maps by disentangling camera motion from scene appearance.  I will show the proposed architectures learn object permanence, can generate RGB views from novel viewpoints in truly novel scenes, can infer affordability in sentences by grounding language in 3D visual simulations, and can learn intuitive physics in a persistent 3D feature space. Our experiments suggest that the proposed architecture is essential to generalize across objects and locations, and it overcomes many limitations of 2D CNNs.", "bio": "Hsiao-Yu (Fish) Tung is a fifth-year PhD student in the Machine Learning Department at CMU, advised by Professor Katerina Fragkiadaki. She is interested in building machines that can understand and interact with the world. Her research spans across unsupervised learning, computer vision, graphics, robotics, and language. She is selected for the 2019 Rising Stars in EECS program. Her research is supported by the Yahoo InMind fellowship. She received her M.S. in CMU MLD and B.S. in Electrical Engineering from National Taiwan University. During her master degree, she worked with Professor Alex Smola on spectral method for Bayesian models and had designed efficient and provable algorithms for unsupervised topic discovery.", "area": "Vision", "key": "Hsiao-Yu(Fish)Tung", "prettyDate": "March 12"}, {"semester": "Spring", "year": "2020", "date": "2020-03-05", "speaker": "Amanda Stent", "website": "https://cra.org/cra-wp/amanda-stent/", "title": "NLP for Natural Documents", "affiliation": "Bloomberg", "sponsor": "Oracle Labs", "video": "", "abstract": "Today's finance industry is continuously searching for alpha, through more advanced modeling and through alternative sources of data. Many alternative sources of data are not raw numerical data but natural documents - human-readable documents containing tables, graphics and text. In this talk, I will present an overview of how we use NLP at Bloomberg to extract information from natural documents, and highlight some research challenges. I also present a case study of how such information can be combined with market data for better predictive modeling.", "bio": "Amanda Stent is a NLP architect in the data science group in the office of the CTO at Bloomberg LP. Previously, she was a director of research and principal research scientist at Yahoo Labs, a principal member of technical staff at AT&T Labs - Research, and an associate professor in the Computer Science Department at Stony Brook University. Her research interests center on natural language processing and its applications. She holds a PhD in computer science from the University of Rochester. She is co-editor of the book Natural Language Generation in Interactive Systems (Cambridge University Press), has co-authored over 100 papers on natural language processing and is co-inventor on over 25 patents and patent applications.", "area": "NLP", "key": "AmandaStent", "prettyDate": "March 05"}, {"semester": "Spring", "year": "2020", "date": "2020-02-20", "speaker": "Weiwei Pan", "website": "https://iacs.seas.harvard.edu/people/weiwei-pan", "title": "What Are Useful Uncertainties in Deep Learning and How Do We Get Them?", "affiliation": "Harvard University", "sponsor": "Oracle Labs", "video": "", "abstract": "While deep learning has demonstrable success on many tasks, the point estimates provided by standard deep models can lead to overfitting and provide no uncertainty quantification on predictions.\u00a0 However, when models are applied to critical domains such as autonomous driving, precision health care, or criminal justice, reliable measurements of a model's predictive uncertainty may be as crucial as correctness of its predictions. At the same time, increasing attention in recent literature is being paid to separating sources of predictive uncertainty, with the goal of separating types of uncertainties reducible through additional data collection from those that represent stochasticity inherent in the data generation process. In this talk, we examine a number of deep (Bayesian) models that promise to capture complex forms for predictive uncertainties, we also examine metrics commonly used to such uncertainties. We aim to highlight strengths and limitations of the models as well as the metrics; we also discuss potential ways to improve both in meaningful ways for downstream tasks.", "bio": "Weiwei received her Ph.D. in pure math from Wesleyan University, where she specialized in higher categorical structures in algebraic topology, and her post-doctoral work at Goettingen Unversity involved categorification of knot invariants. At Harvard, Weiwei works with Finale Doshi-Velez (Harvard dtak) on deep Bayesian and generative models focusing on modeling complex forms of uncertainty and noise, as well as on developing inference methods that enforce down-stream task desiderata.", "area": "ML", "key": "WeiweiPan", "prettyDate": "February 20"}, {"semester": "Spring", "year": "2020", "date": "2020-02-13", "speaker": "Octavian Ganea", "website": "http://people.inf.ethz.ch/ganeao/", "title": "Hyperbolic Geometry in Machine Learning", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "Based on my PhD work. Slides: https://docs.google.com/presentation/d/1dheg6Ul6zQj9tlMLIf-YnU2sNzWI0MbJCej5xAzRL5c/edit#slide=id.p", "bio": "I am a postdoctoral researcher in the group of prof. T. Jaakkola and prof. R. Barzilay at CSAIL-MIT. Previously I obtained my PhD from the Data Analytics Lab at ETH Zurich under the supervision of prof. Thomas Hofmann. I am broadly interested in representation learning for text, graphs or images through statistical or geometric models that could be devised and understood in a mathematically principled manner. In particular, I have recently explored finding and learning latent hierarchical structures in data via hyperbolic geometry.  ", "area": "NLP", "key": "OctavianGanea", "prettyDate": "February 13"}, {"semester": "Spring", "year": "2020", "date": "2020-01-30", "speaker": "Qian Yang", "website": "https://yangqian.myportfolio.com/", "title": "Leveraging AI as a Material for User Experience Design", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=Oxgal1rfJss", "abstract": "Advances in AI promise to improve people's lives and societies. As these systems migrate from research labs into the real world, new challenges have emerged. For example, how should predictive models form an effective team with physicians in clinical decision making? How could the designs of AI-mediated social networks prevent unintended consequences such as data-driven inequality? These are challenges of translation: translating AI's algorithmic advances into valuable, situated human experiences. This talk focuses on this critical translation. I will share a range of human-AI interaction design projects: from designing a system that helps doctors make life-and-death clinical decisions in real practice, to leveraging Natural Language Generation systems to improve authors\u2019 writing experience. Each design addressed a critical challenge in moving AI from research labs valuably into the real world. I outline a new framework that scaffolds the problem space of human-AI interaction design. I discuss the opportunities and challenges it reveals for both AI and user experience research.  ", "bio": "Qian Yang is an interaction design researcher and a Ph.D. candidate at the Human-Computer Interaction Institute at Carnegie Mellon University. Her research focuses on the design and innovation of human-AI interactions. She is best known for designing machine learning systems that effectively aided doctors in making critical clinical decisions. During her Ph.D., Yang has published fifteen peer-reviewed publications on the topic of human-AI interaction at premiere HCI research venus. Four of these papers have received awards. Yang has won a fellowship from the Center for Machine Learning and Health, a Microsoft Research Dissertation Grant, and the Innovation by Design award from Fast Company. This Spring she will be speaking at SXSW on how to design AI products and services.", "area": "HCI + ML", "key": "QianYang", "prettyDate": "January 30"}, {"semester": "Fall", "year": "2019", "date": "2019-12-05", "speaker": "Bhuwan Dhingra", "website": "https://www.cs.cmu.edu/~bdhingra/", "title": "Text as a Virtual Knowledge Base", "affiliation": "Carnegie Mellon University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=0qaL7A7gM8U", "abstract": "Structured Knowledge Bases (KBs) are extremely useful for applications such as question answering and dialog, but are difficult to populate and maintain. People prefer expressing information in natural language, and hence text corpora, such as Wikipedia, contain more detailed up-to-date information. This raises the question -- can we directly treat text corpora as knowledge bases for extracting information on demand? In this talk I will focus on two problems related to this question. First, I will look at augmenting incomplete KBs with textual knowledge for question answering. I will describe a graph neural network model for processing heterogeneous data from the two sources. Next, I will describe a scalable approach for compositional reasoning over the contents of the text corpus, analogous to following a path of relations in a structured KB to answer multi-hop queries. I will conclude by discussing interesting future research directions in this domain.", "bio": "Bhuwan Dhingra is a final year PhD student at Carnegie Mellon University, advised by William Cohen and Ruslan Salakhutdinov. His research uses natural language processing and machine learning to build an interface between AI applications and world knowledge (facts about people, places and things). His work is supported by the Siemens FutureMakers PhD fellowship. Prior to joining CMU, Bhuwan completed his undergraduate studies at IIT Kanpur in 2013, and spent two years at Qualcomm Research in the beautiful city of San Diego.", "area": "NLP", "key": "BhuwanDhingra", "prettyDate": "December 05"}, {"semester": "Fall", "year": "2019", "date": "2019-11-21", "speaker": "Diyi Yang", "website": "https://www.cc.gatech.edu/~dyang888/", "title": "Building Language Technologies for Better Online Communities", "affiliation": "Georgia Tech", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=19UgKTd2rFA", "abstract": "We live in an era where many aspects of our daily activities are recorded as textual and activity data, from social media posts, to medical and financial records, to work activities captured by Wikipedia and other online tools. My research combines techniques in natural language processing, machine learning and theories in social science to study human behavior in online communities, with the goal of developing theories and systems to build better socio-technical systems. In this talk, I will explain my research from two specific studies. The first one studies what makes language persuasive by introducing a simple semi-supervised neural network to recognize persuasion strategies in loan requests on crowdfunding platforms.  The second focuses on modeling how people seek and offer support via language in online cancer support communities and building interventions to support patient communication.  Through these two examples, I show how we can accurately and efficiently model human communication to build better social systems", "bio": "Diyi Yang is an assistant professor in the School of Interactive Computing at Georgia Tech, also affiliated with the Machine Learning Center (ML@GT) at Georgia Tech. Diyi received her PhD from the Language Technologies Institute at Carnegie Mellon University, and her bachelor's degree from Shanghai Jiao Tong University, China. She is interested in computational semantics of human language (such as text analysis, generation, discourse) and computational social science. She has published more than 40 papers at leading NLP/HCI conferences and journals, and received one Notable Dataset Award from EMNLP 2015, one Best Paper Award Nomination from ICWSM 2016, and two Best Paper Honorable Mentions from SIGCHI 2019. Diyi has been awarded Carnegie Mellon Presidential Fellowship and Facebook Ph.D. Fellowship.", "area": "NLP", "key": "DiyiYang", "prettyDate": "November 21"}, {"semester": "Fall", "year": "2019", "date": "2019-11-20", "speaker": "Yuxiong Wang", "website": "https://www.ri.cmu.edu/ri-people/yuxiong-wang/", "title": "Learning to Learn More with Less", "affiliation": "FAIR", "sponsor": "Oracle Labs", "video": "", "abstract": "Understanding how humans and machines learn from few examples remains a fundamental challenge. Humans are remarkably able to grasp a new concept from just few examples, or learn a new skill from just few trials. By contrast, state-of-the-art machine learning techniques typically require thousands of training examples and often break down if the training sample set is too small. In this talk, I will discuss our efforts towards endowing visual learning systems with few-shot learning ability. Our key insight is that the visual world is well structured and highly predictable not only in feature spaces but also in under-explored model and data spaces. Such structures and regularities enable the systems to learn how to learn new tasks rapidly by reusing previous experiences. I will focus on a few topics to demonstrate how to leverage this idea of learning to learn, or meta-learning, to address a broad range of few-shot learning tasks: meta-learning in model space and task-oriented generative modeling. I will also discuss some ongoing work towards building machines that are able to operate in highly dynamic and open environments, making intelligent and independent decisions based on insufficient information.", "bio": "Yuxiong Wang is a postdoctoral fellow in the Robotics Institute at Carnegie Mellon University. He received a Ph.D. in robotics in 2018 from Carnegie Mellon University. His research interests lie in the intersection of computer vision, machine learning, and robotics, with a particular focus on few-shot learning and meta-learning. He has spent time at Facebook AI Research (FAIR).", "area": "Vision, Meta Learning", "key": "YuxiongWang", "prettyDate": "November 20"}, {"semester": "Fall", "year": "2019", "date": "2019-11-14", "speaker": "Samira Samadi", "website": "https://sites.google.com/site/ssamadi/", "title": "Fair Machine Learning: PCA and Spectral Clustering", "affiliation": "Georgia Tech", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=drkJcv9WT6Y", "abstract": "In this talk, I investigate several ML paradigms from the viewpoint of fairness. In the first line of work, I study fairness for Principal Component Analysis (PCA), one of the most commonly used dimensionality reduction techniques. I show on real-world data sets that PCA can inadvertently produce low-dimensional representations with different fidelity for two different demographics. This motivates our study of Fair PCA and more generally multi-criteria dimensionality reduction. I present an exact polynomial-time algorithm for Fair PCA when there are two demographics in the data and approximation algorithms for a broad class of multi-criteria dimensionality reduction when there are multiple demographic groups. In the second line of work, I study spectral clustering (SC) with the constraint that every demographic is proportionally represented in each cluster. We develop variants of both normalized and unnormalized constrained SC and show that they help find fairer clusterings on both synthetic and real data. We also provide a theoretical analysis of our algorithms on a natural variant of the stochastic block model, where the demographic groups have strong inter-group connectivity, but also exhibit a \u201cnatural\u201d clustering structure which is proportionally balanced. We prove that our algorithms can recover this underlying balanced clustering with high probability.", "bio": "Samira Samadi is a Ph.D. candidate at the School of Computer Science, Georgia Tech where she works with Santosh Vempala. Prior to this, she was a research associate at the School of Computer Science at the University of Waterloo where she worked with Shai Ben-David. She received her M.Sc. in Computer Science from the University of British Columbia under the supervision of Nick Harvey and her B.Sc. in Mathematics at the Sharif University of Technology. Her primary research interests are in ethics in AI, machine learning, algorithms, and human computation.", "area": "ML Theory, Fairness ", "key": "SamiraSamadi", "prettyDate": "November 14"}, {"semester": "Fall", "year": "2019", "date": "2019-11-06", "speaker": "Carl Vondrick", "website": "http://www.cs.columbia.edu/~vondrick/", "title": "Learning from Unlabeled Video", "affiliation": "Columbia University.", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=9aR0-mK1GhI", "abstract": "I will discuss our research to use large amounts of unlabeled video in order to efficiently train models for visual recognition. Leveraging millions of videos, our work develops methods for machines to learn perception tasks such as anticipating human actions in the immediate future, tracking visual objects, and recognizing ambient sounds.  We show how to take advantage of the natural context available in video in order to learn without human supervision, for example through the natural synchronization of vision and sound, or the temporal coherence of motion and color.", "bio": "Carl Vondrick is an Assistant Professor of Computer Science at Columbia University. Previously, he was a research scientist at Google. He completed his Ph.D. at the Massachusetts Institute of Technology in 2017.", "area": "Vision", "key": "CarlVondrick", "prettyDate": "November 06"}, {"semester": "Fall", "year": "2019", "date": "2019-10-31", "speaker": "Zi Wang", "website": "https://ziw.mit.edu/", "title": "Bayesian Optimization for Global Optimization of Expensive Black-box Functions", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=Fufcr5As3AI", "abstract": "Many problems in areas ranging from finance and product design to engineering in general all boil down to the problem of optimizing expensive black-box functions. Bayesian optimization uses probabilistic methods to address this problem with assumptions usually expressed by a Gaussian process prior. Motivated by real-world applications in high-dimensional parameter-tuning problems for complex machine learning algorithms and expensive active learning problems in robotics, we study the theoretical understandings of Bayesian optimization, connections among existing methods, and develop efficient and provably correct Bayesian optimization methods for these applications. In this talk, I will give an in-depth tour of our study of Bayesian optimization on how to design a better data acquisition strategy, how to scale up the method to higher-dimensional and larger-scale data and how to analyze the sample complexity without assuming the full knowledge of the prior. Finally, I will also briefly show how we utilized some of these ideas to tackle problems in robot learning and planning for complex long-horizon problems.", "bio": "Zi Wang is a Ph.D. candidate at MIT Computer Science and Artificial Intelligence Laboratory advised by Prof. Leslie Pack Kaelbling and Prof. Tomas Lozano-Perez. Her PhD research focuses on tackling problems related to robot learning, active learning for planning and Bayesian optimization. She received her M.S. degree in Electrical Engineering and Computer Science from MIT in Feb 2016 and B.Eng. degree in Computer Science and Technology from Tsinghua University in Jul 2014. Zi is a recipient of MIT Graduate Women of Excellence Award, Rising Star in EECS and Google Anita Borg Scholarship. While at MIT, she served as co-president of Graduate Women in Course 6 (EECS), co-organizer of the first Machine Learning Across MIT Retreat and research mentor for several undergraduate and MEng students.", "area": "Optimization, Robotics", "key": "ZiWang", "prettyDate": "October 31"}, {"semester": "Fall", "year": "2019", "date": "2019-10-23", "speaker": "Laure Thompson", "website": "https://www.cs.cornell.edu/~laurejt/", "title": "Understanding and Directing What Models Learn", "affiliation": "Cornell University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=_0NDe9EU88s", "abstract": "Machine learning and statistical methods, such as unsupervised semantic models, are popular and useful techniques for making massive digital collections more explorable and analyzable. But what underlying patterns do these models actually learn, and which patterns are they most likely to repeatedly learn? Moreover, how might we direct what these models learn so that they are useful to a wider range of scholarly inquiry? For example, while it might be useful to organize novels by authors, learning this structure is seldom useful when already known and can be problematic if it is mischaracterized as a cross-cutting pattern. In this talk, I will discuss my recent work on measuring and mitigating topic-metadata correlation in topic models. I will show how intentional data modification can make topics more cross-cutting, specific, and stable.", "bio": "Laure Thompson is a final-year Ph.D. candidate in Computer Science at Cornell University where she is advised by David Mimno. Her research interests are in the areas of natural language processing, machine learning, and digital humanities. Driven by humanistic applications, her work uses a wide range of cultural heritage corpora: from texts of science fiction novels and the Patrologia Graeca to images of avant-garde journals and engraved gemstones. Laure is a recipient of an NSF Graduate Research Fellowship and a COLING best paper award. She received her bachelor's degrees in computer science and electrical engineering with minors in mathematics and classical studies from the University of Washington in 2013.", "area": "NLP", "key": "LaureThompson", "prettyDate": "October 23"}, {"semester": "Fall", "year": "2019", "date": "2019-10-16", "speaker": "Veronika Thost", "website": "https://researcher.watson.ibm.com/researcher/view.php?person=ibm-Veronika.Thost", "title": "Knowledge Representations & Reasoning Meets Machine Learning", "affiliation": "IBM", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=2lXEv2sph2I", "abstract": "In many domains, there is structured knowledge which can be leveraged for reasoning in an informed way in order to obtain high quality answers. Symbolic approaches for knowledge representation and reasoning are less prominent today - mainly due to their lack of scalability - but their strength lies in the verifiable and interpretable reasoning that can be accomplished. In this talk, we present work about how symbolic knowledge representations and reasoning can be combined with machine learning. We will present new datasets to evaluate logical rule learning, show how reinforcement learning can support logical reasoning, and consider knowledge graphs as external information for learning (e.g., for recognizing textual entailment).", "bio": "Veronika is a Postdoctoral Researcher in the MIT-IBM Watson AI Lab at IBM Research, Cambridge, MA. Her work focuses on the combination of symbolic knowledge representations and reasoning with learning: on learning logical theories and to guide reasoning over such theories, and on how the information in knowledge graphs can be used as structured, external knowledge to support learning. Previously, Veronika worked as a Postdoctoral Researcher at TU Dresden, Germany, where she also received her Ph.D. in Computer Science in 2017. At that time, she worked on query answering over knowledge graphs, existential rules, and in description logics. Her work has been published at IJCAI, KR, ISWC, ESWC, KR, JWS, and TOCL", "area": "NLP", "key": "VeronikaThost", "prettyDate": "October 16"}, {"semester": "Fall", "year": "2019", "date": "2019-10-10", "speaker": "Grant Van Horn", "website": "https://gvanhorn38.github.io/", "title": "Visipedia + iNaturalist: integrating machine learning into a naturalist community", "affiliation": "Cornell", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=KRTj3Xl6ldw", "abstract": "iNaturalist is a community of over 2 million nature enthusiasts that share observations of the natural world. These observations consist of at least one photo, a GPS coordinate, and a taxonomic label from the tree of life. The iNaturalist community has recorded over 30 million observations of organisms from around the world. These recordings are exported to GBIF for scientists and conservationists to use in research and reports. As the iNaturalist community grows and the expertise becomes more diffuse, the need for automation becomes crucial for maintaining an engaging user experience and for ensuring the accuracy of data exported to GBIF. In this talk I will describe our work on learning the taxonomic identification skills of iNaturalist users, using these skills to assign taxonomic labels to images, and subsequently training computer vision systems on the resulting dataset. These computer vision systems can be accessed in the Apple App Store or Google Play Store in both the \u201ciNaturalist\u201d and \u201cSeek by iNaturalist\u201d apps as well as the iNaturalist website.", "bio": "Grant is a postdoc at Cornell Lab of Ornithology. He earned his PhD at Caltech advised by Prof. Pietro Perona, and BS and MS degrees at UCSD advised by Prof. Serge Belongie. His research focuses on efficient dataset collection and fine-grained visual categorization, particularly for the natural world. He works closely with iNaturalist and the Cornell Lab of Ornithology where he puts his research into production.", "area": "Vision", "key": "GrantVanHorn", "prettyDate": "October 10"}, {"semester": "Fall", "year": "2019", "date": "2019-10-03", "speaker": "Shrimai Prabhumoye", "website": "https://www.cs.cmu.edu/~sprabhum/", "title": "Controlling style, content, and structure in natural language generation", "affiliation": "Carnegie Mellon University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=p3XRBkvCUrg", "abstract": "The 21st century is witnessing a major shift in the way people interact with technology and Natural Language Generation (NLG) is playing a central role. The increasing ubiquity of computing technologies has led to situation-aware applications that are required to produce naturalistic (informative, coherent, and appropriate) outputs. But situation-aware NLG is hard. Devices must not only generate natural sentences - already a challenging task - but include ever more complex data as inputs, and sound more natural every year. How can we expect machines to understand this and make the right choice for what to say? Solving a problem like this requires tackling at least three core tasks of NLG. The first is content determination: the information to be conveyed. Next comes discourse planning: the structure that a document will take on when it is articulated, given the preceding context and the rhetorical intent of the speaker. And finally, lexicalization: the particular words and phrases that convey the content of a sentence with a particular style or tone, given the appropriate structure in the discourse context.", "bio": "Shrimai is a second-year Ph.D. student at Language Technologies, School of Computer Science, Carnegie Mellon University. She is advised by\u00a0Prof. Alan W Black\u00a0and\u00a0Prof. Ruslan Salakhutdinov. She is broadly interested in natural language generation with special focus on style transfer and content transfer. During the course of her Ph.D., she has interned at Facebook AI Research and Microsoft Research.", "area": "NLP", "key": "ShrimaiPrabhumoye", "prettyDate": "October 03"}, {"semester": "Fall", "year": "2019", "date": "2019-09-26", "speaker": "Byron Wallace", "website": "http://www.byronwallace.com/", "title": "What does the evidence say? Models to help make sense of the biomedical literature", "affiliation": "Northeastern University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=qsw5QPtEwiU", "abstract": "How do we know if a particular medical intervention actually works better than the alternatives for a given condition and outcome? Ideally one would consult all available evidence from relevant trials that have been conducted to answer this question. Unfortunately, such results are primarily disseminated in natural language articles that describe the conduct and results of clinical trials. This imposes substantial burden on physicians and other domain experts trying to make sense of the evidence. In this talk I will discuss work on designing tasks, corpora, and models that aim to realize natural language technologies that can extract key attributes of clinical trials from articles describing them, and infer the reported findings regarding these. The hope is to use such methods to help domain experts (such as physicians) access and make sense of unstructured biomedical evidence.  More specifically, I will discuss models to automatically extract trial population characteristics (e.g., conditions), interventions/comparators (treatments), and outcomes studied in a given clinical trial; together these \"PICO\" elements compose well-formed clinical questions. I will then present ongoing work on corpora and models for inferring the comparative effectiveness of a given treatment, as compared to a specified comparator, and with respect to a particular outcome of interest. If successfully realized (a big if), such models would effectively facilitate real-time clinical question answering over reports of clinical trials, in turn enabling evidence-based care", "bio": "Byron Wallace is an assistant professor in the Khoury College of Computer Sciences at Northeastern University. He holds a PhD in Computer Science from Tufts University, where he was advised by Carla Brodley. He has previously held faculty positions at the University of Texas at Austin and at Brown University. His research is in machine learning and natural language processing, with an emphasis on their application in health informatics.  Wallace's work has been supported by grants from the National Science Foundation (including a CAREER award), the National Institutes for Health, and the Army Research Office. He won the Tufts University 2012 Outstanding Graduate Researcher award, and his thesis work was recognized as The Runner Up for the 2013 ACM Special Interest Group on Knowledge Discovery and Data Mining (SIG KDD) Dissertation Award. He co-authored the winning submission for the Health Care Data Analytics Challenge at the 2015 IEEE International Conference on Healthcare Informatics, and co-authored the 2017 Distinguished Clinical Research Informatics Paper Award winner at the American Medical Informatics Association Joint Summits on Translational Sciences. He also received the 2018 Early Career Award from the Society for Research Synthesis.", "area": "NLP, Healthcare", "key": "ByronWallace", "prettyDate": "September 26"}, {"semester": "Fall", "year": "2019", "date": "2019-09-19", "speaker": "Yoon Kim", "website": "", "title": "Neural Grammar Induction", "affiliation": "Harvard University", "sponsor": "Oracle Labs", "video": "", "abstract": "Grammar induction is the task of inducing hierarchical syntactic structure from observed sentences alone. It is a longstanding problem in AI/NLP with potential scientific implications for understanding human language acquisition and engineering implications for improving machine learning systems. In this talk, I will discuss two recent works on unsupervised grammar induction with neural networks: (1) a method for learning a good generative model of language (i.e. language model) while at the same time inducing linguistically meaningful tree structures; (2) an approach to learning non-context free grammars by revisiting and extending the classical approach to grammar induction with probabilistic context-free grammars.", "bio": "Yoon Kim is a fifth-year Ph.D. candidate in computer science at Harvard University. He is advised by Alexander Rush. He is supported by a Google Fellowship.", "area": "NLP", "key": "YoonKim", "prettyDate": "September 19"}, {"semester": "Fall", "year": "2019", "date": "2019-09-12", "speaker": "Ehimwenma Nosakhare", "website": "", "title": "Probabilistic Latent Variable Modeling for Predicting Future Well-Being and Assessing Behavioral Influences on Stress", "affiliation": "Microsoft NERD", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=KiAtYSRmVog", "abstract": "Health research has an increasing focus on promoting well-being and positive mental health, to prevent disease and to more effectively treat disorders. The availability of rich multi-modal datasets and advances in machine learning methods are now enabling data science research to begin to objectively assess well-being. However, most existing studies focus on detecting the current state or predicting the future state of well-being using stand-alone health behaviors. There is a need for methods that can handle a complex combination of health behaviors, as arise in real-world data. Building on our previous work where we predict future well-being, in this talk, I'll present a framework to 1) map multi-modal messy data collected in the \"wild\" to meaningful feature representations of health behavior, 2) uncover latent patterns comprising multiple health behaviors that best predict well-being, and 3) propose how these patterns may be used to recommend healthy behaviors to participants. We show how to use supervised latent Dirichlet allocation (sLDA) to model the observed behaviors, and we apply variational inference to uncover the latent patterns. Implementing and evaluating the model on 5,397 days of data from a group of 244 college students, we find that these latent patterns are indeed predictive of self-reported stress, one of the largest components affecting well-being. We investigate the modifiable behaviors present in these patterns and uncover some ways in which the factors work together to influence well-being. This work contributes a new method using objective data analysis to help individuals monitor their well-being using real-world measurements. Insights from this study advance scientific knowledge on how combinations of daily modifiable human behaviors relate to human well-being.", "bio": "Ehi Nosakhare is an AI Data Scientist at Microsoft's New England Research and Development Center (NERD). She designs, develops and leads the implementation of machine learning solutions in application projects for Microsoft's products and services. In August 2018, she earned her Ph.D. in Electrical Engineering and Computer Science (EECS) from the Massachusetts Institute of Technology (MIT), Cambridge, MA. Her PhD research focused on probabilistic latent variable models and applying them to understand subjective well-being. She is generally interested in developing interpretable ML models and using these models to solve real world problems, as a result, she is curious about the ethical implications of AI/ML. Ehi got her S.M. in EECS from MIT, and graduated with a B.Sc. in Electrical Engineering, summa cum laude, from Howard University, Washington DC. As a student, she completed internships at Microsoft and IBM T. J. Watson Research Center. She is a recipient of a best paper award at the NeurIPS ML for Healthcare Workshop. In 2017, she was an organizer for the Women in Machine Learning (WiML) workshop, co-located with NeurIPS. Ehi has been honored as a Tau Beta Pi Scholar and Fellow. In her spare time, she enjoys reading and re-learning to play the cello.  ", "area": "Healthcare", "key": "EhimwenmaNosakhare", "prettyDate": "September 12"}, {"semester": "Spring", "year": "2019", "date": "2019-04-25", "speaker": "Stephen Roller", "website": "https://research.fb.com/people/roller-stephen/", "title": "ParlAI and Open-Domain Dialogue Research", "affiliation": "FAIR, NY", "sponsor": "Oracle Labs", "video": "", "abstract": "We present ParlAI (pronounced \"parley\"), an all-in-one dialogue and chatbot research platform. ParlAI provides tools for all aspects of conversational research, including allowing one to develop novel models; train and test models on a wide variety of existing datasets; compare to standard baselines; collect rich new datasets and conduct human evaluations using Mechanical Turk, and deploy models to users over Facebook Messenger. We present two research projects built using ParlAI. The first paper we present, \"What Makes a Good Conversation?\", compares two methods for controllable text generation in neural sequence models, and applies them to chit chat. We consider four controllable variables for text, and provide a detailed analysis of their effects on high-level human judgements of conversational aspects. We show that by controlling combinations of these variables, our models demonstrate clear improvements in human quality judgements. The second paper we present, \"The Wizard of Wikipedia\", considers the expectation of users that chatbots should exhibit strong, open-domain factual world knowledge. We present a new dataset of conversations which contains explicit groundings in facts from Wikipedia. We propose novel models for integrating knowledge into conversations, and compare to standard \"generate and hope\" neural models. We show our models exhibit the ability to recall and incorporate factual knowledge, even when discussing previously unseen topics.", "bio": "Stephen Roller is a Research Engineer at Facebook AI Research. His research focuses primarily on generation in neural dialogue agents. Before joining FAIR, Stephen completed his PhD at the University of Texas at Austin under the supervision of Katrin Erk, where his research focused primarily on hypernymy and lexical entailment. Stephen additionally completed part of studies as a visiting PhD student at the University of Stuttgart, where he researched multimodal lexical semantics under the supervision of Sabine Schulte im Walde.", "area": "NLP", "key": "StephenRoller", "prettyDate": "April 25"}, {"semester": "Spring", "year": "2019", "date": "2019-04-18", "speaker": "Dylan Foster", "website": "https://dylanfoster.net/", "title": "Logistic Regression: The Importance of Being Improper", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=WX1X0g8klIk", "abstract": "Logistic regression is a fundamental task in machine learning and statistics. For the simple case of linear models, Hazan et al. (2014) showed that any logistic regression algorithm that estimates model weights from samples must exhibit exponential dependence on the weight magnitude. As an alternative, we explore a counterintuitive technique called improper learning, whereby one estimates a linear model by fitting a non-linear model. Past success stories for improper learning have focused on cases where it can improve computational complexity. Surprisingly, we show that for sample complexity (number of examples needed to achieve a desired accuracy level), improper learning leads to a doubly-exponential improvement in dependence on weight magnitude over estimation of model weights, and more broadly over any so-called \"proper\" learning algorithm. This provides a positive resolution to a COLT 2012 open problem of McMahan and Streeter. As a consequence of this improvement, we also resolve two open problems on the sample complexity of boosting and bandit multi-class classification.", "bio": "Dylan Foster is a postdoctoral researcher at the MIT Institute for Foundations of Data Science. In 2018 he received his PhD in computer science at Cornell University, advised by Karthik Sridharan. His research focuses on theory for machine learning in real-world settings. He is particularly interested in all aspects of generalization theory and related algorithmic questions, particularly as it applies to interactive learning, deep learning, and non-convex optimization. Dylan previously received his BS and MS in Electrical Engineering from USC in 2014. He has received awards including the NDSEG PhD fellowship, Facebook PhD fellowship, and best student paper award at COLT 2018.", "area": "ML Theory", "key": "DylanFoster", "prettyDate": "April 18"}, {"semester": "Spring", "year": "2019", "date": "2019-04-11", "speaker": "Christoph Riedl", "website": "https://christophriedl.net/", "title": "Quantifying Reputation and Success in Art", "affiliation": "Northeastern University", "sponsor": "Oracle Labs", "video": "", "abstract": "In areas of human activity where performance is difficult to quantify in an objective fashion, reputation and networks of influence play a key role in determining access to resources and rewards. To understand the role of these factors, we reconstructed the exhibition history of half a million artists, mapping out the co-exhibition network that captures the movement of art between institutions. Centrality within this network captured institutional prestige, allowing us to explore the career trajectory of individual artists in terms of access to coveted institutions. Early access to prestigious central institutions offered life-long access to high-prestige venues and reduced dropout rate. By contrast, starting at the network periphery resulted in a high dropout rate, limiting access to central institutions. A Markov model predicts the career trajectory of individual artists and documents the strong path and history dependence of valuation in art.", "bio": "Christoph Riedl is assistant professor for Information Systems at the D'Amore-McKim School of Business at Northeastern University. He holds a joint appointment with the Khoury College of Computer Sciences and is a core faculty member at the Network Science Institute. He is a fellow at the Institute for Quantitative Social Science (IQSS) at Harvard. He is recipient of a Young Investigator Award (YIP) from the Army Research Office (ARO) for his work on social networks in collaborative decision-making. Before joining Northeastern University he was a post-doctoral fellow at Harvard Business School and IQSS. He received a PhD in Information Systems from Technische Universitat Munchen (TUM), Germany in 2011, a MSc in Information Systems in 2007, and a BSc in Computer Science in 2006. His work has been funded by NSF, ARO, ONR, and DARPA, and has been published in leading journals including Science, Organization Science, Management Science, Information Systems Research, Academy of Management Discoveries, and the Journal of the Royal Society Interface.", "area": "Creative ML", "key": "ChristophRiedl", "prettyDate": "April 11"}, {"semester": "Spring", "year": "2019", "date": "2019-04-04", "speaker": "Alexander Rush", "website": "http://nlp.seas.harvard.edu/rush.html", "title": "Controllable Text Generation with Deep Latent-Variable Models", "affiliation": "Harvard University", "sponsor": "Oracle Labs", "video": "", "abstract": "Progress in deep learning has led to optimism for automatic text generation. Yet state-of-the-art systems still predict inaccurate output on a non-trivial percentage of examples. Lack of user control to correct these issues makes it difficult to deploy these models in real applications. In this talk, I will argue that discrete latent-variable models provide a natural declarative framework for more controllable text models. I will present two recent works exploring this theme: (1) a method for learning neural template models that can be adjusted directly by users; (2) a variational approach to soft attention that learns alignment as a latent variable. I will end by discussing research challenges for making it easy to design and fit these models for large scale applications.", "bio": "Alexander \"Sasha\" Rush is an Assistant Professor at Harvard University, where he studies natural language processing and machine learning. Sasha received his PhD from MIT supervised by Michael Collins and was a postdoc at Facebook NY under Yann LeCun. His group supports open-source development, running several projects including OpenNMT. His research has received several best paper awards at NLP conferences, an NSF Career award, and faculty awards from Google, Facebook, and others. He is currently the senior program chair of ICLR 2019.", "area": "NLP", "key": "AlexanderRush", "prettyDate": "April 04"}, {"semester": "Spring", "year": "2019", "date": "2019-04-02", "speaker": "Swabha Swayampdipta", "website": "http://swabhs.com/", "title": "Learning Challenges in Natural Language Processing", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "", "abstract": "As the availability of data for language learning grows, the role of linguistic structure is under scrutiny. At the same time, it is imperative to closely inspect patterns in data which might present loopholes for models to obtain high performance on benchmarks. In a two-part talk, I will address each of these challenges.| First, I will introduce the paradigm of scaffolded learning. Scaffolds enable us to leverage inductive biases from one structural source for prediction of a different, but related structure, using only as much supervision as is necessary. We show that the resulting representations achieve improved performance across a range of tasks, indicating that linguistic structure remains beneficial even with powerful deep learning architectures. In the second part of the talk, I will showcase some of the properties exhibited by NLP models in large data regimes. Even as these models report excellent performance, sometimes claimed to beat humans, a closer look reveals that predictions are not a result of complex reasoning, and the task is not being completed in a generalizable way. Instead, this success can be largely attributed to exploitation of some artifacts of annotation in the datasets. I will discuss some questions our finding raises, as well as directions for future work.", "bio": "Swabha Swayamdipta is a PhD candidate at the Language Technologies Institute at Carnegie Mellon University (currently a visiting student at University of Washington). She works with Noah Smith and Chris Dyer on developing efficient algorithms for linguistic structured prediction, with a focus on incorporating syntactic inductive biases. Prior to joining her PhD program, she earned a Masters degree from Columbia University. She has done research internships at Google AI, New York and at Allen Institute of Artificial Intelligence in Seattle.", "area": "NLP", "key": "SwabhaSwayampdipta", "prettyDate": "April 02"}, {"semester": "Spring", "year": "2019", "date": "2019-03-28", "speaker": "Ishan Misra", "website": "https://imisra.github.io/", "title": "Scaling Self-supervised Visual Representation Learning", "affiliation": "Facebook AI Research, NY", "sponsor": "Oracle Labs", "video": "", "abstract": "Self-supervised learning aims to learn representations from the data itself without explicit manual supervision. Existing efforts ignore a crucial aspect of self-supervised learning - the ability to scale to large amount of data because self-supervision requires no manual labels. In this work, we revisit this principle and scale two popular self-supervised approaches to 100 million images. Scaling these methods also provides many interesting insights into the limitations of current self-supervised techniques and evaluations. We conclude that current self-supervised methods are not complex enough to take full advantage of large scale data and do not seem to learn effective high level semantic representations. Finally, we show how scaling current self-supervised methods provides state-of-the-art results that sometimes match or surpass supervised representations on tasks such as object detection, surface normal estimation and visual navigation.", "bio": "Ishan is a Research Scientist at Facebook AI Research. He graduated from Carnegie Mellon University where his PhD thesis was titled \"Visual Learning with Minimal Human Supervision\" and got the Runner Up SCS Distinguished Dissertation Award. This work was about learning recognition models with minimal supervision by exploring structure and biases in the labels (multi-task), classifiers (meta learning) and data (self supervision). His current research interests are in self supervised approaches, understanding vision and language models, and in compositional models for small sample learning.", "area": "Vision", "key": "IshanMisra", "prettyDate": "March 28"}, {"semester": "Spring", "year": "2019", "date": "2019-03-07", "speaker": "Alex Gittens", "website": "http://www.cs.rpi.edu/~gittea/", "title": "Intelligent Randomized Algorithms for the Low CP-Rank Tensor Approximation Problem", "affiliation": "Rensselaer Polytechnic Institute", "sponsor": "Oracle Labs", "video": "", "abstract": "In the context of numerical linear algebra algorithms, where it is natural to sacrifice accuracy in return for quicker computation of solutions whose errors are only slightly larger than optimal, the time-accuracy tradeoff of randomized sketching has been well-characterized. Algorithms such as Blendenpik and LSRN have shown that carefully designed randomized algorithms can outperform industry standard linear algebra codes such as those provided in LAPACK. For numerical tensor algorithms, where the size of problems grow exponentially with the order of the tensor, it is even more desirable to use randomization. However, in this setting, the time-accuracy tradeoff of randomized sketching is more difficult to understand and exploit, as: (1) in the first place, tensor problems are non-convex, (2) the properties of the data change from iteration to iteration, and (3) straightforward applications of standard results on randomized sketching allow for the error to increase from iteration to iteration. On the other hand, the iterative nature of such algorithms opens up the opportunity to learn how to sketch more accurately in an online manner. In this talk we consider the problem of speeding up the computation of low CP-rank (canonical polyadic) approximations of tensors through regularized sketching. We establish for the first time a sublinear convergence rate to approximate critical points of the objective under standard conditions, and further provide algorithms that adaptively select the sketching and regularization rates.", "bio": "Alex Gittens is an assistant professor of computer science at Rensselaer Polytechnic Institute. He obtained his PhD in applied mathematics from CalTech in 2013, and BSes in mathematics and electrical engineering from the University of Houston. After his PhD, he joined the eBay machine learning research group, then the AMPLab (now the RISELab) at UC Berkeley, before joining RPI. His research interests lie at the intersection of randomized linear algebra and large-scale machine learning, in particular encompassing nonlinear and multilinear low-rank approximations; sketching for nonlinear and multilinear problems; and scalable and data-dependent kernel learning.", "area": "ML Theory", "key": "AlexGittens", "prettyDate": "March 07"}, {"semester": "Spring", "year": "2019", "date": "2019-02-28", "speaker": "Farhad Pourkamali Anaraki", "website": "https://www.uml.edu/sciences/computer-science/faculty/pourkamali-anaraki-farhad.aspx", "title": "Scalable and Robust Sparse Subspace Clustering", "affiliation": "UMass Lowell", "sponsor": "Oracle Labs", "video": "", "abstract": "Sparse subspace clustering (SSC) is a popular method in machine learning and computer vision for clustering high-dimensional data points that lie near a union of low-dimensional linear or affine subspaces. Using a two-step approach, the first step involves representing each data point as a linear combination of all other data points, so-called self-expressiveness property, to form an undirected similarity graph. Spectral clustering is then applied to produce the final segmentation and infer the underlying subspaces. The sparse optimization program in the first step of SSC is typically solved by the alternating direction method of multipliers (ADMM) that scales cubically with the number of data points. In addition, the process of optimal parameter selection for ADMM requires a significantly increased amount of computational time. Orthogonal matching pursuit (OMP) has been used as a more efficient alternative; however, OMP is incapable of handling affine subspaces and the choice of sparsity parameter notably impacts the accuracy of SSC.", "bio": "Farhad Pourkamali Anaraki is an Assistant Professor of Computer Science at UMass Lowell. He received his PhD from University of Colorado Boulder under the supervision of Prof. Stephen Becker in 2017. His current research focuses on theoretical foundations of modern data science, and developing efficient and robust machine learning algorithms. He also works on extending the use of machine learning algorithms to other domains, including \u00e5reliability analysis of critical infrastructures in Civil Engineering and advanced manufacturing in Mechanical Engineering.", "area": "ML Theory", "key": "FarhadPourkamaliAnaraki", "prettyDate": "February 28"}, {"semester": "Spring", "year": "2019", "date": "2019-02-21", "speaker": "Irene Chen", "website": "http://irenechen.net/", "title": "Why is my classifier discriminatory?", "affiliation": "MIT CSAIL", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=gbvloQN2NiA", "abstract": "Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.", "bio": "Irene Chen is a PhD student at MIT in Electrical Engineering and Computer Science in the Clinical Machine Learning Group. Her research focuses on building machine learning methods that to advance knowledge in health care and fairness. Before MIT, she received her AB/SM from Harvard in Applied Math and Computational Engineering and worked at Dropbox for two years as a Data Scientist, Machine Learning Engineer, and Chief of Staff.", "area": "Fairness", "key": "IreneChen", "prettyDate": "February 21"}, {"semester": "Spring", "year": "2019", "date": "2019-02-14", "speaker": "Patrick Verga", "website": "https://people.cs.umass.edu/~pat/", "title": "Neural Knowledge Representation and Reasoning", "affiliation": "UMass, Amherst", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=BNQLWb4V7s0", "abstract": "Making complex decisions in science, government policy, finance, and clinical treatments all require integrating and reasoning over disparate sources of information. While some decisions can be made from a single piece of evidence, others require considering information that exists outside of the current context. A long-term store of abstracted knowledge over related concepts can facilitate this type of reasoning, while also influencing interpretation as well as enhancing the acquisition of new knowledge. A symbolic graph over a fixed, human-defined schema encoding facts about entities and their relations is the predominant method of representing knowledge, but this method is brittle, lacks specificity, and is inevitably highly incomplete. On the other extreme, recent work on purely text based knowledge models lack abstractions necessary for complex reasoning. In this talk I will present a middle ground incorporating powerful neural network models with rich structured ontologies and unstructured raw text to improve the representations of entities and their relations. We first discuss our work on universal schema, a method for learning a latent schema over both existing structured resources and unstructured free text data, embedding them jointly within a shared semantic space. Next we inject additional hierarchical structure into the embedding space of concepts, resulting in more efficient statistical sharing amongst related concepts and improving accuracy in both fine-grained entity typing and linking. We then present initial work to represent knowledge in context, including a single model for extracting all entities and long-range relations simultaneously over full paragraphs while jointly linking these entities to a knowledge graph. Lastly, we propose future directions for representing knowledge in context by incorporating cognitive theories of human memory systems and discuss how these models can address longstanding shortcomings in knowledge representation.", "bio": "Patrick Verga is a final year PhD candidate in the College of Information and Computer Sciences at UMass Amherst, advised by Andrew McCallum. His research contributes to knowledge representation and reasoning, with a focus on large knowledge base construction from unstructured text, with applications to general domain, commonsense, and biomedicine. Pat previously interned at Google and the Chan Zuckerberg Initiative and received the best long paper award at EMNLP 2018. Over the past several years he has advised multiple M.S. and junior PhD students, resulting in published research in fine-grained entity typing, unsupervised parsing, and partially labeled named entity extraction. He holds M.S. and B.A degrees in computer science as well as a B.S. in neuroscience.", "area": "NLP", "key": "PatrickVerga", "prettyDate": "February 14"}, {"semester": "Spring", "year": "2019", "date": "2019-02-07", "speaker": "Alane Suhr", "website": "http://alanesuhr.com/", "title": "Modeling and Learning Agents that Understand Language in Context", "affiliation": "Cornell University", "sponsor": "Oracle Labs", "video": "", "abstract": "The meaning of a natural language utterance is influenced by the context in which it occurs, including interaction history and situated context. I will discuss two recent projects in context-dependent natural language understanding for building natural language interfaces to databases and following sequences of instructions. In the first part, I will introduce a model for mapping from natural language to executable SQL queries in an interaction. To resolve the meaning of later utterances, the system must consider the interaction history, including previous user utterances and previously-generated queries. We show how using both implicit and explicit mechanisms for making use of interaction history allows the system to effectively generate context-dependent representations. In the second part, I will describe an approach to map sequences of natural language instructions to system actions that modify an environment, focusing on learning without direct supervision on action sequences. We introduce an exploration-based learning approach that effectively learns to compose system actions to carry out user instructions in context of the environment and interaction.", "bio": "Alane Suhr is a PhD student in the Computer Science department at Cornell University, focusing on building agents that understand natural language grounded in complex interactions. She is the recipient of an AI2 Key Scientific Challenges Award and a Microsoft Research Women's Fellowship, and is a National Science Foundation Graduate Research Fellow. She has received paper awards at ACL 2017 and NAACL 2018. Alane received a Bachelor's degree in Computer Science and Engineering from Ohio State University in 2016.", "area": "NLP", "key": "AlaneSuhr", "prettyDate": "February 07"}, {"semester": "Spring", "year": "2019", "date": "2019-01-31", "speaker": "Sarah Adel Bargal", "website": "http://cs-people.bu.edu/sbargal/", "title": "Grounding Deep Models of Visual Data", "affiliation": "Boston University", "sponsor": "Oracle Labs", "video": "", "abstract": "Deep models are state-of-the-art for many computer vision tasks including object classification, action recognition, and captioning. As Artificial Intelligence systems that utilize deep models are becoming ubiquitous, it is also becoming crucial to explain why they make certain decisions: Grounding model decisions. In this talk I will present: 1) Spatial Grounding for Improving Model Classification at Training Time. We propose a guided dropout regularizer for deep networks based on the evidence of a network prediction. This approach penalizes neurons that are most relevant for model prediction. By dropping such high-saliency neurons, the network is forced to learn alternative paths in order to maintain loss minimization. We demonstrate better generalization ability, an increased utilization of network neurons, and a higher resilience to network compression. 2) Spatial Grounding for Improving Model Classification at Test Time. We propose Guided Zoom, an approach that utilizes spatial grounding to make more informed predictions at test time. Guided Zoom compares the evidence used to make a preliminary decision with the evidence of correctly classified training examples to ensure evidence/prediction consistency, otherwise refines the prediction. We demonstrate accuracy gains for fine-grained classification. 3) Spatiotemporal Grounding. We devise a formulation that simultaneously grounds evidence in space and time, in a single pass, using top-down saliency. We visualize the spatiotemporal cues that contribute to a deep recurrent neural network's classification/captioning output. Based on these spatiotemporal cues, we are able to localize segments within a video that correspond with a specific action, or phrase from a caption, without explicitly optimizing/training for these tasks.", "bio": "Sarah is a Postdoctoral Associate in the Image and Video Computing Group working with Prof. Stan Sclaroff and Prof. Kate Saenko. Sarah first joined the Image and Video Computing Group in 2013 where she then completed her PhD with Prof. Stan Sclaroff. She is a recipient of the IBM PhD Fellowship and the Hariri Graduate Fellowship. Her research interests lie in the intersection of Computer Vision and Machine Learning.", "area": "Vision", "key": "SarahAdelBargal", "prettyDate": "January 31"}, {"semester": "Fall", "year": "2018", "date": "2018-11-28", "speaker": "Alexandra Olteanu", "website": "http://www.aolteanu.com/", "title": "Social Data: Biases, Methodological Pitfalls, and Social Good Applications", "affiliation": "Microsoft Research Montr\u00e9al", "sponsor": "Oracle Labs", "video": "", "abstract": "Data-driven computational systems and studies already make assessments about the physical or mental health of individuals, or about their personality or political views, in order to drive policies, to change behaviors, to shape products and services, and for automated decision making. An important source of data for many of these systems are the ever-growing datasets of online user traces, which promise to offer captivating insights into human phenomena. Alas, some of these systems and studies conjecture that such social datasets are adequate, often as-is, for the problem at hand, with little or no scrutiny. Yet, this is rarely the case.  In this talk, we will challenge such adequacy assumptions, and cover several types of biases and limits that surface when leveraging social datasets, related to both the characteristics of these datasets, as well as of the methods for acquiring and analyzing them. I will focus on identifying, quantifying, or minimizing such risks. Understanding these risks is particularly important when tackling significant societal challenges, where the dichotomy between maximizing benefits and minimizing risks is often more palpable. Thus, I will ground our discussion in several social good applications, such as humanitarian crises, news coverage of climate change, minority issues and advocacy, hate speech, and health. I will also overview domain specific insights to showcase the potential benefits of such applications.", "bio": "Alexandra Olteanu is a computational social science and social computing researcher. Currently, she is a Postdoctoral Researcher in the Fairness, Accountability, Transparency and Ethics (FATE) Group at Microsoft Research Montr\u00e9al (though she sits with Microsoft Research NYC). Prior to joining the FATE group, she was a Social Good Fellow at the IBM T.J. Watson Research Center, NY. She is interested in how data and methodological limitations delimit what we can learn from online social traces, and how we can make the systems that leverage such data safer, fairer, and generally less biased. The problems she tackles are often motivated by existing societal challenges such as hate speech, racial discrimination, climate change, and disaster relief. Her work has won two best paper awards (WISE 2014, Eurosys' SNS workshop 2012), and has been featured in the UN OCHA's \"World Humanitarian Data and Trends\" and in popular media outlets, including The Washington Post, VentureBeat, and ZDNet. More recently, she co-authored a survey of biases and methodological pitfalls when working with online social data, and has been co-organizing several tutorials on the topic at a variety of major data mining, and web and social media conferences, including ICWSM, KDD, WSDM, WWW, and SDM. She has also served on the program committees of the main social media and web conferences, including ICWSM, WWW, WebSci, CIKM, and SIGIR, on the steering committee of the new ACM Conference on Fairness, Accountability, and Transparency (FAT*), and as the Tutorial Co-chair for ICWSM 2018 and FAT* 2018. Alexandra holds a PhD (2016) from \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland. She draws her experience from academic institutions and research labs across 5 different countries.", "area": "Fairness", "key": "AlexandraOlteanu", "prettyDate": "November 28"}, {"semester": "Fall", "year": "2018", "date": "2018-11-08", "speaker": "Subhro Roy", "website": "https://sroy9.github.io/", "title": "Towards Natural Human Robot Communication", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "Robots are becoming more and more popular with the rise of self driving cars, autonomous drones, and warehouse automation. However, they still require experts to set up the goals for the task, and are usually devoid of a high level understanding of its environment. Language can address these issues. Non expert users can seamlessly instruct robots using natural language commands. Linguistic resources can be used to extract knowledge about the world, which can be distilled into actionable intelligence. In this talk, I will describe some of our recent work in this direction. The first focuses on robust referring expression grounding, allowing users to describe commands involving objects in the environment. The second focuses on grounding high level instructions using background knowledge from WikiHow, Conceptnet and Wordnet. I will conclude by describing some of our ongoing work in acquiring commonsense knowledge for household robots.", "bio": "Subhro is a Postdoctoral Associate at the Computer Science and AI Laboratory (CSAIL) at MIT working with Prof. Nicholas Roy. His research focuses on grounding natural language instructions and commonsense knowledge acquisition; aimed towards capable service robots that interact seamlessly with humans. His research contributes towards programs funded by the US Army Research Labs and the Toyota Research Institute. Subhro obtained his Ph.D. at the University of Illinois, Urbana Champaign, advised by Prof. Dan Roth. His doctoral research focused on models for automated numeric reasoning and word problem solving. His research led to the development of several top performing word problem solvers and the MAWPS system for standardizing datasets and evaluation in the area. His work has been published in TACL, EMNLP, NAACL, AAAI, CoRL and ISER. Subhro obtained his B. Tech. degree at the Indian Institute of Technology (IIT) Kharagpur.", "area": "NLP, Vision", "key": "SubhroRoy", "prettyDate": "November 08"}, {"semester": "Fall", "year": "2018", "date": "2018-10-24", "speaker": "Ellie Pavlick", "website": "https://cs.brown.edu/people/epavlick/", "title": "Why should we care about linguistics?", "affiliation": "Brown University", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=PDi1z9sb_Z0", "abstract": "In just the past few months, a flurry of adversarial studies have pushed back on the apparent progress of neural networks, with multiple analyses suggesting that deep models of text fail to capture even basic properties of language, such as negation, word order, and compositionality. Alongside this wave of negative results, our field has stated ambitions to move beyond task-specific models and toward \"general purpose\" word, sentence, and even document embeddings. This is a tall order for the field of NLP, and, I argue, marks a significant shift in the way we approach our research. I will discuss what we can learn from the field of linguistics about the challenges of codifying all of language in a \"general purpose\" way. Then, more importantly, I will discuss what we cannot learn from linguistics. I will argue that the state-of-the-art of NLP research is operating close to the limits of what we know about natural language semantics, both within our field and outside it. I will conclude with thoughts on why this opens opportunities for NLP to advance both technology and basic science as it relates to language, and the implications for the way we should conduct empirical research.", "bio": "Ellie Pavlick is an Assistant Professor of Computer Science and Brown University and a Research Scientist at Google AI. Ellie received her PhD from University of Pennsylvania under the supervision of Chris Callison-Burch. Her current research focus is on semantics, pragmatics, and building cognitively-plausible computational models of natural language inference.", "area": "NLP", "key": "ElliePavlick", "prettyDate": "October 24"}, {"semester": "Fall", "year": "2018", "date": "2018-10-18", "speaker": "No\u00e9mie Elhadad", "website": "http://people.dbmi.columbia.edu/noemie/", "title": "Phenotyping Endometriosis through Mixed Membership Models of Self-Tracking Data", "affiliation": "Columbia University", "sponsor": "Oracle Labs", "video": "", "abstract": "Despite the impressive past and recent advances in medical sciences, there are still a host of chronic conditions which are not well understood and lack even consensus description of their signs and symptoms. Without such consensus, research for precise treatments and ultimately a cure is at a halt. Phenotyping these conditions, that is, systematically characterizing the signs, symptoms and other aspects of these conditions, is thus particularly needed. Computational phenotyping can help identify cohorts of patients at scale and identify potential sub-groups, thus generating new hypotheses for these mysterious conditions. While traditional phenotyping algorithms rely on clinical documentation and expert knowledge, phenotyping for enigmatic conditions might benefit from patient expertise as well. In this talk I will focus on one such enigmatic condition, endometriosis, a chronic condition estimated to affect 10% of women in reproductive age. I will describe approaches needed to phenotype the condition: eliciting dimensions of disease, engaging patients in self-tracking their condition, and discovering phenotypes and sub-phenotypes of endometriosis based on patients' accounts of the disease.", "bio": "Noemie Elhadad is an Associate Professor in Biomedical Informatics, affiliated with Computer Science and the Data Science Institute at Columbia University. Her research is at the intersection of computation, technology, and medicine with a focus on machine learning for healthcare and natural language processing of clinical and health texts. Her work is funded by the National Science Foundation, the National Library of Medicine, the National Cancer Institute, and the National Institute for General Medical Sciences.", "area": "Healthcare ", "key": "No\u00e9mieElhadad", "prettyDate": "October 18"}, {"semester": "Fall", "year": "2018", "date": "2018-10-11", "speaker": "Fredrik Johansson", "website": "https://www.fredjo.com/", "title": "Estimating Causal Effects from High-Dimensional Observational Data", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "Everyone wants to make better decisions. The impact of a decision on an outcome of interest is called a causal effect, and is traditionally estimated by performing randomized experiments. However, large data sources such as electronic medical records or insurance claims present opportunities to study causal effects of interventions that are difficult to evaluate through experiments. One example is the management of septic patients in the ICU. This typically involves performing several interventions in sequence, the choice of one depending on the outcome of others. Successfully evaluating the effect of these choices depends on strong assumptions, such as having adjusted for all confounding variables. While many argue that having high-dimensional data increases the likelihood of this assumption being true, it also introduces new challenges: the more variables we use for estimating effects, the less likely that patients who received different treatments are similar in all of them. In this talk, we will discuss causal effect estimation and treatment group overlap through the lens of domain adaptation and off-policy reinforcement learning. We will introduce the potential outcomes framework, classical methods for estimating causal effects, as well as new ones, tailored for working with large datasets.", "bio": "Fredrik Johansson is a postdoctoral associate in David Sontag's Clinical Machine Learning Group at MIT. He completed his Ph.D. at Chalmers University of Technology, Sweden in 2017, working on machine learning methods for network data. His current research is focused on theory and methodology for estimating causal effects and learning policies from observational data, often inspired by problems in the medical domain.", "area": "Healthcare, Causality", "key": "FredrikJohansson", "prettyDate": "October 11"}, {"semester": "Fall", "year": "2018", "date": "2018-10-04", "speaker": "Jun-Yan Zhu", "website": "https://people.csail.mit.edu/junyanz/", "title": "Learning to Generate Images", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=0jVcWgTxfTc", "abstract": "Deep learning has revolutionized the field of visual recognition. Since 2012, we witnessed an enormous jump in recognition performance on the standard benchmarks as well as many real-world applications. Meantime, many people in computer vision and graphics were wondering if deep learning can help visual synthesis. Unfortunately, it turned out that using deep neural networks to generate high-dimensional data such as images was extremely difficult. In this talk, I will discuss its main challenges and present a few end-to-end learning frameworks (e.g., pix2pix, CycleGAN, pix2pixHD) for generating and manipulating natural images. Then, I will show various applications such as generating synthetic training data (computer vision), photo manipulation and synthesis (computer graphics), converting MRIs into CT scans (medical imaging), and applications in NLP and speech synthesis. Finally, I will briefly discuss our ongoing efforts on learning to synthesize 3D textured objects and high-res videos, with the ultimate goal of recreating our visual world.", "bio": "Jun-Yan Zhu is a postdoctoral researcher at MIT CSAIL. He obtained his Ph.D. in Electrical Engineering and Computer Sciences from UC Berkeley in 2017 after spending five years at CMU and UC Berkeley. He received his B.E in Computer Sciences from Tsinghua University in 2012. His research interests are in computer vision, computer graphics, and machine learning, with the goal of building machines capable of understanding and recreating our visual world. His Ph.D. work was supported by a Facebook Fellowship. His dissertation won the 2018 ACM SIGGRAPH Outstanding Doctoral Dissertation Award from SIGGRAPH and 2017-18 David J. Sakrison Memorial Prize for outstanding doctoral research from the UC Berkeley EECS Department. He has served as a Technical Paper Committee member at SIGGRAPH Asia 2018 and a guest editor of International Journal of Computer Vision.", "area": "Vision", "key": "Jun-YanZhu", "prettyDate": "October 04"}, {"semester": "Fall", "year": "2018", "date": "2018-09-27", "speaker": "Anna Rogers", "website": "http://www.cs.uml.edu/~arogers/", "title": "What's in your embedding, and how it predicts task performance", "affiliation": "UMass Lowell", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=heKsgZSOB1Q", "abstract": "Word embeddings are the most widely used kind of distributional meaning representations in both industrial and academic NLP systems, and they can make dramatic difference in the performance of the system. However, the absence of a reliable intrinsic evaluation metric makes it hard to choose between dozens of models and their parameters. This work presents Linguistic Diagnostics (LD), a new methodology for evaluation, error analysis and development of word embedding models that is implemented in an open-source Python library. In a large-scale experiment with 14 datasets LD successfully highlights the differences in the output of GloVe and word2vec algorithms that correlate with their performance on different NLP tasks.", "bio": "Anna is a post-doctoral associate in the Computer Science Department at Text Machine lab, University of Massachusetts (Lowell). She works at the intersection of linguistics, natural language processing, and machine learning. She holds a Ph.D. degree from the Department of Language and Information Sciences at the University of Tokyo (Japan). Her current research focuses on interpretability of deep learning, evaluation of distributional meaning representations, and semantic compositionality. She also leads annotation projects for sentiment analysis and temporal reasoning. ", "area": "NLP", "key": "AnnaRogers", "prettyDate": "September 27"}, {"semester": "Fall", "year": "2018", "date": "2018-09-20", "speaker": "Maggie Makar", "website": "https://mymakar.github.io/", "title": "Spread of contagions in the presence of latent spreaders: identifying hidden culprits and learning the probability of infection", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=MhQ7iOlT4aE", "abstract": "When an infection spreads in a community, an individual's probability of becoming infected depends on both her susceptibility and exposure to the contagion through contact with others. While one often has knowledge regarding an individual's susceptibility, in many cases, whether or not an individual's contacts are contagious is unknown. We study the problem of predicting if an individual will adopt a contagion in the presence of multiple modes of infection (exposure/susceptibility) and latent neighbor influence. We present a generative probabilistic model and a variational inference method to learn the parameters of our model. Through a series of experiments on synthetic data, we measure the ability of the proposed model to identify latent spreaders, and predict the risk of infection. Applied to a real dataset of 20 thousand hospital patients, we demonstrate the utility of our model in predicting the onset of a healthcare associated infection using patient room-sharing and nurse-sharing networks. Our model outperforms existing benchmarks and provides actionable insights for the design and implementation of targeted interventions to curb the spread of the infection.", "bio": "Maggie Makar is a graduate student at CSAIL, MIT. She works on developing models and inference tools to analyze interaction data (e.g., interactions on social networks and diffusion of contagions). She focuses on untangling causal mechanisms that govern diffusion dynamics and quantifying heterogeneous effects of interventions in connected communities. She received her BA in Mathematics and Economics from the University of Massachusetts in Amherst.", "area": "Healthcare", "key": "MaggieMakar", "prettyDate": "September 20"}, {"semester": "Fall", "year": "2018", "date": "2018-09-13", "speaker": "Liping Liu", "website": "https://www.eecs.tufts.edu/~liulp/", "title": "Embedding: Choose Right Relations to Embed", "affiliation": "Tufts", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=hJ8TE5zudUw", "abstract": "Word embeddings are a widely-used tool to analyze language. Exponential family embeddings generalize the technique to other types of data by modeling the conditional probability of a target observation (a word or an item) conditioned on the elements in the context (other words or items). One challenge to fitting embedding methods is sparse data, such as a document/term matrix that contains many zeros. We develop zero-inflated embeddings to address this issue. In a zero-inflated embedding (ZIE), a zero in the data can come from an interaction to other data (i.e., an embedding) or from a separate process by which many observations are equal to zero (i.e. a probability mass at zero). Fitting a ZIE naturally down-weights the zeros and dampens their influence on the model. Another challenge is that the appear-to-be context often contains unrelated items. The embedding model considering all context elements will encode noisy co-occurrences as item relations in the embedding. We improve the quality of the embedding representations by choosing a subset of context elements for the embedding model. We develop a probabilistic attention model and use amortized variational inference to automatically choose this subset. ", "bio": "Liping Liu holds the position of \"The Schwartz Family Assistant Professor'' at Tufts University. His research interests include variational inference, generative models, and embedding models. Prior to joining Tufts, Liu worked as a postdoctoral associate at Columbia University. Advised by Prof. David Blei, he worked on probabilistic embedding models. He earned his doctorate degree at Oregon State University, where he studied probabilistic models and applied these techniques to ecology studies. He also has industry experiences at IBM T.J. Watson Research and Alibaba. He is a reviewer for main machine learning conferences and journals, such as ICML, NIPS, ICLR, AISTATS, JMLR, and TPAMI.", "area": "ML Theory, NLP", "key": "LipingLiu", "prettyDate": "September 13"}, {"semester": "Spring", "year": "2018", "date": "2018-04-26", "speaker": "Peter Yu", "website": "https://people.csail.mit.edu/peterkty/", "title": "Robot Perception for Manipulation", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "Our team (MIT MCube Lab) participated in Amazon Robotics Challenge (ARC) in 2015 - 2017, and won the stowing task in 2017. The challenge was to develop a fully autonomous system to pick and place products in a warehouse setting, where various products may coexist inside a single bin. Robots are still far from achieving human speed, flexibility, and reliability. In the first half of the talk, I will describe our approach to the ARC, list the lessons we have learned, and then propose our wish list regarding technologies that will be useful for developing similar systems in the future.  One major item in the wish list is to exploit physics and contact sensing in the perception system, where vision usually plays a big role but is still insufficient in practice. This can be due to occlusions, inaccurate models, ambiguous appearances, etc. I will spend the second half of the talk on our effort on using tactile sensing to estimate the pose of an object in realtime. I will draw the connections between our problem and mobile robot localization problem and show how we can apply frameworks developed in the localization community. Our results show that incorporating extra information can improve the accuracy from vision alone. Moreover, even when visual cues are temporarily missing, our system can still reason about the object state during manipulation. ", "bio": "Peter K.T. Yu received the degrees of B.S. in Computer Science from National Chiao-Tung University, Hsinchu, Taiwan, in 2010, and M.S. in Computer Science from National Taiwan University, Taipei, Taiwan, in 2012. He is currently a Ph.D. candidate of Electrical Engineering and Computer Science at Massachusetts Institute of Technology under the supervision of Prof. Alberto Rodriguez in the Manipulation and Mechanisms Lab. He focuses on state estimation involving contact to enable reactive control in contact manipulation tasks.", "area": "Robotics", "key": "PeterYu", "prettyDate": "April 26"}, {"semester": "Spring", "year": "2018", "date": "2018-04-19", "speaker": "Daqing Yi", "website": "http://info.dqyi.org/", "title": "Bridging probabilistic inference and motion planning with Markov Chain Monte Carlo", "affiliation": "UW", "sponsor": "Oracle Labs", "video": "", "abstract": "Probabilistic models have been powerful tools in modeling problems in artificial intelligence. It encodes uncertain/unknown components into stochastic substructure that works with deterministic substructure in inference problems. Markov Chain Monte Carlo (MCMC) methods follow simple designs and efficiently generate random samples that approximate a target distribution. It can provide answers to the stochastic substructure in an inference problem, which inspires us to introduce MCMC to motion planning problems.  In this talk, I will describe informed sampling methods that use MCMC in solving optimal kinodynamic motion-planning problems. Our proposed MCMC approach efficiently samples from an informed set, especially when the dimension is high and the volume of informed set gradually decreases. I will also describe how we introduce MCMC methods by directly sampling over \u201cunknown\u201d Pareto fronts in trajectory spaces. The sampled trajectories gradually converge to Pareto optimal solutions of a multi-objective motion planning problem. ", "bio": "Daqing Yi is a postdoctoral researcher working with Prof. Siddhartha Srinivasa in the Personal Robotics Lab at the University of Washington. He received his Ph.D. in Computer Science under the supervision of Prof. Michael Goodrich at Brigham Young University. He works at the intersection of robotics and interactive machine intelligence. He focuses on algorithms that bootstrap robot understanding from interaction with humans, and efficiently generate robust actions in collaborating with humans. He has received a Best Conference Paper Award from the IEEE International Conference on System, Man, and Cybernetics.", "area": "Robotics", "key": "DaqingYi", "prettyDate": "April 19"}, {"semester": "Spring", "year": "2018", "date": "2018-04-10", "speaker": "Maithra Raghu", "website": "https://maithraraghu.com/", "title": "Insights from Deep Representations", "affiliation": "Cornell", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=gCia3v5Niig", "abstract": "To continue the successes of deep learning, it becomes increasingly important to better understand the phenomena exhibited by these models, ideally through a combination of systematic experiments and theory. Central to this challenge is a better understanding of deep representations. In this talk I discuss some of our work addressing questions in this space. I overview our development of measures of neural network expressivity, and quantify and empirically measure the effect of network depth and width on the latent representations. I then describe adapting Canonical Correlation Analysis (SVCCA) as a tool to directly compare latent representations, across layers, training steps, and even different networks. The results show differences in per-layer convergence and also help identify parts of the representation critical to the task. Finally, I introduce a new testbed of environments for Deep Reinforcement Learning that lets us study different RL algorithms, single agent, multiagent and self play settings, and evaluate generalization in a systematic way. ", "bio": "Maithra Raghu is a PhD student at Cornell, working with Jon Kleinberg, and a research resident at Google Brain. Her research interests are broadly in developing a better understanding of latent representations learned by deep neural networks, and using these insights to help guide new improvements. ", "area": "RL", "key": "MaithraRaghu", "prettyDate": "April 10"}, {"semester": "Spring", "year": "2018", "date": "2018-03-29", "speaker": "Maja Rudolph", "website": "http://maja-rita-rudolph.com/", "title": "Exponential Family Embeddings", "affiliation": "Columbia", "sponsor": "Oracle Labs", "video": "", "abstract": "Word embeddings are a powerful approach for capturing semantic similarity among terms in a vocabulary. Exponential family embeddings extend the idea of word embeddings to other types of high-dimensional data such as count data from a recommendation system or real-valued data from neural recordings. Exponential family embeddings have three ingredients; embeddings as latent variables, a predefined conditioning set for each observation called the context, and a conditional likelihood from the exponential family. The embeddings are inferred with a scalable algorithm based on stochastic gradient descent. In this talk, I discuss three highlights of the exponential family embeddings model class: (A) The approximations used for existing methods such as word2vec can be understood as a biased stochastic gradients procedure on a specific type of exponential family embedding model. (B) By choosing different likelihoods from the exponential family we can generalize the task of learning distributed representations to different application domains. (C) Finally, the probabilistic modeling perspective allows us to incorporate structure and domain knowledge in the latent space. With dynamic embeddings, we can study how word usage changes over time and structured embeddings allow us to learn embeddings that vary across related groups of data. Key to the success of our method is that the groups share statistical information and we develop three sharing strategies: dynamic modeling, hierarchical modeling, and amortization.", "bio": "As a computer science PhD student at Columbia University, Maja Rudolph studies probabilistic modeling and approximate inference. Together with her advisor David Blei, she works on embedding models and explores how they can be used to find rich, interpretable structure in large data sets. In 2013, she obtained a BS in mathematics from MIT. www.maja-rita-rudolph.com", "area": "NLP", "key": "MajaRudolph", "prettyDate": "March 29"}, {"semester": "Spring", "year": "2018", "date": "2018-03-22", "speaker": "Phil Thomas", "website": "https://people.cs.umass.edu/~pthomas/", "title": "New and Old Concentration Inequalities", "affiliation": "UMass", "sponsor": "Oracle Labs", "video": "", "abstract": "In this talk I will review Hoeffding's inequality before presenting some other old and new concentration inequalities, including a strict improvement on Hoeffding's inequality (for identically distributed random variables) and a concentration inequality for conditional value at risk (CVaR).", "bio": "I study a branch of artificial intelligence (AI) called reinforcement learning (RL). I am currently co-directing the Autonomous Learning Lab (ALL) at UMass Amherst with Sridhar Mahadevan. Before that I worked as a postdoc for Emma Brunskill at CMU. I completed my Ph.D. in computer science at UMass Amherst in 2015, where Andrew Barto was my adviser. I completed my B.S. and M.S. in computer science at CWRU in 2008 and 2009, where Michael Branicky was my adviser. Before that, in high school, I was introduced to computer science and mentored by David Kosbie.", "area": "RL", "key": "PhilThomas", "prettyDate": "March 22"}, {"semester": "Spring", "year": "2018", "date": "2018-03-08", "speaker": "Jerry Li", "website": "https://jerryzli.github.io/", "title": "Mixture Models, Robustness, and Sum-of-Squares Proofs", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "We use the Sum of Squares (SoS) method to develop a new efficient algorithm for clustering and mean estimation in well-separated high-dimensional mixture models, substantially improving upon the statistical guarantees achieved by previous efficient algorithms. In particular, we study mixtures of k distributions, where every pair of distributions has means separated by at least k^epsilon for any epsilon > 0. In the special case of spherical Gaussian mixtures, we give a k^O(1/epsilon^2)-time algorithm that learns the means of the components in the mixture and accurately clusters samples from the mixture. This is the first algorithm to improve on greedy (\u201csingle-linkage\u201d) and spectral clustering, breaking a long-standing barrier for efficient algorithms at separation k^1/4.  Our techniques are based on adapting algorithmic ideas from robust statistics, and are potentially of independent interest. Our main algorithm for learning mixture models provides an entirely SoS interpretation of the convex programming framework of [Diakonikolas et al, FOCS 16]. We show that many of the proofs from that paper can be replaced with much simpler proofs using only basic concentration and Holder's inequality, which allows us to approach this problem via SoS. As a corollary of this, we also obtain improved rates for robust mean estimation in certain regimes.  Joint work with Sam Hopkins, Cornell.", "bio": "Jerry Li is a Ph.D student in CSAIL, working with Ankur Moitra. His main research interests are in developing theoretically sound machine learning algorithms for real world modern systems. So far this has lead to the study of provably secure machine learning, and the study of distributed and massively parallel learning algorithms. For his research, he has been awarded a Simons Fellowship and an NSF Fellowship. ", "area": "", "key": "JerryLi", "prettyDate": "March 08"}, {"semester": "Spring", "year": "2018", "date": "2018-03-01", "speaker": "Yulia Tsvetkov", "website": "https://www.cs.cmu.edu/~ytsvetko/", "title": "TBA", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "NLP", "key": "YuliaTsvetkov", "prettyDate": "March 01"}, {"semester": "Spring", "year": "2018", "date": "2018-02-22", "speaker": "Joseph Tassarotti", "website": "http://www.cs.bc.edu/~tassarot/", "title": "Hashing and Sketching for Latent Dirichlet-Categorical Models", "affiliation": "Oracle", "sponsor": "Oracle Labs", "video": "", "abstract": "When scaling up and streaming statistical inference algorithms one immediately runs into two issues: merging distributed inference results and coping with unbounded data. In this talk, we discuss how to tackle these problems by employing feature hashing, sketching, and approximate counters to represent the model's sufficient statistics. We provide novel approximation bounds for algorithms that combine count-min sketch with approximate counters and support a merge operation. Finally, we show that combining these approximations yields a distributed inference algorithm that produces the same quality approximation, but with less than a quarter of the memory. ", "bio": "Joseph Tassarotti is a fifth year PhD student in the Computer Science Department at Carnegie Mellon University, advised by Robert Harper. His dissertation work is on the formal verification of concurrent randomized algorithms, and he is interested in the use of these algorithms in scalable machine learning systems. Joseph is the recipient of an NDSEG fellowship, and he earned an A.B. in Computer Science from Harvard College in 2013.", "area": "", "key": "JosephTassarotti", "prettyDate": "February 22"}, {"semester": "Spring", "year": "2018", "date": "2018-02-15", "speaker": "Adji Dieng", "website": "https://adjidieng.github.io/", "title": "Deep Sequence Models: Context Representation, Regularization, and Application to Language", "affiliation": "Columbia", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=0nj1hD4-9gE", "abstract": "Recurrent Neural Networks (RNNs) are the most successful models for sequential data. They have achieved state-of-the-art results in many tasks including language modeling, image and text generation, speech recognition, and machine translation. Despite all these successes, RNNs still face some challenges: they fail to capture long-term dependencies (don't believe the myth that they do!) and they easily overfit.  The ability to capture long-term dependencies in sequential data depends on the way context is represented. Theoretically, RNNs capture all the dependencies in the sequence via the use of recurrence and parameter sharing. However practically, RNNs face optimization issues. Assumptions made to counter these optimization challenges hinder the capability of RNNs to capture long-term dependencies. On the other hand, the overfitting problem of RNNs stem from the strong dependence of the hidden units to each other.  I will talk about my research on context representation and regularization for RNNs. First, I will make the case that in the context of language, topic models are very effective at representing context and can be used jointly with RNNs to facilitate learning and capture long-term dependencies. Second, I will discuss our new proposed method to regularize RNNs called NOISIN. NOISIN relies on the concept of unbiased noise injection in the hidden units of RNNs to reduce co-adaptation. It significantly improves the generalization capabilities of existing RNN-based models including RNNs with dropout. ", "bio": "Adji Bousso Dieng is a PhD student at Columbia University where she works with David Blei and John Paisley. Her work at Columbia is about combining probabilistic graphical modeling and deep learning to design better sequence models. She develops these models within the framework of variational inference which enables efficient and scalable learning. Her hope is that her research can be applied to many real world applications particularly to natural language understanding.  Prior to joining Columbia, she worked as a Junior Professional Associate at the World Bank. She did her undergraduate training in France where she attended Lycee Henri IV and Telecom ParisTech---France's Grandes Ecoles system. She holds a Diplome d'Ingenieur from Telecom ParisTech and spent the third year of Telecom ParisTech's curriculum at Cornell University where she earned a Master in Statistics.  Learn more on her homepage http://stat.columbia.edu/~diengadji/ ", "area": "", "key": "AdjiDieng", "prettyDate": "February 15"}, {"semester": "Spring", "year": "2018", "date": "2018-02-08", "speaker": "Bharath Hariharan", "website": "http://home.bharathh.info/", "title": "Visual recognition beyond large labeled training sets", "affiliation": "Cornell", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=rBrstWqWzbc", "abstract": "The performance of recognition systems has grown by leaps and bounds these last 5 years. However, modern recognition systems still require thousands of examples per class to train. Furthermore, expanding the capabilities of the system by introducing new visual concepts again requires collecting thousands of examples for the new concept. In contrast, humans are known to quickly learn new visual concepts from as few as 1 example, and indeed require very little labeled data to build their powerful visual systems from scratch. The requirement for large training sets also makes it infeasible to use current machine vision systems for rare or hard-to-annotate visual concepts or new imaging modalities.  I will talk about some of our work on reducing this need for large labeled training sets. I will describe novel loss functions for training convolutional network-based feature representations so that new concepts can be learned from a few examples, and ways of hallucinating additional examples for data-starved classes. I will also discuss our attempt to learn feature representations without any labeled data by leveraging motion-based grouping cues. I will end with a discussion of where we are and thoughts on the way forward. ", "bio": "Bharath Hariharan is an assistant professor at Cornell. Before joining Cornell, he spent two years as a postdoc in Facebook AI Research after obtaining a PhD from UC Berkeley with Jitendra Malik. At Berkeley, he was the recepient of the Microsoft Research fellowship. His interests are in all things visual recognition. Of late, he has become bothered by the reliance on massive labeled datasets and the scalability of such datasets to harder problems such as visual reasoning. His current work is on building recognition systems that learn with less data and / or output a much deeper understanding of images.", "area": "Vision", "key": "BharathHariharan", "prettyDate": "February 08"}, {"semester": "Spring", "year": "2018", "date": "2018-02-01", "speaker": "Graham Neubig", "website": "http://www.phontron.com/", "title": "What Can Neural Networks Teach us about Language?", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=D0TEo_5EdWY", "abstract": "Neural networks have led to large improvements in the accuracy of natural language processing systems. These have mainly been based on supervised learning: we create linguistic annotations for a large amount of training data, and train networks to faithfully reproduce these annotations. But what if we didn't tell the neural net about explicitly, but instead *asked it what it thought* about language without injecting our prior biases? Would the neural network be able to learn from large amounts of data and confirm or discredit our existing linguistic hypotheses? Would we be able to learn linguistic information from lower-resourced languages where this information has not been annotated? In this talk I will discuss methods for unsupervised learning of linguistic information using neural networks that attempt to answer these questions. I will also explain briefly about automatic mini-batching, a computational method (implemented in the DyNet neural network toolkit), which greatly speeds large-scale experiments with complicated network structures needed for this type of unsupervised learning.", "bio": "Graham Neubig is an assistant professor at the Language Technologies Institute of Carnegie Mellon University. His work focuses on natural language processing, specifically multi-lingual models that work in many different languages, and natural language interfaces that allow humans to communicate with computers in their own language. Much of this work relies on machine learning to create these systems from data, and he is also active in developing methods and algorithms for machine learning over natural language data. He publishes regularly in the top venues in natural language processing, machine learning, and speech, and his work occasionally wins awards such as best papers at EMNLP, EACL, and WNMT. He is also active in developing open-source software, and is the main developer of the DyNet neural network toolkit.", "area": "NLP", "key": "GrahamNeubig", "prettyDate": "February 01"}, {"semester": "Fall", "year": "2017", "date": "2017-11-30", "speaker": "Rajesh Ranganath", "website": "https://cims.nyu.edu/~rajeshr/", "title": "Black Box Variational Inference: Scalable, Generic Bayesian Computation and its Applications", "affiliation": "NYU", "sponsor": "Oracle Labs", "video": "", "abstract": "Probabilistic generative models are robust to noise, uncover unseen patterns, and make predictions about the future. Probabilistic generative models posit hidden structure to describe data. They have addressed problems in neuroscience, astrophysics, genetics, and medicine. The main computational challenge is computing the hidden structure given the data --- posterior inference. For most models of interest, computing the posterior distribution requires approximations like variational inference. Classically, variational inference was feasible to deploy in only a small fraction of models. We develop black box variational inference. Black box variational inference is a variational inference algorithm that is easy to deploy on a broad class of models and has already found use in neuroscience and healthcare. The ideas around black box variational inference also facilitate new kinds of variational methods such as hierarchical variational models. Hierarchical variational models improve the approximation quality of variational inference by building higher-fidelity approximations from coarser ones. Black box variational inference opens the doors to new models and better posterior approximations. Lastly, I will discuss some of the challenges that variational methods face moving forward.", "bio": "Rajesh Ranganath is a postdoc at Columbia University's Department of Statistics and a research affiliate at MIT's Institute for Medical Engineering and Science. He will be an assistant professor at the Courant Institute of Mathematical Sciences at NYU starting January 2018. His research interests include approximate inference, model checking, Bayesian nonparametrics, and machine learning for healthcare. Rajesh recently completed his PhD at Princeton with David Blei. Before starting his PhD, Rajesh worked as a software engineer for AMA Capital Management. He obtained his BS and MS from Stanford University with Andrew Ng and Dan Jurafsky. Rajesh has won several awards and fellowships including the NDSEG graduate fellowship and the Porter Ogden Jacobus Fellowship, given to the top four doctoral students at Princeton University.", "area": "", "key": "RajeshRanganath", "prettyDate": "November 30"}, {"semester": "Fall", "year": "2017", "date": "2017-11-20", "speaker": "Claudia P\u00e9rez D\u2019Arpino", "website": "https://ai.stanford.edu/~cdarpino/", "title": "Learning How to Plan for Multi-Step Manipulation in Collaborative Robotics", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "The use of robots for complex manipulation tasks is currently challenged by the limited ability of robots to construct a rich representation of the activity at both the motion and tasks levels in ways that are both functional and apt for human-supervised execution. For instance, the operator of a remote robot would benefit from planning assistance, as opposed to the currently used method of joint-by-joint direct teleoperation. In manufacturing, robots are increasingly expected to execute manipulation tasks in shared workspace with humans, which requires the robot to be able to predict the human actions and plan around these predictions. In both cases, it is beneficial to deploy systems that are capable of learning skills from observed demonstrations, as this would enable the application of robotics by users without programming skills. However, previous work on learning from demonstrations is limited in the range of tasks that can be learned and generalized across different skills and different robots. I this talk, I present C-LEARN, a method of learning from demonstrations that supports the use of hard geometric constraints for planning multi-step functional manipulation tasks with multiple end effectors in quasi-static settings, and show the advantages of using the method in a shared autonomy framework.", "bio": "Claudia P\u00e9rez D\u2019Arpino is a PhD Candidate in the Electrical Engineering and Computer Science Department at the Massachusetts Institute of Technology, advised by Prof. Julie A. Shah in the Interactive Robotics Group since 2012. She received her degrees in Electronics Engineering (2008) and Masters in Mechatronics (2010) from the Simon Bolivar University in Caracas, Venezuela, where she served as Assistant Professor in the Electronics and Circuits Department (2010-2012) with a focus on Robotics. She participated in the DARPA Robotics Challenge with Team MIT (2012-2015). Her research at CSAIL combines machine learning and planning techniques to empower humans through the use of robotics and AI. Her PhD research centers in enabling robots to learn and create strategies for multi-step manipulation tasks by observing demonstrations, and develop efficient methods for robots to employ these skills in collaboration with humans, either for shared workspace collaboration, such as assembly in manufacturing, or for remote robot control in shared autonomy, such as emergency response scenarios. Web:http://people.csail.mit.edu/cdarpino/", "area": "", "key": "ClaudiaP\u00e9rezD\u2019Arpino", "prettyDate": "November 20"}, {"semester": "Fall", "year": "2017", "date": "2017-11-16", "speaker": "Steven Wu", "website": "https://zstevenwu.com/", "title": "A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem", "affiliation": "MSR", "sponsor": "Oracle Labs", "video": "", "abstract": "Bandit learning is characterized by the tension between long-term exploration and short-term exploitation. However, as has recently been noted, in settings in which the choices of the learning algorithm correspond to important decisions about individual people (such as criminal recidivism prediction, lending, and sequential drug trials), exploration corresponds to explicitly sacrificing the well-being of one individual for the potential future benefit of others. This raises a fairness concern. In such settings, one might like to run a \u201cgreedy\u201d algorithm, which always makes the (myopically) optimal decision for the individuals at hand \u2014 but doing this can result in a catastrophic failure to learn. In this paper, we consider the linear contextual bandit problem and revisit the performance of the greedy algorithm. We give a smoothed analysis, showing that even when contexts may be chosen by an adversary, small perturbations of the adversary\u2019s choices suffice for the algorithm to achieve \u201cno regret\u201d, perhaps (depending on the specifics of the setting) with a constant amount of initial training data. This suggests that \u201cgenerically\u201d (i.e. in slightly perturbed environments), exploration and exploitation need not be in conflict in the linear setting.", "bio": "Steven Wu is currently a Post-Doctoral Researcher at Microsoft Research in New York City, where he is a member of the Machine Learning and Algorithmic Economics groups. He will be joining the Department of Computer Science and Engineering at the University of Minnesota as an Assistant Professor starting in fall 2018. He received his Ph.D. in Computer Science from the University of Pennsylvania in 2017, under the supervision of Michael Kearns and Aaron Roth. His doctoral dissertation \u201cData Privacy Beyond Differential Privacy\u201d received the 2017 Morris and Dorothy Rubinoff Dissertation Award. His research focuses on algorithm design under different social constraints. In particular, his primary research interest is on data privacy, specifically differential privacy, where he builds tools for data analysis under the constraint of privacy preservation. His recent research also studies algorithmic fairness, especially in the context of machine learning, where he investigates how we can prevent bias and unfairness in algorithmic decision making. He examines problems in these areas using methods and models from machine learning theory, economics, optimization, and beyond.", "area": "", "key": "StevenWu", "prettyDate": "November 16"}, {"semester": "Fall", "year": "2017", "date": "2017-11-09", "speaker": "Lu Wang", "website": "http://www.ccs.neu.edu/home/luwang/", "title": "What Makes a Good Argument: Understanding and Predicting High Quality Arguments Using NLP Methods", "affiliation": "Northeastern", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=JviDF2VasLc", "abstract": "Debate and deliberation play essential roles in politics and civil discourse. While argument content and linguistic style both affect debate outcomes, limited work has been done on studying the interplay between the two. In the first part of this talk, I will present a joint model that estimates the inherent persuasive strengths of different topics, the effects of numerous linguistic features, and the interactions between the two as they affect debate audience. By experimenting with Oxford-style debates, our model predicts audience-adjudicated winners with 74% accuracy, significantly outperforming models based on linguistic features alone. We also find that winning sides employ more strong arguments (as corroborated by human judgment) and debaters all tend to shift topics to stronger ground. The model further allows us to identify the linguistic features associated with strong or weak arguments.  In the second part of my talk, I will present our recent study on retrieving diverse types of supporting arguments from relevant documents for user-specified topics. We find that human writers often use different types of arguments to promote persuasiveness, which can be characterized with different linguistic features. We then show how to leverage argument type to assist the task of supporting argument detection. I will also discuss our follow-up work on automatic argument generation. ", "bio": "Lu Wang is an Assistant Professor in College of Computer and Information Science at Northeastern University since 2015. She received her Ph.D. in Computer Science from Cornell University and her bachelor degrees in Intelligence Science and Technology and Economics from Peking University. Her research mainly focuses on designing machine learning algorithms and statistical models for natural language processing (NLP) tasks, including abstractive text summarization, language generation, argumentation mining, information extraction, and their applications in interdisciplinary subjects (e.g., computational social science). Lu and her collaborators received an outstanding short paper award at ACL 2017 and a best paper nomination award at SIGDIAL 2012. Her group's work is funded by National Science Foundation (NSF), Intelligence Advanced Research Projects Activity (IARPA), and several industry gifts (Toutiao AI Lab, and NVIDIA GPU program). More information about her research can be found at www.ccs.neu.edu/home/luwang/.", "area": "NLP", "key": "LuWang", "prettyDate": "November 09"}, {"semester": "Fall", "year": "2017", "date": "2017-11-02", "speaker": "Beomjoon Kim", "website": "https://people.csail.mit.edu/beomjoon/", "title": "Learning to Guide Task and Motion Planning by Predicting Constraints", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "In robotics, it is essential to be able to plan efficiently in high-dimensional continuous state-action spaces for long horizons. For such complex planning problems, unguided uniform sampling of actions until a path to a goal is found is hopelessly inefficient, and gradient-based approaches often fall short when the optimization manifold of a given problem is not smooth. In this talk, I will introduce two of our recent approaches for using past planning experience to learn to predict constraints for guiding a planner. In the first part, I will introduce a technique that uses generative adversarial networks and importance sampling estimation to learn an action distribution that restricts the search space to a promising region, when an input is represented with a vector. In the second part, I will discuss the limitation of a vector representation in complex robot planning settings, and propose a more suitable representation for guiding a search, called a score-space representation. With this representation, we can predict a constraint on the search space by optimizing a black-box function. We empirically show that a planner is able to find a solution more efficiently using these approaches on a various robot task and motion planning problems.", "bio": "Beomjoon Kim is a PhD student at MIT CSAIL under the supervision of Leslie Pack Kaelbling and Tomas Lozano-Perez. His recent research focuses on developing machine learning algorithms for complex robot planning problems, in which problems involve reasoning about both discrete, logical structures and continuous, geometric structures of the world. In the past, he has worked on robot learning from demonstrations and reinforcement learning. He received his MS.c from McGill University under the supervision of Joelle Pineau, and received BMath from University of Waterloo.", "area": "Robotics", "key": "BeomjoonKim", "prettyDate": "November 02"}, {"semester": "Fall", "year": "2017", "date": "2017-10-20", "speaker": "Kyunghyun Cho", "website": "http://www.kyunghyuncho.me/", "title": "Deep Learning, Where are you going?", "affiliation": "NYU", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=3B5Ty5VD-5Q", "abstract": "There are three axes along which advances in machine learning and deep learning happen. They are (1) network architectures, (2) learning algorithms and (3) spatio-temporal abstraction. In this talk, I will describe a set of research topics I've pursued in each of these axes. For network architectures, I will describe how recurrent neural networks, which were largely forgotten during 90s and early 2000s, have evolved over time and have finally become a de facto standard in machine translation. I continue on to discussing various learning paradigms, how they related to each other, and how they are combined in order to build a strong learning system. Along this line, I briefly discuss my latest research on designing a query-efficient imitation learning algorithm for autonomous driving. Lastly, I present my view on what it means to be a higher-level learning system. Under this view each and every end-to-end trainable neural network serves as a module, regardless of how they were trained, and interacts with each other in order to solve a higher-level task. I will describe my latest research on trainable decoding algorithm as a first step toward building such a framework.", "bio": "Kyunghyun Cho is an assistant professor of computer science and data science at New York University. He was a postdoctoral fellow at University of Montreal until summer 2015, and received PhD and MSc degrees from Aalto University early 2014. He tries best to find a balance among machine learning, natural language processing and life, but often fails to do so.", "area": "NLP", "key": "KyunghyunCho", "prettyDate": "October 20"}, {"semester": "Fall", "year": "2017", "date": "2017-10-12", "speaker": "Varun Jampani 2017", "website": "https://varunjampani.github.io/", "title": "Bilateral Neural Networks for Image, Video and 3D Vision", "affiliation": "Nvidia", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=6LIcXwhOrGY", "abstract": "Natural images exhibit high information correlation across pixels. Bilateral filtering provides a simple yet powerful framework for information propagation across pixels. The common use-case is to manually choose a parametric filter type, usually a Gaussian filter. We generalize the parameterization using a high-dimensional linear approximation and derive a gradient descent algorithm so the filter parameters can be learned from data. We demonstrate the use of learned bilateral filters in several applications where Gaussian bilateral filters are traditionally employed where we consistently observed improvements with filter learning. In addition, the ability to learn generic high-dimensional sparse filters allows us to stack several parallel and sequential filters like in convolutional neural networks (CNN) resulting in a new breed of neural networks which we call \u2018Bilateral Neural Networks\u2019 (BNN). We demonstrate the use of BNNs on several 2D, video and 3D vision tasks. Experiments on diverse datasets and tasks demonstrate the use BNNs for a range of vision problems.", "bio": "Varun Jampani works as a research scientist at Nvidia Research in Westford, US. He obtained his PhD at Max Planck Institute for Intelligent Systems (MPI) in T\u00fcbingen, Germany under the supervision of Prof. Peter V. Gehler. He works in the areas of machine learning and computer vision and his main research interests include probabilistic inference and neural networks. He obtained his BTech and MS from International Institute of Information Technology, Hyderabad (IIIT-H), India, where he was a gold medalist. During his studies, he did internships at Microsoft research institutes in Redmond (US), Cambridge (UK) and Cairo (Egypt); MPI, T\u00fcbingen (Germany) and; GE global research, Bangalore (India). He also worked as a volunteer teacher in Tibetan Children\u2019s Village, Dharamsala, India.", "area": "", "key": "VarunJampani2017", "prettyDate": "October 12"}, {"semester": "Fall", "year": "2017", "date": "2017-10-05", "speaker": "Francesco Orabona", "website": "http://francesco.orabona.com/", "title": "Coin Betting for Backprop without Learning Rates and More", "affiliation": "Stony Brook", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=61o-TMEcDMM", "abstract": "Deep learning methods achieve state-of-the-art performance in many application scenarios. Yet, these methods require a significant amount of hyperparameters tuning in order to achieve the best results. In particular, tuning the learning rates in the stochastic optimization process is still one of the main bottlenecks. In this talk, I will propose a new stochastic gradient descent procedure that does not require any learning rate setting. Contrary to previous methods, we do not adapt the learning rates nor we make use of the assumed curvature of the objective function. Instead, we reduce the optimization process to a game of betting on a non-stochastic coin and we propose an optimal strategy based on a generalization of Kelly betting. Moreover, this reduction can be also used for other machine learning problems. Theoretical convergence is proven for convex and quasi-convex functions and empirical evidence shows the advantage of our algorithm over popular stochastic gradient algorithms.", "bio": "Francesco Orabona is an Assistant Professor at Stony Brook University. His research interests are in the area of theoretically motivated and efficient machine learning algorithms, with emphasis on online and stochastic methods. He received the PhD degree in Electrical Engineering at the University of Genoa, in 2007. He is (co)author of more than 60 peer reviewed papers.", "area": "Optimization", "key": "FrancescoOrabona", "prettyDate": "October 05"}, {"semester": "Fall", "year": "2017", "date": "2017-09-28", "speaker": "Nika Haghtalab", "website": "https://www.cs.cornell.edu/~nika/", "title": "Oracle-efficient Online Learning and Applications to Auction Design", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "", "abstract": "We consider the fundamental problem of learning from expert advice, a.k.a online no-regret learning, where we have access to an offline optimization oracle that can be used to compute, in constant time, the best performing expert at any point in time. We consider the design of no-regret algorithms that are computationally efficient using such an oracle. We present structural properties under which we show oracle-efficient no-regret algorithms exist, even when the set of experts is exponentially large in a natural representation of the problem. Our algorithm is a generalization of the Follow-The-Perturbed-Leader algorithm of Kalai and Vempala that at every step follows the best-performing expert subject to some perturbations. Our design uses a shared source of randomness across all experts that can be efficiently implemented by using an oracle on a random modification of the history of the play at every time step.  Our second main contribution is showing that the structural properties required for our oracle-efficient online algorithm are present in a large class problems. As an example, we discuss applications of our oracle-efficient learning results to the adaptive optimization of a large class of auctions, including (1) VCG auctions with bidder-specific reserves in single-parameter settings, (2) envy-free item pricing in multi-item auctions, and (3) Myerson-like auctions for single-item settings. ", "bio": "Nika Haghtalab is a Ph.D. student at the Computer Science department of Carnegie Mellon University, co-advised by Avrim Blum and Ariel Procaccia. Her research interests include machine learning theory, computational aspects of economics, and algorithms. Nika is a recipient of the IBM and Microsoft Research Ph.D. fellowships.", "area": "ML Theory", "key": "NikaHaghtalab", "prettyDate": "September 28"}, {"semester": "Fall", "year": "2017", "date": "2017-09-21", "speaker": "Yogarshi Vyas", "website": "http://www.cs.umd.edu/~yogarshi/", "title": "Detecting Asymmetric Semantic Relations in Context : A Case-Study on Hypernymy Detection", "affiliation": "UMD", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=cEoqQQgyLuE", "abstract": "Comparing the meaning of words and understanding how they relate is a fundamental challenge in natural language understanding. In this talk, I\u2019ll introduce WHiC, a challenging testbed for detecting hypernymy, an asymmetric relation between words. While previous work has focused on detecting hypernymy between word types, we ground the meaning of words in specific contexts drawn from WordNet examples, and require predictions to be sensitive to changes in contexts. WHiC also lets us analyze different properties of two approaches of inducing vector representations of word meaning in context, allowing us to identify their strengths and weaknesses. I\u2019ll also show that such contextualized word representations also improve detection of a wider range of semantic relations in context.", "bio": "Yogarshi Vyas is a fourth year PhD student in the Department of Computer Science at the University of Maryland, College Park. His broad research interests lie in semantics, multilingual NLP, and machine translation, and the intersection of these. His current research focus is on comparing and contrasting the meaning of text in different languages using the idea of entailment as well as learning representations for multilingual data that facilitate meaningful and easy comparisons across languages. He recently won the Adam Kilgarriff Best Paper award at *SEM 2017.", "area": "NLP", "key": "YogarshiVyas", "prettyDate": "September 21"}, {"semester": "Fall", "year": "2017", "date": "2017-09-14", "speaker": "Pat Flaherty", "website": "http://people.math.umass.edu/~flaherty/?_ga=2.230150364.1118255471.1504663390-490697572.1416926222", "title": "A Nonparametric Bayesian Model for Single-cell Variant Calling", "affiliation": "UMass", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=hjnyoNZ1RQw", "abstract": "Advances in DNA sequencing technology have enabled surprising discoveries in basic science and novel diagnostics in personalized medicine. Recently, the ability to read the DNA sequence of a single cell has presented new statistical and computational challenges. We address the problem of calling single-nucleotide mutations in single-cell sequencing data. We present some results evaluating existing mutation calling algorithms on data generated from a single-cell sequence data simulator. We describe a nonparametric Bayesian generative model for combining single-cell and bulk DNA sequencing data, and we show preliminary results from this model.", "bio": "Patrick Flaherty is a Professor in the Department of Mathematics & Statistics at UMass Amherst. He received his PhD in Electrical Engineering and Computer Science from the University of California, Berkeley and he was a postdoctoral scholar at Stanford University in the Department of Biochemistry. His research focuses on scalable, statistical methods for analyzing large genomic data sets.", "area": "Bioinformatics", "key": "PatFlaherty", "prettyDate": "September 14"}, {"semester": "Fall", "year": "2017", "date": "2017-09-07", "speaker": "Dean Eckles", "website": "https://www.deaneckles.com/", "title": "Learning from many experiments using regularized instrumental variable methods: Applications to peer effects in online networks", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "https://www.youtube.com/watch?v=grDtaryIU60", "abstract": "The widespread adoption of randomized experiments (i.e. A/B tests) in the Internet industry means that there are often numerous well-powered experiments on a given product. Individual experiments are often simple \"bake-off\" evaluations of a new intervention: They allow us to estimate effects of that particular intervention on outcomes of interest, but they are often not informative about the mechanisms for these effects or what other inventions might do. We consider what else we can learn from a large set of experiments. In particular, we use many experiments to learn about the effects of the various endogenous variables (or mechanisms) via which the experiments affect outcomes. This involves treating the experiments as instrumental variables, and so this setting is similar to, but somewhat different from, \"many instrument\" settings in econometrics and biostatistics. Motivated by the distribution of experiment first-stage effects, we present and evaluate sparsity-inducing regularization methods and cross-validation for instrumental variables. Our applications are to estimating peer effects in online social networks mediated by ranking systems.  Joint work with Alex Peysakhovich (Facebook) and including additional joint work with Eytan Bakshy (Facebook) and Ren\u00e9 Kizilcec (Stanford). ", "bio": "Dean Eckles is a social scientist, statistician, and faculty at MIT. Dean is the KDD Career Development Professor in Communications and Technology, an assistant professor in the MIT Sloan School of Management, and affiliated faculty at the MIT Institute for Data, Systems & Society. He was previously a member of the Core Data Science team at Facebook. He studies how interactive technologies affect human behavior by mediating, amplifying, and directing social influence \u2014 and statistical methods to study these processes. Dean\u2019s empirical work uses large field experiments and observational studies. His research appears in the Proceedings of the National Academy of Sciences and other peer-reviewed journals and proceedings in statistics, computer science, and marketing. Dean holds degrees from Stanford University in philosophy (BA), cognitive science (BS, MS), statistics (MS), and communication (PhD).", "area": "", "key": "DeanEckles", "prettyDate": "September 07"}, {"semester": "Spring", "year": "2017", "date": "2017-06-13", "speaker": "Qiang Liu", "website": "", "title": "A Stein Variational Framework for Deep Probabilistic Modeling", "affiliation": "Dartmouth College", "sponsor": "Oracle Labs", "video": "", "abstract": "Modern AI and machine learning techniques increasingly depend on highly complex, hierarchical (deep) probabilistic models to reason with complex relations and learn to predict and act under uncertain environment. This, however, casts a significant demand for developing efficient computational methods for handling highly complex probabilistic models for which exact calculation is prohibitive. In this talk, we discuss a new framework for approximate learning and inference that combines ideas from Stein's method, an advantaged theoretical technique developed by mathematical statistician Charles Stein, with practical machine learning and statistical computation techniques such as variational inference, Monte Carlo, optimal transport and reproducing kernel Hilbert space (RKHS). Our framework provides a new foundation for probabilistic learning and reasoning and allows us to develop a host of new algorithms for a variety of challenging statistical tasks, that are significantly different from, and have critical advantages over, traditional methods. We will discuss a number of examples, including a computationally tractable goodness-of-fit test for evaluating highly complex models, a new type of approximation inference method for scalable Bayesian computation, amortized maximum likelihood training for deep generative models, and new policy gradient methods that yield better exploration using Bayesian uncertainty for deep reinforcement learning.", "bio": "Qiang Liu is an assistant professor of computer science at Dartmouth college. His research interests are in machine learning, Bayesian inference, probabilistic graphical models and deep learning. He received his Ph.D from University of California at Irvine, followed with a postdoc at MIT CSAIL.", "area": "", "key": "QiangLiu", "prettyDate": "June 13"}, {"semester": "Spring", "year": "2017", "date": "2017-05-04", "speaker": "Scott W. Linderman", "website": "", "title": "Bayesian Learning and Inference in Recurrent Switching Linear Dynamical Systems", "affiliation": "Columbia University", "sponsor": "Oracle Labs", "video": "", "abstract": "Many natural systems, such as neurons firing in the brain or basketball teams traversing a court, give rise to time series data with complex, nonlinear dynamics. We can gain insight into these systems by decomposing the data into segments that are each explained by simpler dynamic units. I will present a model class that builds on the switching linear dynamical system (SLDS), leveraging its combination of discrete and continuous latent states to discover dynamical units. Our recurrent SLDS will go one step further: by learning how transition probabilities depend on observations or continuous latent states, we will better explain switching behavior. Our key innovation is to design these recurrent SLDS models to enable P\u00f3lya-gamma auxiliary variable techniques and thus make approximate Bayesian learning and inference in these models easy, fast, and scalable.", "bio": "Scott is a postdoctoral fellow in the labs of Liam Paninski and David Blei at Columbia University. He completed his Ph.D. in Computer Science at Harvard University under the supervision of Ryan Adams and Leslie Valiant, and he received his B.S. in Electrical and Computer Engineering from Cornell University. Prior to graduate school, he worked at Microsoft as a software engineer on the Windows networking stack. His research is focused on machine learning, computational neuroscience, and the general question of how computer science and statistics can help us decipher biological computation. ", "area": "", "key": "ScottW.Linderman", "prettyDate": "May 04"}, {"semester": "Spring", "year": "2017", "date": "2017-04-26", "speaker": "Tom Williams", "website": "", "title": "Genuine Helpers: Enabling natural language capabilities for interactive robots", "affiliation": "Tufts", "sponsor": "Oracle Labs", "video": "", "abstract": "Natural language understanding and generation capabilities are crucial for natural human-like human robot interactions. This is especially true in domains such as eldercare, education, space, and search-and-rescue robotics, in which alternate interfaces or interaction techniques may be difficult for users to use due to cognitive or physical limitations. Approximately 40% of wheelchair users, for example, find it difficult or impossible to use a standard joystick, making natural language an attractive modality for interaction and control.  My research investigates how intelligent robots can communicate through natural language in realistic human-robot interaction scenarios, in which knowledge is uncertain, incomplete, and decentralized. To do so, I draw on techniques and concepts from artificial intelligence, psychology, linguistics, and philosophy, and engage in both algorithm development and empirical experimentation.  In my talk, I will present a set of cognitively inspired algorithms I have developed to allow robots to better identify the entities (e.g., objects, people, and locations) referenced in natural language by their human conversational partners, and to better infer those conversational partners\u2019 intentions, in uncertain and open worlds. I will then discuss how these algorithms have been implemented on a robotic wheelchair in order to significantly extend the state of the art of natural language enabled robot wheelchairs. ", "bio": "Tom Williams is a PhD candidate in the joint Computer Science and Cognitive Science program at Tufts University, and will be joining the faculty of Colorado School of Mines in the fall. Tom\u2019s research focuses on enabling and understanding natural language based human-robot interaction, especially as applied to assistive and search-and-rescue robotics. He previously served as a visiting researcher at the Institute for Artificial Intelligence in Bremen, Germany, and has co-organized several international workshops on human-robot interaction.", "area": "", "key": "TomWilliams", "prettyDate": "April 26"}, {"semester": "Spring", "year": "2017", "date": "2017-04-20", "speaker": "Hari Balasubramanian", "website": "", "title": "Models based on longitudinal healthcare event data", "affiliation": "UMass Amherst", "sponsor": "Oracle Labs", "video": "", "abstract": "In this presentation, we will discuss a framework for analyzing data concerning healthcare events at the individual level. These events can be of various types \u2013 outpatient, emergency room, inpatient, lab, pharmaceutical etc., each corresponding to one or more diagnoses. Each event happens on a certain day (or a certain hour) and when such data is collected over a period of time, it creates an evolving point process unique to each patient. Such a point process provides information about the intensity and diversity of encounters \u2013 how frequent and how fragmented care is across multiple settings, an issue of particular concern for patients with multiple chronic conditions. In this presentation, we provide concrete examples of such datasets and the operational implications for clinicians. We will also try to seek the audience\u2019s feedback on what machine learning techniques might be best suited to recognizing patterns in high-dimensional event sequences.", "bio": "", "area": "Dr. Hari Balasubramanian is Associate Professor of Industrial Engineering at the University of Massachusetts, Amherst. He received his doctoral degree at the Arizona State University in 2006. Dr. Balasubramanian spent two years as a Research Associate at Mayo Clinic in Rochester, Minnesota before joining the University of Massachusetts in 2008. His research interests are in operations research applied to healthcare. In 2013, Dr. Balasubramanian received a National Science Foundation CAREER award focused on healthcare delivery. ", "key": "HariBalasubramanian", "prettyDate": "April 20"}, {"semester": "Spring", "year": "2017", "date": "2017-04-13", "speaker": "Sainbayar Sukhbaatar", "website": "http://cims.nyu.edu/~sainbar/", "title": "Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play", "affiliation": "New York University", "sponsor": "Oracle Labs", "video": "", "abstract": "We describe a simple scheme that allows an agent to explore its environment in an unsupervised manner. Our scheme pits two versions of the same agent, Alice and Bob, against one another. Alice proposes a task for Bob to complete; and then Bob attempts to complete the task. In this work we will focus on (nearly) reversible environments, or environments that can be reset, and Alice will \"propose\" the task by running a set of actions and then Bob must partially undo, or repeat them, respectively. Via an appropriate reward structure, Alice and Bob automatically generate a curriculum of exploration, enabling unsupervised training of the agent. When deployed on an RL task within the environment, this unsupervised training reduces the number of episodes needed to learn.", "bio": "I am a PhD student working with Rob Fergus and Yann Lecun at Department of Computer Science in New York University. My research interests are deep learning, neuroscience and reinforcement learning. http://cims.nyu.edu/~sainbar/", "area": "", "key": "SainbayarSukhbaatar", "prettyDate": "April 13"}, {"semester": "Spring", "year": "2017", "date": "2017-04-06", "speaker": "Robert Kozma", "website": "https://www.cics.umass.edu/person/kozma-robert", "title": "Computational Aspects of Brain Dynamics: Experiments, Models, and New AI Approaches", "affiliation": "UMass Amherst", "sponsor": "Oracle Labs", "video": "", "abstract": "Recent progress with high-resolution brain imaging techniques, including functional Magnetic Resonance Imaging (fMRI), Magnetoencephalography (MEG), Positron Emission Tomography (PET), Electro-Corticography (ECoG), and Electroencephalography (EEG), demonstrates an amazing vista on the complex spatio-temporal dynamics of cortical processes. Experiments show that the brain generates oscillatory neuronal activity at a broad range of frequencies and that these oscillations correlate with cognitive activity.  In this talk we summarize some key results of brain imaging experiments and introduce computational models of the observed brain oscillations and cognitive processing. We elaborate on a class of models, according to which brains are perceived as open thermodynamic systems converting sensory data into meaningful knowledge during repetitive phase transitions. Cortical phase transitions are viewed as neural correlates of higher cognition, which can be implemented in computers to develop new principles of intelligent computing and superior AI. ", "bio": "Robert Kozma is Visiting Professor at Computer Science, UMass Amherst, and Director of the Biologically-Inspired Neural & Dynamical Systems (BINDS) Lab. His research focuses on developing novel artificial intelligent system motivated by the operation of brains, see https://www.cics.umass.edu/person/kozma-robert.", "area": "", "key": "RobertKozma", "prettyDate": "April 06"}, {"semester": "Spring", "year": "2017", "date": "2017-03-30", "speaker": "Mikael Henaff", "website": "", "title": "Tracking the World State with Recurrent Entity Networks", "affiliation": "New York University", "sponsor": "Oracle Labs", "video": "", "abstract": "We introduce a new model, the Recurrent Entity Network (EntNet). It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data. For language understanding tasks, it can reason on-the-fly as it reads text, not just when it is required to answer a question or respond as is the case for a Memory Network (Sukhbaatar et al., 2015). Like a Neural Turing Machine or Differentiable Neural Computer (Graves et al., 2014; 2016) it maintains a fixed size memory and can learn to perform location and content-based read and write operations. However, unlike those models it has a simple parallel architecture in which several memory locations can be updated simultaneously. The EntNet sets a new state-of-the-art on the bAbI tasks, and is the first method to solve all the tasks in the 10k training examples setting. We also demonstrate that it can solve a reasoning task which requires a large number of supporting facts, which other methods are not able to solve, and can generalize past its training horizon. It can also be practically used on large scale datasets such as Children's Book Test, where it obtains competitive performance, reading the story in a single pass.", "bio": "I am a Ph.D student at NYU, advised by Yann LeCun. During my Ph.D I have interned at Facebook AI Research and worked on projects involving natural language, reasoning and memory. Prior to that I worked at the NYU Center for Health Informatics and Bioinformatics, applying machine learning methods to problems in biomedicine. I received my undergraduate degree in math from the University of Texas at Austin.", "area": "", "key": "MikaelHenaff", "prettyDate": "March 30"}, {"semester": "Spring", "year": "2017", "date": "2017-03-23", "speaker": "David Moorman", "website": "", "title": "Making Sense of Neuron Ensembles: Advances and Issues in Neural Coding", "affiliation": "UMass Amherst", "sponsor": "Oracle Labs", "video": "", "abstract": "The brain contains approximately 80 billion neurons, and any perception, behavior, or thought requires the integration across thousands to millions of these neurons. Advances in neural technology now allows us to monitor the activity of hundreds to thousands of neurons simultaneously, in real time. Although we are able to collect rich data sets, our ability to interpret them, and to use this information to explain behavior, is still limited.  In this talk I will give an overview of issues surrounding neural encoding with a focus on what remains to be done to make sense of this complex information. I will also discuss some of our own research, but my main goal will be to identify problems in neuroscience that could be better addressed with advanced computation and analysis, potentially even by interested members of the UMass community. ", "bio": "David Moorman is an Assistant Professor in Psychological and Brain Sciences at UMass Amherst. His lab studies neural systems involved in motivation and cognition, and how these systems are disrupted in psychiatric disorders. More information can be found at: moormanlab.org", "area": "", "key": "DavidMoorman", "prettyDate": "March 23"}, {"semester": "Spring", "year": "2017", "date": "2017-02-23", "speaker": "Andrew Trapp", "website": "", "title": "Using Density to Identify Fixations in Gaze Data: Optimization-Based Formulations and Algorithms", "affiliation": "Worcester Polythechnic Institute", "sponsor": "Oracle Labs", "video": "", "abstract": "Eye tracking is an increasingly common technology with a variety of practical uses. Eye-tracking gaze data can be categorized into two main events: fixations, which represent attention, whereas saccades occur between fixation events. We propose a novel manner to identify fixations based on their density, which concerns both the fixation duration as well as its inter-point proximity. We develop two mixed-integer nonlinear programming formulations and corresponding algorithms to recover the densest fixations in a data set. Our approach is parameterized by a unique value that controls for the degree of desired density. We conclude by discussing computational results and insights on real data sets.", "bio": "Andrew C. Trapp completed his PhD in Industrial Engineering from the University of Pittsburgh in 2011. He is presently an Assistant Professor of Operations and Industrial Engineering at Worcester Polytechnic Institute (WPI) in Worcester, MA. His research focus is on using advanced analytical techniques, in particular mathematical optimization, to find optimal decisions to problems arising from a diverse cross-section of sectors such as humanitarian operations, healthcare, data mining, and sustainability. He develops new theory, models, and computational solution approaches to tackle such problems. He has published in leading optimization journals such as Operations Research, European Journal of Operational Research, INFORMS Journal on Computing, Annals of Operations Research, IIE Transactions, and Discrete Optimization.", "area": "", "key": "AndrewTrapp", "prettyDate": "February 23"}, {"semester": "Spring", "year": "2017", "date": "2017-02-15", "speaker": "Naomi Fitter", "website": "", "title": "Exploring Human-Inspired Haptic Interaction Skills for Robots", "affiliation": "University of Pennsylvania", "sponsor": "Oracle Labs", "video": "", "abstract": "A human-inspired understanding of the world can enhance robots' abilities to successfully and safely explore the world around them in applications from successfully manipulating delicate objects to playfully high-fiving a human teammate. Particularly in situations where human skills outweigh modern robot capabilities, data collected from people can yield models for successful robot behaviors. In this talk, I will cover my past cognitive robotics work on helping the PR2 robot to explore and label objects with haptic adjectives and my more recent work on allowing the Baxter robot to label and reciprocate human motions.", "bio": "Naomi Fitter is a PhD Candidate and member of the Haptics Group in the University of Pennsylvania GRASP Lab, working with Professor Katherine Kuchenbecker. She investigates socially relevant physical human-robot interactions like human-robot high fives and hand-clapping games. Her work involves a combination of haptics, socially assistive robotics, entertaining robotics, and physical human-robot interaction.", "area": "", "key": "NaomiFitter", "prettyDate": "February 15"}, {"semester": "Spring", "year": "2017", "date": "2017-02-14", "speaker": "Tsendsuren Munkhdalai", "website": "", "title": "Language Understanding and Reasoning with Memory Augmented Neural Networks", "affiliation": "UMass CICS", "sponsor": "Oracle Labs", "video": "", "abstract": "This talk will first briefly review recent advances in memory augmented neural nets and then present our own contribution, Neural Semantic Encoders (NSE) [1,2]. With a special focus on NSE, we show that external memory in conjunction with attention mechanism can be a good asset in natural language understanding and reasoning. Particularly we will cover a set of real and large-scale NLP tasks ranging from sentence classification to seq-seq learning and question answering, and demonstrate how NSE is effectively applied to them.  References  1. Munkhdalai, Tsendsuren, and Hong Yu. \"Neural Semantic Encoders.\" (To appear in EACL 2017).  2. Munkhdalai, Tsendsuren, and Hong Yu. \"Reasoning with memory augmented neural networks for language comprehension.\" (To appear in ICLR 2017). ", "bio": "Tsendsuren Munkhdalai is a postdoctoral associate at Prof. Hong\u2019s BioNLP group at Umass medical school. He recently received his PhD in biomedical information extraction and NLP from the Department of Computer Science at Chungbuk National University, South Korea under the excellent supervision of Prof. Keun Ho Ryu. His research interest includes semi-supervised learning, representation learning, meta learning and deep learning with applications to natural language understanding and (clinical/biomedical) information extraction.", "area": "", "key": "TsendsurenMunkhdalai", "prettyDate": "February 14"}, {"semester": "Spring", "year": "2017", "date": "2017-02-09", "speaker": "Hao Tang", "website": "", "title": "Sequence Prediction with Neural Segmental Models", "affiliation": "Toyota Technical Institute at Chicago", "sponsor": "Oracle Labs", "video": "", "abstract": "Segments that span contiguous parts of inputs, such as phonemes in speech, named-entities in sentences, actions in videos, occur frequently in sequence prediction problems. Recent work has shown that segmental models, a class of models that explicitly hypothesizes segments, can significantly improve accuracy. However, segmental models suffer from slow decoding, hampering the use of computationally expensive features. In addition, training segmental models requires detailed manual annotation, which makes collecting datasets expensive.  In the first part of the talk, I will introduce discriminative segmental cascades, a multi-pass framework that allows us to improve accuracy by adding higher-order features and neural segmental features while maintaining efficiency. I will also show how the cascades can be used to speed up inference and training. In the second part of the talk, I will discuss end-to-end training for segmental models with various loss functions. I will address the difficulty of end-to-end training from random initialization by comparing it to two-stage training. Finally, I will show how end-to-end training can eliminate the need for detailed manual annotation. ", "bio": "Hao Tang is a Ph.D. candidate at Toyota Technological Institute at Chicago. His main interests are in machine learning and its application to speech recognition, with particular interests in discriminative training and segmental models. His work on segmental models has been nominated for the Best Paper award at ASRU 2015, and an application of such models to fingerspelling recognition has earned a Best Student Paper Award at ICASSP 2016. He received a B.S. degree in Computer Science and a M.S. degree in Electrical Engineering from National Taiwan University in 2007 and 2010, respectively.", "area": "", "key": "HaoTang", "prettyDate": "February 09"}, {"semester": "Spring", "year": "2017", "date": "2017-02-02", "speaker": "Stephan Mandt", "website": "", "title": "Advances in scalable probabilistic modeling: theory, applications, and challenges", "affiliation": "Disney Research", "sponsor": "Oracle Labs", "video": "", "abstract": "Probabilistic modeling is a popular approach to solving machine learning problems. We will begin by reviewing variational inference, where Bayesian inference is mapped to non-convex optimization. We first introduce variational tempering, where we augment our probabilistic model with a temperature random variable. This leads to an adaptive annealing mechanism which prevents the algorithm from getting stuck in poor local optima. In addition, defining temperature locally for every datapoint results in a more robust model that automatically downweighs outliers, leading to better density estimates. In the second part of the talk, we give a Bayesian analysis of stochastic gradient descent with constant learning rates (constant SGD). In particular, we relate this algorithm to Markov-Chain Monte Carlo (MCMC) sampling. Drawing on the tools of variational inference and stochastic differential equations, we investigate and formalize this connection and show how we can use constant SGD as a cheap and scalable approximate MCMC sampler that can compete with more complicated state-of-the-art variational approaches. Finally, we introduce exponential family embeddings which give a more statistical view on word embeddings and allow us to generalize them to other kinds of high-dimensional data.", "bio": "Stephan Mandt is a Research Scientist at Disney Research Pittsburgh, where he leads the statistical machine learning group. Previously, he was a postdoctoral researcher with David Blei at Columbia University, where he worked on scalable approximate Bayesian inference algorithms. Trained as a statistical physicist, he held a previous postdoctoral fellowship at Princeton University and holds a Ph.D. from the University of Cologne as a fellow of the German National Academic Foundation.", "area": "", "key": "StephanMandt", "prettyDate": "February 02"}, {"semester": "Spring", "year": "2017", "date": "2017-01-19", "speaker": "Jeff Flanigan", "website": "", "title": "Parsing and Generation for the Abstract Meaning Representation", "affiliation": "Carnegie Mellon", "sponsor": "Oracle Labs", "video": "", "abstract": "Uncovering meaning in language and correctly expressing meaning in generated text are key tasks in intelligent language processing. In this talk, I introduce parsing and generation algorithms for the Abstract Meaning Representation (AMR). AMR is a whole-sentence semantic representation which captures relational semantics, or \"who is doing what to whom,\" as a directed graph. Recently, an annotated corpus of over 45,000 sentences has been constructed, enabling training of broad-coverage AMR parsers and generators.  First, I will present a method for parsing into AMR using techniques from combinatorial optimization. The method consists of two stages, which first identify concepts and then add relations between them using a maximum connected subgraph algorithm, utilizing Lagrangian relaxation to enforce constraints on well-formedness.  Next I present a method for generating language from AMR using weighted tree transducers. The method first converts the AMR graph to a tree and which is then transduced to a string, and relies on discriminative learning and an argument realization model to overcome data sparsity. ", "bio": "Jeff Flanigan is a Ph.D. candidate at Carnegie Mellon University in the Language Technologies Institute. He works on statistical natural language processing, focusing on semantic parsing, generation, and machine translation. He built the first AMR parser, which earned Honorable Mention for Best Long Paper at ACL 2014, as well as the first AMR generator. His undergraduate degree is from the University of California, Santa Barbara, and he has a Masters degree in physics from Caltech.", "area": "", "key": "JeffFlanigan", "prettyDate": "January 19"}, {"semester": "Fall", "year": "2016", "date": "2016-12-08", "speaker": "John Lalor", "website": "", "title": "Building Evaluation Scales for NLP using Item Response Theory", "affiliation": "UMass CICS", "sponsor": "Oracle Labs", "video": "", "abstract": "Evaluation of NLP methods requires testing against a previously vetted gold-standard test set and reporting standard metrics (accuracy/precision/recall/F1). The current assumption is that all items in a given test set are equal with regards to difficulty and discriminating power. This talk introduces Item Response Theory (IRT) from psychometrics as an alternative means for gold-standard test-set generation and NLP system evaluation. IRT is able to describe characteristics of individual items - their difficulty and discriminating power - and can account for these characteristics in its estimation of ability. In this talk, I will give an introduction to Item Response Theory and describe an IRT gold-standard test set for Recognizing Textual Entailment. Our IRT model compares NLP systems with the performance in a human population and is able to provide more insight into performance than standard evaluation metrics. We show that a high accuracy score does not always imply a high IRT score, which depends on the item characteristics and the response pattern. ", "bio": "John Lalor is a 2nd year Ph.D. student at UMass Amherst, working with Prof. Hong Yu in the Bio-NLP lab. His research interests include NLP and its applications in the medical domain. Prior to UMass, he received an M.S. degree from DePaul University and a B.B.A. from the University of Notre Dame.", "area": "", "key": "JohnLalor", "prettyDate": "December 08"}, {"semester": "Fall", "year": "2016", "date": "2016-12-01", "speaker": "Jayant Krishnamurthy", "website": "", "title": "Semantic Parsing to Probabilistic Programs for Situated Question Answering", "affiliation": "AI2", "sponsor": "Oracle Labs", "video": "", "abstract": "Situated question answering is the problem of answering questions about an environment such as an image or diagram. This problem is challenging because it requires jointly interpreting a question and an environment using background knowledge to select the correct answer. We present Parsing to Probabilistic Programs, a novel situated question answering model that can use background knowledge and global features of the question/environment interpretation while retaining efficient approximate inference. Our key insight is to treat semantic parses as probabilistic programs that execute nondeterministically and whose possible executions represent environmental uncertainty. We evaluate our approach on a new, publicly-released data set of 5000 science diagram questions, outperforming several competitive classical and neural baselines.  If time permits, I will also talk about some more recent work combining probabilistic programming and neural networks for program induction. ", "bio": "Jayant Krishnamurthy is a research scientist at the Allen Institute for Artificial Intelligence. He received his Ph.D. in Computer Science from Carnegie Mellon University in 2015. His research interests are natural language understanding for tasks such as question answering.", "area": "", "key": "JayantKrishnamurthy", "prettyDate": "December 01"}, {"semester": "Fall", "year": "2016", "date": "2016-11-30", "speaker": "Mohit Iyyer", "website": "", "title": "Understanding and Answering Questions about Creative Language", "affiliation": "University of Maryland", "sponsor": "Oracle Labs", "video": "", "abstract": "Creative language\u2014the sort found in novels, film, and comics\u2014contains a wide range of linguistic phenomena, from increased syntactic complexity (e.g., metaphors, sarcasm) to high-level discourse structures such as narrative and character arcs. In this talk, I present neural architectures for two different tasks involving creative language: 1) modeling dynamic fictional relationships in novels and 2) predicting dialogue and artwork from comic book panels. While creative language understanding has many applications (e.g., designing more engaging conversational agents), I motivate these tasks through quiz bowl, which is a trivia game that contains many questions about novels, paintings, and comics. I conclude by discussing work in progress on using the proposed models to improve quiz bowl question answering.", "bio": "", "area": "", "key": "MohitIyyer", "prettyDate": "November 30"}, {"semester": "Fall", "year": "2016", "date": "2016-11-17", "speaker": "Andreas ten Pas", "website": "", "title": "Grasp Pose Detection in Dense Clutter", "affiliation": "Northeastern", "sponsor": "Oracle Labs", "video": "", "abstract": "We present a grasp detection method that can be used to localize robotic grasp configurations directly from sensor data without estimating object pose. Our method takes a point cloud from an RGBD-camera, like the Microsoft Kinect, as input and produces 6-DOF grasp pose estimates. We use an algorithmic framework that first generates a large number of grasp candidates and then uses machine learning to predict if a candidate is a viable grasp. For the second step, we first used HOG features to train a support vector machine. We later-on improved this step by training a convolutional neural network. We discuss a number of ways to improve grasp detection performance for the latter method. To evaluate our methods, we conducted a series of robotic experiments in a dense clutter tabletop scenario. In addition, we will present recent results on applying our method in a mobile manipulation scenario and on detecting grasps on objects of interest.", "bio": "Andrea ten Pas is currently a Ph.D. student in the Helping Hands Lab in the College of Computer and Information Science at Northeastern University, advised by Professor Robert Platt. His main interests are in the field of perception and robotics. In particular, focusing on perception for robotic grasping and manipulation. Andrea is also the author of several ROS packages that handle grasping objects in cluttered environments.", "area": "", "key": "AndreastenPas", "prettyDate": "November 17"}, {"semester": "Fall", "year": "2016", "date": "2016-11-10", "speaker": "Evan Shelhamer", "website": "http://imaginarynumber.net/", "title": "A Fuller Understanding of Fully Convolutional Networks", "affiliation": "Berkeley", "sponsor": "Oracle Labs", "video": "", "abstract": "Fully convolutional networks are end-to-end, pixels-to-pixels architectures for image-to-image tasks such as semantic segmentation, surface normal estimation, and colorization. By addressing the whole task these networks can do image-to-image mapping with efficient inference and learning. Casting classification networks into fully convolutional form brings transfer learning to pixelwise problems for accuracy and data efficiency. Fusing features across layers yields a multi-resolution, joint model of what and where to refine the output. Fully convolutional networks take a step in the direction of a unified, learned approach to pixel prediction. In this talk I'll cover the definition and operation of fully convolutional networks, examine new experiments that inform the care and feeding of these models, and highlight extensions to weak supervision, structured output, and video.", "bio": "Evan Shelhamer is a PhD student at UC Berkeley advised by Trevor Darrell as a member of the Berkeley AI Research. His research is on deep learning and end-to-end optimization for vision. Before switching coasts, he studied computer science (AI concentration) and psychology at University of Massachusetts Amherst. He is the lead developer of the Caffe deep learning framework and takes his coffee black.", "area": "", "key": "EvanShelhamer", "prettyDate": "November 10"}, {"semester": "Fall", "year": "2016", "date": "2016-11-10", "speaker": "Samantha Kleinberg", "website": "", "title": "Causal Inference and Explanation to Improve Human Health", "affiliation": "Stevens Institute of Technology", "sponsor": "Oracle Labs", "video": "", "abstract": "Massive amounts of medical data such as from electronic health records and body-worn sensors are being collected and mined by researchers, but translating findings into actionable knowledge remains difficult. The first challenge is finding causes, rather than correlations, when the data are highly noisy and often missing. The second is using these to explain specific cases, such as why an individual\u2019s blood glucose is raised. In this talk I discuss new methods for both causal inference and explanation, and show how these could be used to provide individualized feedback to patients. In the second part of this talk I discuss our recent work using multiple sensing modalities to automatically identify eating and how this can ultimately be used to support individuals with chronic disease. ", "bio": "Samantha Kleinberg is an Assistant Professor of Computer Science at Stevens Institute of Technology. She received her PhD in Computer Science from New York University in 2010 and was a Computing Innovation Fellow at Columbia University in the Department of Biomedical informatics from 2010-2012. She is the recipient of NSF CAREER and JSMF Complex Systems Scholar Awards and her work is also supported by the NIH through an R01. She is the author of Causality, Probability, and Time (Cambridge University Press, 2012) and Why: A Guide to Finding and Using Causes (O\u2019Reilly Media, 2015). ", "area": "", "key": "SamanthaKleinberg", "prettyDate": "November 10"}, {"semester": "Fall", "year": "2016", "date": "2016-11-03", "speaker": "Tianfan Xue", "website": "https://people.csail.mit.edu/tfxue/", "title": "Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "We study the problem of synthesizing a number of likely future frames from a single input image. In contrast to traditional methods, which have tackled this problem in a deterministic or non-parametric way, we propose to model future frames in a probabilistic manner. Our probabilistic model makes it possible for us to sample and synthesize many possible future frames from a single input image. To synthesize realistic movement of objects, we propose a novel network structure, namely a Cross Convolutional Network; this network encodes image and motion information as feature maps and convolutional kernels, respectively. In experiments, our model performs well on synthetic data, such as 2D shapes and animated game sprites, as well as on real-world video frames. Please refer to our website for more details: http://visualdynamics.csail.mit.edu/. ", "bio": "Tianfan Xue is currently a fifth-year Ph.D. student in MIT CSAIL, working with William T. Freeman. Before that, he received his B.E. degree from Tsinghua Universtiy, and M.Phil. degree from The Chinese University of Hong Kong. His research interests include computer vision, image processing, and machine learning. Specifically, he is interested in motion estimation and image and video processing based on the motion information.", "area": "", "key": "TianfanXue", "prettyDate": "November 03"}, {"semester": "Fall", "year": "2016", "date": "2016-10-27", "speaker": "Chris Kedzie", "website": "", "title": "Real-Time Web Scale Event Summarization Using Sequential Decision Making", "affiliation": "Columbia", "sponsor": "Oracle Labs", "video": "", "abstract": "We present a system based on sequential decision making for the online summarization of massive document streams, such as those found on the web. Given an event of interest (e.g. \"Boston marathon bombing\"), our system is able to filter the stream for relevance and produce a series of short text updates describing the event as it unfolds over time. Unlike previous work, our approach is able to jointly model the relevance, comprehensiveness, novelty, and timeliness required by time-sensitive queries. We demonstrate a 28.3% improvement in summary F1 and a 43.8% improvement in time-sensitive F1 metrics.", "bio": "Chris Kedzie is a 3rd year Ph.D. candidate in the Department of Computer Science at Columbia University, working in the field of Natural Language Processing under Prof. Kathleen McKeown. His research focuses on predictive models for summarization of news streams. He is also interested in language generation for summarization. Before studying computer science, he played classical guitar and studied music theory/composition at Loyola Marymount University.", "area": "", "key": "ChrisKedzie", "prettyDate": "October 27"}, {"semester": "Fall", "year": "2016", "date": "2016-10-20", "speaker": "Jiajun Wu", "website": "https://jiajunwu.com/", "title": "Computational Perception of Physical Object Properties", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "We study the problem of learning physical object properties from unlabeled videos. Inspired by findings in cognitive science that even infants are able to perceive a physical world full of dynamic content, we aim to build models to characterize object properties from synthetic and real-world scenes. In this talk, I will present some models we recently proposed for physical scene understanding, as well as a newly collected video dataset. I will also talk about a behavior study on its potential connection to human perception.", "bio": "Jiajun Wu is a Ph.D. student at Massachusetts Institute of Technology, advised by Professor Bill Freeman and Professor Josh Tenenbaum. His research interests lie on the intersection of computer vision, machine learning, and computational cognitive science. Before coming to MIT, he received his B.Eng. from Tsinghua University, China, advised by Professor Zhuowen Tu. He has also spent time working at research labs of Microsoft, Facebook, and Baidu.", "area": "", "key": "JiajunWu", "prettyDate": "October 20"}, {"semester": "Fall", "year": "2016", "date": "2016-10-13", "speaker": "Hugo Larochelle", "website": "", "title": "Fighting our Big Data Addiction with Representation Learning", "affiliation": "Twitter Cortex", "sponsor": "Oracle Labs", "video": "", "abstract": "Recently, tremendous progress has been made in applying machine learning to AI problems (e.g. speech recognition, object recognition, machine translation), notably with deep neural networks, that automate the learning of meaningful representations (features) directly from raw data. However, these successes were largely enabled thanks to the collection of large labeled datasets. Such datasets are costly to generate, thus it would be desirable to reduce our reliance on them.  In this talk, I'll discuss 3 general approaches that go in this direction: learning representations using unsupervised learning, multi-modal learning and domain adaptation. For each, I'll give an example of a successful instantiation of these approaches, taken from my own research. ", "bio": "Hugo Larochelle is Research Scientist at Twitter and Assistant Professor at the Universit\u00e9 de Sherbrooke (UdeS). Before, he spent two years in the machine learning group at University of Toronto, as a postdoctoral fellow under the supervision of Geoffrey Hinton. He obtained his Ph.D. at Universit\u00e9 de Montr\u00e9al, under the supervision of Yoshua Bengio. He is the recipient of two Google Faculty Awards. His professional involvement includes associate editor for the IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), member of the editorial board of the Journal of Artificial Intelligence Research (JAIR) and program chair for the International Conference on Learning Representations (ICLR) of 2015, 2016 and 2017.", "area": "", "key": "HugoLarochelle", "prettyDate": "October 13"}, {"semester": "Fall", "year": "2016", "date": "2016-10-11", "speaker": "Chao Chen", "website": "", "title": "Topological Analysis of Modern Data", "affiliation": "City University of New York", "sponsor": "Oracle Labs", "video": "", "abstract": "We are facing unprecedented challenges from modern data such as vast volume, high dimensionality, and complex intrinsic structures. To address these issues, we need scalable and robust methods to extract concise, intuitive and discriminative global information from data. Topology data analysis (TDA) is a new area focusing on the extraction and usage of topological structures of data with strong theoretical guarantee. In this talk, I will introduce the main theoretical tools in TDA and their applications. I will also present my recent work of combining the topological view with probabilistic graphical models in machine learning.", "bio": "Dr. Chao Chen is an Assistant Professor in City University of New York. His interdisciplinary research lies in between computational topology, machine learning, and biomedical image analysis. His research has been published in top venues in all these domains. For more information, please visit his website.", "area": "", "key": "ChaoChen", "prettyDate": "October 11"}, {"semester": "Fall", "year": "2016", "date": "2016-09-22", "speaker": "Thien Huu Nguyen", "website": "", "title": "Neural Information Extraction with Memory", "affiliation": "New York University", "sponsor": "Oracle Labs", "video": "", "abstract": "Neural Networks (NN) have been applied successfully to many Information Extraction (IE) tasks recently. However, most of the current models are designed for a separate task of the IE pipeline, focusing only on the local information specific to the task. Such local models are not able to capture the global information or the long range inter-dependencies between multiple prediction stages, that are necessary for many IE problems.  In this talk, we present our recent research on memory augmented networks to address such limitations of the local NN models. In particular, we introduce memory tensors to accumulate the prediction information during the course of the local stages, and provide such global memory as additional evidence for the local predictions of IE. Our experiments on event extraction and entity linking demonstrate that the memory augmented networks outperform the traditional local NN models and feature-based approaches for such problems. ", "bio": "Thien Huu Nguyen is a fifth-year Ph.D. student in the Computer Science Department at New York University (NYU). His Ph.D. research centers around the development of Deep Learning models for Information Extraction of Natural Language Processing, including Relation Extraction, Event Extraction, Mention Detection, and Slot Filling. His research advisors at NYU are Professor Ralph Grishman and Professor Kyunghyun Cho.", "area": "", "key": "ThienHuuNguyen", "prettyDate": "September 22"}, {"semester": "Fall", "year": "2016", "date": "2016-09-16", "speaker": "Siva Reddy", "website": "", "title": "Freebase Semantic Parsing with and without QA pairs", "affiliation": "University of Edinburgh", "sponsor": "Oracle Labs", "video": "", "abstract": "I will present three semantic parsing approaches for querying Freebase in natural language 1) training only on raw web corpus, 2) training on question-answer (QA) pairs and 3) training on both QA pairs and web corpus. For 1 and 2, we conceptualise semantic parsing as a graph matching problem, where natural language graphs built using CCG/dependency logical forms are transduced to Freebase graphs. For 3, I will present a natural-logic approach for SemanticParsing. Our methods achieve state-of-the-art on WebQuestions and Free917 QA datasets.", "bio": "Siva Reddy is a Google PhD fellow at the University of Edinburgh under the supervision of Mirella Lapata and Mark Steedman. His primary research interests are in semantic parsing, information extraction, distributional semantics and cross-language transfer. His work is published in TACL, ACL, NAACL, EMNLP. He won the best paper award in IJCNLP 2011, a first place in SemEval 2011 Compositionality Detection task, and a second place in SemEval 2010 WSD task. He worked with Google Parsing team as an intern during his PhD, and as a full-time employee for Adam Kilgarriff\u2019s Sketch Engine before starting his PhD. Apart from language, he loves Badminton (represents Edinburgh University in league matches), and is also learning to play Irish whistle. He is currently on the job market looking for a postdoc.", "area": "", "key": "SivaReddy", "prettyDate": "September 16"}, {"semester": "Fall", "year": "2016", "date": "2016-09-15", "speaker": "Antoine Bordes", "website": "", "title": "Reasoning with Memory Networks: Successes and Challenges", "affiliation": "Facebook", "sponsor": "Oracle Labs", "video": "", "abstract": "This talk will first briefly review Memory Networks, an attention-based neural network architecture introduced in (Weston et al., 15), which has been shown to be able to reach promising performance for question answering on synthetic data. Then, we will explore and discuss the successes and remaining challenges arising when applying Memory Networks to human generated natural language, in the context of large-scale question answering, machine reading and dialog management.", "bio": "Antoine is a research scientist at Facebook Artificial Intelligence Research. Prior to joining Facebook in 2014, he was a CNRS staff researcher in the Heudiasyc laboratory of the University of Technology of Compiegne in France. In 2010, he was a postdoctoral fellow in Yoshua Bengio's lab of University of Montreal. He received his PhD in machine learning from Pierre & Marie Curie University in Paris in early 2010. He received two awards for best PhD from the French Association for Artificial Intelligence and from the French Armament Agency, as well as a Scientific Excellence Scholarship awarded by CNRS in 2013.", "area": "", "key": "AntoineBordes", "prettyDate": "September 15"}, {"semester": "Spring ", "year": "2016", "date": "2016-05-26", "speaker": "Matthew Taylor", "website": "", "title": "Learning from Demonstration, Human Feedback, and Environmental Rewards", "affiliation": "Washington State University", "sponsor": "Yahoo!", "video": "", "abstract": "Reinforcement learning algorithms are able to find near-optimal solutions, but often suffer from poor initial performance and long learning times. Furthermore, an external environmental reward is not always available. This talk will discuss two sets of work on leveraging human knowledge to learn sequential decision tasks. First, we will discuss how human-demonstrated data can be leveraged to improve autonomous learning. Second, we will show how discrete human feedback can be used to learn complex tasks in the absence of an external reward signal. The talk will conclude with a selection of open problems and future research directions.", "bio": "Dr. Matthew E. Taylor is an assistant professor at Washington State University in the school of electrical engineering and computer science. He holds the Allred Distinguished Professorship in Artificial Intelligence, has won an NSF CAREER award, and is on the IFAAMAS board of directors. He currently supervises more than 10 graduate students in the Intelligent Robot Learning Laboratory. Current research interests include intelligent agents, multi-agent systems, reinforcement learning, transfer learning, and robotics.", "area": "", "key": "MatthewTaylor", "prettyDate": "May 26"}, {"semester": "Spring ", "year": "2016", "date": "2016-05-19", "speaker": "Matthew Gombolay", "website": "", "title": "Human-Machine Collaborative Optimization via Apprenticeship Scheduling", "affiliation": "MIT", "sponsor": "Yahoo!", "video": "", "abstract": "Health care, manufacturing, and military operations require the careful choreography of resources - people, robots, and machinery - to effectively fulfill the responsibilities of the profession. Poor resource utilization has been shown to have drastic health, safety, and economic consequences. However, coordinating a heterogeneous team of agents to complete a set of tasks related through upper- and lower-bound temporal constraints is NP-Hard. Further, the process of modeling the multi-faceted aspects of real-world scenarios is labor-intensive and leaves much to be desired. Yet, there is hope. In practice, we know there are a rare breed of human experts who effectively reason about complex resource optimization problems every day. The question then becomes: How can we autonomously learn the rules-of-thumb and heuristics from these domain experts to support real-time decision-support and autonomously coordinate human-robot teams? In this talk, I will present a novel computational technique, known as Apprenticeship Scheduling, which 1) learns the heuristics and implicit rules-of-thumb developed by domain experts from years of experience, 2) embeds and leverages this knowledge within a scalable resource optimization framework, and 3) provides decision support in a way that engages users and benefits them in their decision-making process. By intelligently leveraging the ability of humans to learn heuristics and the speed of modern computation, we can improve the ability to coordinate resources in these time- and safety-critical domains.", "bio": "Matthew Gombolay is a PhD candidate and NSF Graduate Research Fellow in the Interactive Robotics Group at the Massachusetts Institute of Technology (MIT). He received his S.M. (2013) from the department of Aeronautics and Astronautics at MIT and his B.S (2011) from the department of Mechanical Engineering at Johns Hopkins University. Matthew studies the interaction of humans and automation and is developing computational methods for real-time and collaborative resource optimization. Matthew focuses on harnessing the strengths of human domain experts and sophisticated computational techniques to form collaborative human-machine teams for manufacturing, healthcare, and military operations. Matthew has worked for MIT Lincoln Laboratory and the Johns Hopkins University Applied Physics Laboratory developing cutting-edge planning and scheduling algorithms for ballistic and anti-ship missile defense with the US Navy and Missile Defense Agency. Matthew has received a Best Technical Paper Award from the AIAA Intelligent Systems Committee, and his work has been highlighted in media outlets such as PBS, NBC, Harvard Business Review, and public radio.", "area": "", "key": "MatthewGombolay", "prettyDate": "May 19"}, {"semester": "Spring ", "year": "2016", "date": "2016-04-28", "speaker": "Jayadev Acharya", "website": "", "title": "Testing Big Data Distributions", "affiliation": "MIT", "sponsor": "Yahoo!", "video": "", "abstract": "Given samples from an unknown distribution p, is it possible to distinguish whether p has a certain property P, versus far from P? This fundamental question has received tremendous attention in statistics, and information theory under hypothesis testing focusing on the asymptotic analysis, and more recently initiated in the computer science literature, where the emphasis has been on small sample size and computational complexity. Nevertheless, even for basic properties of distributions such as monotonicity, unimodality, and independence the optimal sample complexity of this problem is not known.  We provide a general approach via which we obtain sample-optimal and computationally efficient testers for all these distribution families. Underlying our approach is an algorithm that distinguishes whether two distributions are close in the chi-squared distance or far in the L1 distance.  The talk is based on joint work with Constantinos Daskalakis and Gautam Kamath. ", "bio": "Jayadev Acharya is a postdoc in EECS department at MIT. He obtained a Ph.D in ECE from UC San Diego. His research interests lie in information theory, machine learning, algorithms, and statistics.", "area": "", "key": "JayadevAcharya", "prettyDate": "April 28"}, {"semester": "Spring ", "year": "2016", "date": "2016-04-14", "speaker": "Brad Hayes", "website": "", "title": "Developing Capable Collaborative Robots", "affiliation": "MIT", "sponsor": "Yahoo!", "video": "", "abstract": "Robots capable of collaborating with people provide tremendous value, bringing with them the potential to revolutionize a wide array of industries ranging from health care to education to manufacturing. Particularly in domains where modern robots are ineffective, human-robot teaming can be leveraged to increase the efficiency, capability, and safety of people. Central to building these autonomous systems are the problems of teammate goal inference, task modeling, and multi-agent coordination, each of which can be extremely challenging without a priori task knowledge or behavioral models. In this talk I will cover my recent work towards developing robots that learn from co-workers and provide transparent, supportive behaviors -- actions a collaborator can perform that facilitate another's task completion or comprehension.", "bio": "Brad Hayes is a Postdoctoral Associate and a member of the Interactive Robotics Group in the Computer Science and Artificial Intelligence Lab at MIT, working with Professor Julie Shah. He received his PhD from Yale University, advised by Professor Brian Scassellati. Brad is interested in building robotic systems that are supportive, interactive, and intuitive, capable of performing complex collaborative tasks with humans to reduce cognitive or physical load. His work involves a combination of learning from demonstration, human teaming psychology, intention recognition and projection, and human-robot interaction.", "area": "", "key": "BradHayes", "prettyDate": "April 14"}, {"semester": "Spring ", "year": "2016", "date": "2016-04-12", "speaker": "Scott Miller", "website": "", "title": "Beating the News: Predicting Significant Societal Events from Open Source Data", "affiliation": "Raytheon BBN Technologies", "sponsor": "Yahoo!", "video": "", "abstract": "Beating the News: Predicting Significant Societal Events from Open Source Data  This talk will describe BBN\u2019s efforts in IARPA\u2019s OSI (Open Source Indicators) program. OSI aimed to develop automated methods for continuously monitoring publicly available data sources to predict significant societal events with a lead time of seven days or greater. OSI\u2019s test region was Latin America and included both Spanish and Portuguese-speaking countries. I will describe three forecasting components that we developed, one each for civil unrest, disease outbreaks, and election results. All three components are based on a common methodology that includes a) data acquisition components for real-time monitoring of data streams, b) feature extractors to convert data streams into time series, c) time series analysis to detect causal patterns, and d) statistical models for event prediction. The talk will present specific characteristics of the forecasting tasks, methods used, results, and lessons learned.  Sequence Recognition in Speech Lattices  Time permitting, I will present a short description of a novel algorithm for performing named entity recognition (NER) in word lattices such as those produced by speech recognition systems. Unlike the case of text, the normalization term for algorithms such as CRFs cannot be ignored. I will describe a solution that uses locally normalized probability distributions and a pair of taggers \u2014 one working forward in time and the other backward \u2014 that are combined using dual decomposition. Accuracy is comparable to other state-of-the-art techniques and the algorithm can identify names anywhere in the lattice, including those not in the one-best output of the recognizer. ", "bio": "Scott Miller is a Senior Technical Director and Lead Scientist in the Speech and Language Department at BBN. He currently leads an effort focused on extracting structured information from foreign language sources. Miller\u2019s previous roles at BBN include Principal Investigator under IARPA\u2019s OSI program and technical lead for BBN\u2019s effort under JHU\u2019s Center of Excellence. Miller previously served as Chief Scientist at Basis Technology Corporation where he led efforts that developed machine-learning methods for syntax-based machine translation and multilingual text processing. At Basis, he also served as PI for a DARPA GALE subcontract. In 2004 Miller founded Translingual Technologies, a Massachusetts startup that created novel machine translation technology for making foreign-language content accessible to monolingual English speakers. Miller served as a senior researcher at JHU SCALE 2009 (Summer Camp for Applied Language Exploration): Semantically Informed Machine Translation, focused on Urdu to English translation. He coled SCALE 2010: All-Source Knowledge Base Population, which focused on constructing knowledge bases from multiple sources, including conversational speech and informal text genres, in English and Arabic. Miller\u2019s technical innovations include: IdentiFinder, the first successful statistical named-entity tagging algorithm (U.S. Patent 6,052,682, Miller, Bikel and Schwartz). IdentiFinder has been successfully applied to ASR (Automatic Speech Recognition), OCR (Optical Character Recognition) and text in multiple languages including English, Arabic, and Chinese. The work is widely cited. SIFT (Statistical Information from Text), which was among the first successful joint-inference information extraction algorithms, achieving state-of-the-art performance in a U.S. Government evaluation (MUC-7). BBN\u2019s Quick Tagger, which dramatically improved the practicality of deploying information extraction capabilities by reducing annotation effort from many days to a few hours. Miller has authored numerous technical articles and holds a Ph.D. from Northeastern University.", "area": "", "key": "ScottMiller", "prettyDate": "April 12"}, {"semester": "Spring ", "year": "2016", "date": "2016-04-07", "speaker": "Robert Zinkov", "website": "", "title": "Composing inference methods for probabilistic models", "affiliation": "Indiana University", "sponsor": "Yahoo!", "video": "", "abstract": "Probabilistic inference procedures are usually coded painstakingly from scratch, for each target model and each inference algorithm. In this talk, I will show how inference procedures can be posed as program transformations which transform one probabilistic model into another probabilistic model. These transformations allow us to generate programs which express exact and approximate inference, and allow us to compose multiple inference procedures over a single model. The resulting inference procedure runs in time comparable to a handwritten procedure.", "bio": "Rob Zinkov is a Research Scientist at Indiana University working with Chung-chieh Shan on probabilistic programming and Bayesian inference.", "area": "", "key": "RobertZinkov", "prettyDate": "April 07"}, {"semester": "Spring ", "year": "2016", "date": "2016-04-05", "speaker": "Waleed Ammar", "website": "", "title": "Towards universal analyzers of natural language", "affiliation": "CMU", "sponsor": "Yahoo!", "video": "", "abstract": "How can we enable computers to process natural language in multilingual settings (think airports, social media, etc.)? Thanks to decades of natural language processing (NLP) research, we have been able to develop language analyzers in many languages, including languages with little or no training data. I will review some of the key developments in multilingual NLP research, with an emphasis on syntax.  Despite this progress, the mainstream approach to developing multilingual NLP models (for high-resource languages) has been to independently train one model for each language, which is unsatisfactory for practical as well as theoretical reasons. To that end, I will describe a general framework for training language-universal models, with competitive results in two instantiations of this framework for dependency parsing and language modeling. ", "bio": "Waleed Ammar is finishing up his PhD at CMU and will soon be joining Allen Institute for Artificial Intelligence (AI2). Before the PhD, Waleed was a software engineer at the machine translation group at Microsoft Research. He received two tech transfer awards at Microsoft Research and the Google PhD fellowship in natural language processing.", "area": "", "key": "WaleedAmmar", "prettyDate": "April 05"}, {"semester": "Spring ", "year": "2016", "date": "2016-03-31", "speaker": "Hee-Tae Jung", "website": "", "title": "Learning Performance Models for Post-Stroke Therapy from Demonstration", "affiliation": "UMass CS", "sponsor": "Yahoo!", "video": "", "abstract": "The use of robots and games is becoming a popular trend in stroke rehabilitation research. Despite the acknowledged importance, however, research on evaluating the patient\u2019s qualitative motor performance, customizing the initial task workspace based on the patient\u2019s performance, and generating visualized performance reports of autonomous sessions for the therapist have received little attention. The essence of these is to model the therapist\u2019s decision criteria to evaluate the qualitative motor performance and to use such evaluation to assess difficulties in the different regions of the task workspace for the individual stroke patient. In this talk, first I will motivate the needs of such models by introducing the results of a single-subject case study, and then propose a computational framework to learn the necessary models from therapist's demonstration. The experiment results with two patients and two therapists suggest that the proposed framework is promising.", "bio": "Hee-Tae Jung is a PhD candidate at the College of Information and Computer Sciences, University of Massachusetts Amherst, and a member of the Perceptual Robotics Lab. He received his BS in Computer Science from Yonsei University, Korea in 2007 and MS in Computer Science from Stanford University, USA in 2009. His research focus is on developing and analyzing intelligent assistive technologies for the population with special needs. He is the recipient of the Robin Popplestone Scholarship and the Graduate School Dissertation Research Grant. He was selected as an ACM/IEEE Human-Robot Interaction (HRI) Pioneer in 2015 and was an elected PC Co-Chair for the ACM/IEEE HRI Pioneers Workshop 2016. He served as an editorial assistant for the Journal of Robotics and Autonomous Systems from 2013 through 2014.", "area": "", "key": "Hee-TaeJung", "prettyDate": "March 31"}, {"semester": "Spring ", "year": "2016", "date": "2016-03-24", "speaker": "Manzil Zaheer", "website": "", "title": "Exponential Stochastic Cellular Automata for Massively Parallel Inference", "affiliation": "CMU", "sponsor": "Yahoo!", "video": "", "abstract": "We propose an embarrassingly parallel, memory efficient inference algorithm for latent variable models in which the complete data likelihood is in the exponential family. The algorithm is a stochastic cellular automaton and converges to a valid maximum a posteriori fixed point. Applied to latent Dirichlet allocation we find that our algorithm is over an order of magnitude faster than the fastest current approaches. A simple C++/MPI implementation on a 4-node cluster sampling more than half a billion tokens per second. We process 3 billion documents and achieve predictive power competitive with collapsed Gibbs sampling and variational inference.  This work was done at Oracle labs with Michael L Wick, Jean-Baptiste Tristan and Guy L Steele. ", "bio": "Manzil Zaheer is a PhD student at Carnegie Mellon University, advised by Alexander Smola. Currently, he is a research intern at Oracle labs. He is broadly interested in machine learning. He works in the design and implementation of scalable machine learning algorithms for distributed and parallel architectures. He recently has been interested on recurrent neural networks, representation learning, and automatic theorem proving. One of his research aims is to solve the mismatch between statistical models and computational resources and develop scalable approaches able to handle enormous amounts in order to solve practical problems.", "area": "", "key": "ManzilZaheer", "prettyDate": "March 24"}, {"semester": "Spring ", "year": "2016", "date": "2016-03-17", "speaker": "Rachel Cummings", "website": "", "title": "Adaptive Learning with Robust Generalization Guarantees", "affiliation": "Caltech", "sponsor": "Yahoo!", "video": "", "abstract": "The traditional notion of generalization --- i.e., learning a hypothesis whose empirical error is close to its true error --- is surprisingly brittle. As has recently been noted [DFH+15b], even if several algorithms have this guarantee in isolation, the guarantee need not hold if the algorithms are composed adaptively. In this paper, we study three notions of generalization ---increasing in strength--- that are robust to post-processing and amenable to adaptive composition, and examine the relationships between them. We call the weakest such notion Robust Generalization. A second, intermediate, notion is the stability guarantee known as differential privacy. The strongest guarantee we consider we call Perfect Generalization. We prove that every hypothesis class that is PAC learnable is also PAC learnable in a robustly generalizing fashion, albeit with an exponential blowup in sample complexity. We conjecture that a stronger version of this theorem also holds that avoids any blowup in sample complexity (and, in fact, it would, subject to a longstanding conjecture [LW86, War03]). It was previously known that differentially private algorithms satisfy robust generalization. In this paper, we show that robust generalization is a strictly weaker concept, and that there is a learning task that can be carried out subject to robust generalization guarantees, yet cannot be carried out subject to differential privacy, answering an open question of [DFH+15a]. We also show that perfect generalization is a strictly stronger guarantee than differential privacy, but that, nevertheless, many learning tasks can be carried out subject to the guarantees of perfect generalization.", "bio": "Rachel Cummings is a Ph.D. candidate in Computing and Mathematical Sciences at the California Institute of Technology. She received her B.A. degrees in Mathematics and Economics from the University of Southern California and her M.S. degree in Computer Science from Northwestern University. Her research interests lie in the intersection of computer science and economics, specifically problems surrounding algorithmic game theory, data privacy, and learning theory. She won the Best Paper Award at DISC 2014, and she is the recipient of a Simons Award for Graduate Students in Theoretical Computer Science.", "area": "", "key": "RachelCummings", "prettyDate": "March 17"}, {"semester": "Spring ", "year": "2016", "date": "2016-02-19", "speaker": "Manuela Veloso", "website": "http://www.cs.cmu.edu/~mmv", "title": "[Robotics-MLFL] Robot Autonomy: Data Collection and Interaction with Humans", "affiliation": "CMU", "sponsor": "Yahoo!", "video": "", "abstract": "We research on autonomous mobile robots with a seamless integration of perception, cognition, and action. In this talk, I will briefly introduce our CoBot service robots, who consistently move in our buildings to fulfill user requests. I will then introduce the CoBot robots as novel mobile data collectors of vital information of our buildings, and present their data representation, their active data gathering algorithm, and the particular use of the gathered WiFi data by CoBot. I will further present a detailed overview of multiple contributions in terms of human-robot interaction, and detail the use and planning for language-based complex commands. I will then conclude with some philosophical and technical points on my view on the future of autonomous robots in our environments.", "bio": "Manuela Maria Veloso is the Herbert A. Simon Professor in Computer Science and Robotics at Carnegie Mellon University. She was the President of AAAI (Association for the Advancement of Artificial Intelligence) until 2014, and the co-founder and a Past President of the RoboCup Federation. She is a fellow of AAAI, IEEE, and AAAS. She founded and directs the CORAL research laboratory, for the study of autonomous agents that Collaborate, Observe, Reason, Act, and Learn, http://www.cs.cmu.edu/~coral. Professor Veloso and her students have worked with a variety of autonomous robots, including mobile service robots and soccer robots. The CoBot service robots have autonomously navigated for more than 1,000km in multi-floor office buildings. See http://www.cs.cmu.edu/~mmv for further information, including publications.", "area": "", "key": "ManuelaVeloso", "prettyDate": "February 19"}, {"semester": "Spring ", "year": "2016", "date": "2016-02-04", "speaker": "Edo Liberty", "website": "", "title": "Online Data mining: PCA and K-Means", "affiliation": "Yahoo!", "sponsor": "Yahoo!", "video": "", "abstract": "Algorithms for data mining, unsupervised machine learning and scientific computing were traditionally designed to minimize running time in the batch setting (random access to memory). In recent years, a significant amount of research is devoted to producing scaleable algorithms for the same problems. A scaleable solution assumes some limitation on data access and/or compute model. Some well known models include map reduce, message passing, local computation, pass efficient, streaming and others. In this talk we argue for the need to consider the online model in data mining tasks. In an online setting, the algorithm receives data points one by one and must make some decision immediately (without examining the rest of the input). The quality of the algorithm's decisions is compared to the best possible in hindsight. Note that no stochasticity assumption is made about the input. While practitioners are well aware of the need for such algorithms, this setting was mostly overlooked by the academic community. Here, we will review new results on online k-means clustering and online Principal Component Analysis (PCA).", "bio": "Edo Liberty is a research director and Yahoo Labs and leads its Scalable Machine Learning group. He received his BSc in Computer Science and Physics from Tel Aviv University and his PhD in Computer Science from Yale. After his postdoctoral position at Yale in the Applied Math department he co-founded a New York based startup. Since 2009 he has been with Yahoo Labs. His research focuses on the theory and practice of large scale data mining.", "area": "", "key": "EdoLiberty", "prettyDate": "February 04"}, {"semester": "Spring ", "year": "2016", "date": "2016-01-28", "speaker": "Arya Mazumdar", "website": "", "title": "Neural Auto-associative Memory via Sparse Recovery", "affiliation": "UMass CS", "sponsor": "Yahoo!", "video": "", "abstract": "An associative memory is a structure learned from a dataset M of vectors (signals) in a way such that, given a noisy version of one of the vectors as input, the nearest valid vector from M (nearest neighbor) is provided as output, preferably via a fast iterative algorithm. Traditionally, neural networks are used to model the above structure. In this talk we propose a model of associative memory based on sparse recovery of signals. Our basic premise is simple. Given a dataset, we learn a set of linear constraints that every vector in the dataset must satisfy. Provided these linear constraints possess some special properties, it is possible to cast the task of finding nearest neighbor as a sparse recovery problem. Assuming generic random models for the dataset, we show that it is possible to store exponential number of n-length vectors in a neural network of size O(n). Furthermore, given a noisy version of one of the stored vectors corrupted in linear number of coordinates, the vector can be correctly recalled using a neurally feasible algorithm.  Instead of assuming the above subspace model for the dataset, we might assume that the data is a sparse linear combination of vectors from a dictionary (sparse-coding). This very relevant model poses significant challenge in designing associative memory and is one of the main problems we will describe. (This is a joint work with Ankit Singh Rawat (CMU) and was presented in part at NIPS'15). ", "bio": "Arya Mazumdar is an assistant professor in the College of Information and Computer Science at the University of Massachusetts, Amherst. From Jan 2013 till recently Arya used to be an assistant professor at University of Minnesota-Twin Cities, and form Aug 2011 to Dec 2012, he was a postdoctoral scholar at Massachusetts Institute of Technology. He received his Ph.D. from University of Maryland, College Park, in 2011. Arya is a recipient of 2014-15 NSF CAREER award and the 2010 IEEE ISIT Student Paper Award. He is also the recipient of the Distinguished Dissertation Award, 2011, at the University of Maryland. He spent the summers of 2008 and 2010 at the Hewlett-Packard Laboratories, Palo Alto, CA, and IBM Almaden Research Center, San Jose, CA, respectively. Arya's research interests include Information and Coding Theory and their applications to networked systems and learning.", "area": "", "key": "AryaMazumdar", "prettyDate": "January 28"}, {"semester": "Spring ", "year": "2016", "date": "2016-01-21", "speaker": "Karl Stratos", "website": "", "title": "Spectral Learning of Lexical Representations in Natural Language Processing", "affiliation": "Columbia", "sponsor": "Yahoo!", "video": "", "abstract": "There has recently been much success in deriving rich, distributional representations of words from large quantities of unlabeled text. They include discrete representations such as agglomerative clusters (e.g., Brown clusters) and real-valued vectors such as word embeddings (e.g., word2vec). These lexical representations can be deployed off-the-shelf in a wide range of language processing tasks to help the model generalize at the word level.  In this talk, I will present a simple and efficient algorithm for learning such representations. The algorithm is spectral---i.e., it involves the use of singular value decomposition (SVD), and it comes with a theoretical guarantee of recovering the underlying model given enough data from the model. In addition, we find that our algorithm can be much more scalable than other methods in practice. For example, it can be up to 10x faster than the Brown clustering algorithm in wall-clock time while delivering competitive lexical representations. ", "bio": "Karl Stratos is a PhD student at Columbia University, advised by Michael Collins. He is broadly interested in machine learning techniques and their applications in natural language processing. His recent focus has been on spectral algorithms, representation learning, and structured prediction. One of his research aims is to develop practical approaches to leveraging enormous amounts of unlabeled data.", "area": "", "key": "KarlStratos", "prettyDate": "January 21"}, {"semester": "Fall", "year": "2015", "date": "2015-12-03", "speaker": "Lawson L.S. Wong", "website": "", "title": "Learning the State of the World: Object-based World Modeling for Mobile-Manipulation Robots", "affiliation": "MIT", "sponsor": "Yahoo!", "video": "", "abstract": "Mobile-manipulation robots performing service tasks in human-centric indoor environments need to know about relevant aspects of their spatial surroundings. However, service robots rarely know the exact state of the world, unlike industrial robots in structured environments. Additionally, as the world is shared with humans, uncertainty in the complete state of the world is inevitable over time. Mobile-manipulation robots therefore need to continuously perform state estimation, using perceptual information to maintain a representation of the state, and its uncertainty, of task-relevant aspects of the world. Because indoor tasks frequently require interacting with objects, objects should be given critical emphasis in spatial representations for service robots. In my Ph.D. work, I propose a world model based on objects, their semantic attributes (task-relevant properties such as type and pose), and their geometric realizations in the physical world.  Objects are challenging to keep track of because there is significant uncertainty in their states. Object detection and recognition using robotic vision is still error-prone. Objects can also be inherently ambiguous because they have similar attributes. Besides detection noise, other agents may change the state of the world. Compounded over multitudes of objects and long temporal horizons, the above sources of uncertainty give rise to a challenging estimation problem. Fortunately, most objects do not change quickly, and sensing is relatively cheap, so we can leverage information from multiple diverse snapshots of similar world states. However, putting the information together introduces a data association problem, which I tackle with constrained Bayesian nonparametric models. By carefully aggregating information across different viewpoints, times, and sensors, I show that robots can reduce their uncertainty in the state of the world and maintain more accurate object-based world models. ", "bio": "Lawson L.S. Wong is a Ph.D. candidate at the Massachusetts Institute of Technology, working in the Learning and Intelligent Systems Group under the supervision of Leslie Pack Kaelbling and Tom\u00e1s Lozano-P\u00e9rez. Previously, he received his B.S. (with Honors) and M.S. in Computer Science at Stanford University, both in 2009. His current research focuses on acquiring, representing, and estimating knowledge about the world that an autonomous robot may find useful. More broadly, Lawson is interested in, and follows many topics within, the fields of robotics, machine learning, and artificial intelligence. He was recently awarded a AAAI Robotics Student Fellowship and a Croucher Foundation Fellowship for Postdoctoral Research. He will begin his postdoctoral appointment at Brown University in 2016, working with Stefanie Tellex.", "area": "", "key": "LawsonL.S.Wong", "prettyDate": "December 03"}, {"semester": "Fall", "year": "2015", "date": "2015-11-19", "speaker": "David Blei", "website": "", "title": "Scaling and Generalizing Variational Inference", "affiliation": "Columbia", "sponsor": "Yahoo!", "video": "", "abstract": "Latent variable models have become a key tool for the modern statistician, letting us express complex assumptions about the hidden structures that underlie our data. Latent variable models have been successfully applied in numerous fields.  The central computational problem in latent variable modeling is posterior inference, the problem of approximating the conditional distribution of the latent variables given the observations. Posterior inference is central to both exploratory tasks and predictive tasks. Approximate posterior inference algorithms have revolutionized Bayesian statistics, revealing its potential as a usable and general-purpose language for data analysis.  Bayesian statistics, however, has not yet reached this potential. First, statisticians and scientists regularly encounter massive data sets, but existing approximate inference algorithms do not scale well. Second, most approximate inference algorithms are not generic; each must be adapted to the specific model at hand.  In this talk I will discuss our recent research on addressing these two limitations. I will describe stochastic variational inference, an approximate inference algorithm for handling massive data sets. I will demonstrate its application to probabilistic topic models of text conditioned on millions of articles. Then I will discuss black box variational inference. Black box inference is a generic algorithm for approximating the posterior. We can easily apply it to many models with little model-specific derivation and few restrictions on their properties. I will demonstrate its use on a suite of nonconjugate models of longitudinal healthcare data.  This is joint work based on these two papers:  M. Hoffman, D. Blei, J. Paisley, and C. Wang. Stochastic variational inference. Journal of Machine Learning Research, 14:1303-1347.     http://www.cs.columbia.edu/~blei/papers/HoffmanBleiWangPaisley2013.pdf  R. Ranganath, S. Gerrish, and D. Blei. Black box variational inference. Artificial Intelligence and Statistics, 2014.     http://www.cs.columbia.edu/~blei/papers/RanganathGerrishBlei2014.pdf ", "bio": "David Blei is a Professor of Statistics and Computer Science at Columbia University, and a member of the Columbia Data Science Institute. His research is in statistical machine learning, involving probabilistic topic models, Bayesian nonparametric methods, and approximate posterior inference algorithms for massive data. He works on a variety of applications, including text, images, music, social networks, user behavior, and scientific data. David has received several awards for his research, including a Sloan Fellowship (2010), Office of Naval Research Young Investigator Award (2011), Presidential Early Career Award for Scientists and Engineers (2011), Blavatnik Faculty Award (2013), and ACM-Infosys Foundation Award (2013).", "area": "", "key": "DavidBlei", "prettyDate": "November 19"}, {"semester": "Fall", "year": "2015", "date": "2015-11-12", "speaker": "David Duvenaud", "website": "", "title": "Automatically Constructing Models, and Automatically Explaining Them, too.", "affiliation": "Harvard", "sponsor": "Yahoo!", "video": "", "abstract": "How could an artificial intelligence do statistics? It would need an open-ended language of models, and a way to search through and compare those models. Even better would be a system that could explain the different types of structure found, even if that type of structure had never been seen before. This talk presents a prototype of such a system, which builds structured Gaussian processes regression models by combining covariance kernels to build a custom model for each dataset. The resulting models can be broken down into relatively simple components, and surprisingly, it's not hard to write code that automatically describes each component, even for novel combinations of kernels. The result is a procedure that takes in a dataset, and outputs a report with plots and English descriptions of the different types of structure found in that dataset. I'll also talk about advances in black-box stochastic variational inference methods, which have the potential to open the door to even broader model classes.", "bio": "David Duvenaud is a postdoctoral researcher in the Harvard School of Applied Sciences and Engineering. He obtained his doctorate in machine learning at the University of Cambridge. His research has focused on probabilistic models of functions, with applications to forecasting, numeric computations, and deep learning. David previously worked on machine vision at Google research, and co-founded Invenia, an energy forecasting and trading firm.", "area": "", "key": "DavidDuvenaud", "prettyDate": "November 12"}, {"semester": "Fall", "year": "2015", "date": "2015-11-05", "speaker": "Jason Yosinski", "website": "", "title": "Training and Understanding Deep Neural Networks for Robotics, Design, and Perception", "affiliation": "Cornell", "sponsor": "Yahoo!", "video": "", "abstract": "Artificial Neural Networks (ANNs) form a powerful class of models with both theoretical and practical advantages. Networks with more than one hidden layer (\"deep\" neural networks) compute multiple functions on later layers that share the use of intermediate results computed on earlier layers. This compositional, hierarchical structure provides a strong bias, or regularization, toward solutions that seem to work well on a large variety of real-world problems.  In this talk I will begin by showing a few examples of how this general compositional bias can excel at such diverse tasks as designing robot gaits and 3D objects. I will then discuss a few simple experiments that shed light on the inner workings of neural nets trained to classify images. The first study examines the computation performed by the entire set of neurons on a layer in a network, and subsequent work illuminates the computation performed by individual units, and finally the computation performed by the network as a whole. The experiments taken together reveal some surprising behaviors of large networks and lead to a greater understanding and intuition for the computation performed by deep neural nets. ", "bio": "Jason Yosinski is a PhD student and NASA Space Technology Research Fellow working on machine learning and computer vision, mostly at the Cornell Creative Machines Lab, but sometimes at the University of Montreal, the Jet Propulsion Laboratory, and Google DeepMind. His research focuses on building and understanding neural network models that allow robots to learn how to walk and computers to perceive the visual world. In grad school he helped create the first artificially intelligent guest to be interviewed on NPR, and his work in AI has been featured in Fast Company, The Economist, TEDx, and the BBC. Before coming to Cornell, Mr. Yosinski graduated from Caltech, worked at a statistics startup, and spent a year developing a program in Pasadena that tricks middle school students into learning math while they play with robots.", "area": "", "key": "JasonYosinski", "prettyDate": "November 05"}, {"semester": "Fall", "year": "2015", "date": "2015-10-29", "speaker": "Zornitsa Kozareva", "website": "", "title": "What's in a Web Query?", "affiliation": "Yahoo!", "sponsor": "Yahoo!", "video": "", "abstract": "Over the years search paradigm has shifted from document retrieval to deeper user intent understanding. Today\u2019s users are no longer satisfied with seeing a list of relevant documents, instead they want to complete tasks and take actions on them. The question I will address in this talk is how to build an automated user intent understanding system, where given a query like \"Mia\" the users see relevant intents such as \"buy latest album of the singer\", or \"check-in flight to Miami\". I will begin by introducing the task and main challenges with semantic representations. Then, I will describe query categorization and tagging models used for intent prediction. Finally, by running experiments and evaluations on the shopping, movie, restaurant and sport domains, I will highlight current capabilities and limitations.", "bio": "Dr. Zornitsa Kozareva is a Senior Manager of the Query Processing and User Intent Understanding group at Yahoo! Labs. She leads the team powering queries for Mobile Search and Advertisement. Prior to that she was a Research Assistant Professor at the University of Southern California and a Research Scientist in the Natural Language group at the Information Sciences Institute. She received her PhD with Cum Laude from the University of Alicante, Spain. Her research interests lie in Web-based knowledge acquisition, semantics, ontology population, multilingual information extraction and sentiment analysis. Dr. Kozareva is a recipient of the RANLP young scientist award, and has organized the SemEval challenges on paraphrases, sentiment analysis, causality detection and relation identification.", "area": "", "key": "ZornitsaKozareva", "prettyDate": "October 29"}, {"semester": "Fall", "year": "2015", "date": "2015-10-27", "speaker": "Greg Shakhnarovich", "website": "", "title": "Zoom-out features for image understanding", "affiliation": "TTI", "sponsor": "Yahoo!", "video": "", "abstract": "I will describe a novel feed-forward architecture, which maps small image elements (pixels or superpixels) to rich feature representations extracted from a sequence of nested regions of increasing extent. These regions are obtained by \"zooming out\" from the superpixel all the way to scene-level resolution. Applied to semantic segmentation, our approach exploits statistical structure in the image and in the label space without setting up explicit structured prediction mechanisms, and thus avoids complex and expensive inference. Instead superpixels are classified by a feedforward multilayer network with skip-layer connections spanning the zoomout levels. Using off-the-shelf network, pre-trained on ImageNet classification task, this zoom-out architecture achieves near state-of-the-art accuracy on the PASCAL VOC 2012 test set. Joint work with Mohammadreza Mostajabi and Payman Yadollahpour.", "bio": "Since February 2008, I am an Assistant Professor at TTI-Chicago, a philanthropically endowed academic computer science institute located on the University of Chicago campus. I also hold a part-time faculty appointment at the University of Chicago Department of Computer Science. Prior to coming to TTI-Chicago, I was a post-doctoral researcher at the Department of Computer Science of Brown University where I worked with Michael Black. I received my PhD degree at MIT where I worked at CSAIL with Trevor Darrell on computer vision and machine learning. My thesis topic was Learning Task-Specific Similarity. Before coming to MIT, I was a graduate student in the Computer Science Department of the Technion, Israel Institute of Technology in Haifa, Israel, where I got my MSc thesis under the advisement of Ran El-Yaniv and Yoram Baram. I got my undergraduate degree in Math and CS from Hebrew University in Jerusalem, Israel. ", "area": "", "key": "GregShakhnarovich", "prettyDate": "October 27"}, {"semester": "Fall", "year": "2015", "date": "2015-10-19", "speaker": "James Zou", "website": "", "title": "Machine learning for ubiquitous genomics and precision medicine", "affiliation": "Microsoft Research", "sponsor": "Yahoo!", "video": "", "abstract": "What can we learn about our societies and ourselves by decoding the genomes of hundreds of thousands of individuals? I will describe two projects that address complementary aspects of this question. In the first part of the talk, I will discuss integrating genomics with computational social sciences to characterize human mating patterns over the last few generations. The second part of the talk will investigate how we can estimate harmful mutations that are present in the general population but have not been observed yet. Patterns that arise from both analyses have significant implications for understanding the dynamics of human diseases and provide a roadmap for precision medicine. I'll highlight the machine learning methods that we've developed to tackle both projects. This talk will be accessible to a general CS audience.", "bio": "James Zou is a postdoc at MSRNE. He received his Ph.D. from Harvard in 2014 and was recently a Simons fellow at U.C. Berkeley. He is broadly interested in machine learning and applications in understanding human evolution and diseases.", "area": "", "key": "JamesZou", "prettyDate": "October 19"}, {"semester": "Fall", "year": "2015", "date": "2015-10-15", "speaker": "Zhaoliang Lun", "website": "", "title": "Learning Style Similarity of Shapes", "affiliation": "UMass CS", "sponsor": "Yahoo!", "video": "", "abstract": "The human perception of stylistic similarity transcends structure and function - for instance, a bed and a dresser may share a common style. I will present an algorithm that learns a style similarity measure such that it is aligned with human perception. Our measure is inspired by observations about style-similarity in art history literature, which point to the presence of similarly shaped, salient, geometric elements as a key indicator of stylistic similarity between structurally different objects. We translate these observations into an algorithmic measure by quantifying in geometric terms what makes geometric elements be perceived as similarly shaped, employing this quantification to detect similar style elements on the analyzed shapes, and finally collating the element-level geometric similarity measurements into an object-level style measure consistent with human perception. To achieve this consistency we employ crowd-sourcing and machine learning to quantify the different components of our measure. I will conclude my talk by presenting ongoing work on automatic style-driven shape synthesis. ", "bio": "Zhaoliang Lun is a fifth year PhD student at the College of Information and Computer Sciences at UMass Amherst, working with Prof. Evangelos Kalogerakis and Prof. Rui Wang. His research focuses on 3D shape analysis, modeling and synthesis, and in particular machine learning techniques for geometry processing. His research goal is to develop new tools that will enable effective retrieval of shapes from large 3D model collections, and easy creation of new 3D models for casual users. Before coming to UMass, he obtained a B.S. degree in Computer Science at Fudan University in China.", "area": "", "key": "ZhaoliangLun", "prettyDate": "October 15"}, {"semester": "Fall", "year": "2015", "date": "2015-10-08", "speaker": "Laura Haas", "website": "", "title": "Accelerating the Discovery of Insights from Data", "affiliation": "IBM", "sponsor": "Yahoo!", "video": "", "abstract": "Today, businesses and scientists alike struggle to get to the value in their data. Their challenges include finding and gaining access to the data they need, \u201cwrangling\u201d the data into a form they can use, and setting up the systems and software to be used \u2013 all before even tackling the analysis. With no coordination, multiple groups may re-do the heavy lifting to ready the data for use, or struggle to figure out what data is already available. Further, the skills required to get from raw data to insight span a broad range from systems to data management, optimization, statistics, algorithms, story-telling and visualization. Rarely can you find such multi-disciplinary expertise in one team \u2013 it is typically scattered across multiple business units or departments.  The IBM Research Accelerated Discovery Lab is a unique, collaborative environment specifically designed to facilitate complex analytic projects by tackling these challenges. One of the key elements of the Lab is the notion of a data lake, accessed through an easy-to-use, collaborative tool called LabBook, which, together with new practices such as datastorming, helps bridge the gaps between experts from different disciplines. We will highlight some successful applications of these technologies, from diverse fields such as medical research, food safety, social media analytics and predictive equipment maintenance. ", "bio": "Laura Haas is an IBM Fellow and Director of IBM Research\u2019s Accelerated Discovery Lab. She was Director of Computer Science at IBM\u2019s Almaden Research Center from 2005 to 2011, and had worldwide responsibility for IBM Research\u2019s exploratory science program from 2009 through 2013. From 2001-2005, she led the Information Integration Solutions architecture and development teams in IBM's Software Group. Previously, Dr. Haas was a research staff member and manager at Almaden. She is best known for her work on the Starburst query processor, from which DB2 LUW was developed, on Garlic, a system which allowed integration of heterogeneous data sources, and on Clio, the first semi-automatic tool for heterogeneous schema mapping. She has received several IBM awards for Outstanding Innovation and Technical Achievement, an IBM Corporate Award for information integration technology, the Anita Borg Institute Technical Leadership Award, and the ACM SIGMOD Codd Innovation Award. Dr. Haas was Vice President of the VLDB Endowment Board of Trustees from 2004-2009, and is a member of the National Academy of Engineering and the IBM Academy of Technology, an ACM Fellow, a Fellow of the American Academy of Arts and Sciences, and Vice Chair of the board of the Computing Research Association.", "area": "", "key": "LauraHaas", "prettyDate": "October 08"}, {"semester": "Fall", "year": "2015", "date": "2015-10-01", "speaker": "Karthik Narasimhan2015", "website": "", "title": "Language Understanding for Text-based Games Using Deep Reinforcement Learning", "affiliation": "MIT", "sponsor": "Yahoo!", "video": "", "abstract": "In this paper, we consider the task of learning control policies for text-based games. In these games, all interactions in the virtual world are through text and the underlying state is not observed. The resulting language barrier makes such environments challenging for automatic game players. We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback. This framework enables us to map text descriptions into vector representations that capture the semantics of the game states. We evaluate our approach on two game worlds, comparing against baselines using bag-of-words and bag-of-bigrams for state representations. Our algorithm outperforms the baselines on both worlds demonstrating the importance of learning expressive representations.   ", "bio": "I'm a fourth year PhD student at CSAIL, working with Prof. Regina Barzilay. I am primarily interested and work in the area of Computational Semantics, specifically in language understanding, grounding and machine comprehension. My goal is to develop richer representations for meaning that can capture its variable nature and context sensitivity, while keeping learning tractable. Previously, I have worked on computational morphology - applied to Keyword Spotting and unsupervised analysis using Morphological Chains. I have a B.Tech in Computer Science from IIT Madras (2012) and an SM in Computer Science from MIT (2014).", "area": "", "key": "KarthikNarasimhan2015", "prettyDate": "October 01"}, {"semester": "Fall", "year": "2015", "date": "2015-09-24", "speaker": "Xialoan Wang", "website": "", "title": "What your Knowledge Base is Missing, and Where to Find It", "affiliation": "UMass CS", "sponsor": "Yahoo!", "video": "", "abstract": "Knowledge bases, collections of a massive number of facts (RDF triples) in diverse topics, have been widely used in applications, including enhancing search results for multiple major search engines. However, existing knowledge bases are incomplete, with many facts missing, in particular, little-known, long-tailed facts, such as Snow White\u2019s age and the PC chairs of ICML 2015. Augmenting knowledge bases is crucial for the correctness of the applications that use them, and for the quality of the user experience. Completing knowledge bases by adding new facts is not easy. Even though current information extraction systems extract facts from web sources automatically, determining what to extract and from where, and evaluating the quality of the extracted facts require manual effort and are highly dependent on the help of domain experts. In this work, our goal is to reduce this manual effort, by automatically identifying high-quality sources for missing facts. We develop a technique to recommend data-source and topic pairs using automatically generated facts (triples) from multiple information extraction systems. We define a profit function to quantify the quality of a candidate data-source and topic pair, propose a highly scalable summarization pipeline to derive high-profit recommendations, and further evaluate the preliminary results.  This work is ongoing and we welcome suggestions and feedback. ", "bio": "Xiaolan Wang is a third year PhD student in the College of Information and Computer Sciences, University of Massachusetts, Amherst, advised by Prof. Alexandra Meliou. Her research interests include database management, data cleaning, and data integration. She enjoys working on projects with strong theoretical grounding and practical impact. Xiaolan was awarded a Google PhD fellowship in 2015.", "area": "", "key": "XialoanWang", "prettyDate": "September 24"}, {"semester": "Fall", "year": "2015", "date": "2015-09-10", "speaker": "Bo Liu", "website": "", "title": "Proximal Gradient Temporal Difference Learning", "affiliation": "UMass CS", "sponsor": "Yahoo!", "video": "", "abstract": "In this paper, we show for the first time how gradient TD (GTD) reinforcement learning methods can be formally derived as true stochastic gradient algorithms, not with respect to their original objective functions as previously attempted, but rather using derived primal-dual saddle-point objective functions. We then conduct a saddle-point error analysis to obtain finite-sample bounds on their performance. Previous analyses of this class of algorithms use stochastic approximation techniques to prove asymptotic convergence, and no finite-sample analysis had been attempted. Two novel GTD algorithms are also proposed, namely projected GTD2 and GTD2-MP, which use proximal \u201cmirror maps\u201d to yield improved convergence guarantees and acceleration, respectively. The results of our theoretical analysis imply that the GTD family of algorithms are comparable and may indeed be preferred over existing least squares TD methods for off-policy learning, due to their linear complexity. We provide experimental results showing the improved performance of our accelerated gradient TD methods. ", "bio": "Bo Liu is a Ph.D. candidate in School of Computer Science, University of Massachusetts Amherst, working under Prof. Sridhar Mahadevan. His primary research area covers machine learning, deep learning, stochastic optimization and their applications to BIGDATA. In the summers of 2011 and 2013, he enjoyed interning at eBay Search Science and Amazon Machine Learning, respectively.", "area": "", "key": "BoLiu", "prettyDate": "September 10"}, {"semester": "Spring ", "year": "2015", "date": "2015-05-07", "speaker": "Maximilian Nickel", "website": "", "title": "Multilinear Embeddings of Knowledge Graphs", "affiliation": "MIT", "sponsor": "Yahoo!", "video": "", "abstract": "Knowledge graphs, which store facts in form of entities and their relationships, have found important applications in areas such as Web search and question answering. Recently, machine learning for knowledge graphs has received considerable attention as it can be used to discover previously unknown facts, to categorize and disambiguate entities, and to support automated knowledge base construction. However, knowledge graphs pose also unique challenges for machine learning, due to their size and their complex, relational structure.  In this talk, I will present a family of latent feature models for knowledge graphs (and graph-structured data in general) that allow to create complex statistical models of graphs with millions of entities and billions of known facts. I will discuss how the proposed approach exploits relational information through its multilinear latent variable structure and how it can be applied to a wide range of tasks including link prediction, entity resolution, and link-based clustering. In addition, I will show briefly how the model can be used to answer complex probabilistic queries on knowledge graphs and how it can be combined with observable variable models to further increase its predictive performance and scalability. ", "bio": "Maximilian Nickel is a postdoctoral fellow at MIT where he is with the McGovern Institute for Brain Research and the Laboratory for Computational and Statistical Learning. In 2013, he received his PhD with summa cum laude from the Ludwig Maximilian University Munich. From 2010 to 2013 he worked as a research assistant at Siemens Corporate Technology. His research interests center around machine learning from relational and graph-structured knowledge representations and its applications in artificial intelligence, automated knowledge base construction, and question answering.", "area": "", "key": "MaximilianNickel", "prettyDate": "May 07"}, {"semester": "Spring ", "year": "2015", "date": "2015-05-05", "speaker": "Mo Yu", "website": "", "title": "Structure Representations with Feature-rich Compositional Embedding Models", "affiliation": "Johns Hopkins", "sponsor": "Yahoo!", "video": "", "abstract": "Word embeddings, a popular type of distributed word representations learned by neural language models, have become a popular way to handle the data sparsity problem in Natural Language Processing (NLP). However, word embeddings are not sufficient for capturing structure information in languages, which are critical for many NLP tasks. This talk focuses on composing structure representations via word embeddings and a minimal set of non-lexical features. Specifically, we proposed the Feature-rich Compositional Embedding Models (FCM), which learns to build specific transformation for each word according to its contextual information, and uses the transformations to derive the structure embeddings from all the component word embeddings.  Furthermore, we show that above model can be viewed as representing features as tensors, which can be further improved with low-rank tensor approximations and by joint-training on labeled and unlabeled data. Experiments, including (1) relation extraction on ACE2005, (2) PP-attachment on WSJ and (3) phrase similarity on PPDB, show that the proposed methods can out-perform both the other feature learning models based on deep networks or word embeddings, and the traditional log-linear models based on feature engineering. ", "bio": "Mo Yu is now a visiting student at Johns Hopkins University and a fourth-year Ph.D. student in the Department of Computer Science at Harbin Institute of Technology. He is now working with Professor Mark Dredze and Professor Raman Arora on Representation Learning methods for NLP tasks such as relation extraction, syntactic parsing and semantic compositions.  Prior to JHU, he was visiting Microsoft Research Asia in the year 2008 and 2010, working on Content-based Image Retrieval (CBIR) and target-dependent sentiment analysis, respectively, and was visiting Baidu NLP group during the year 2012-2013, working on Deep Learning for Natural Language Processing and Dependency Parsing. ", "area": "", "key": "MoYu", "prettyDate": "May 05"}, {"semester": "Spring ", "year": "2015", "date": "2015-04-23", "speaker": "Rob Platt", "website": "", "title": "Robot Grasping of Novel Objects in Dense Clutter", "affiliation": "Northeastern University", "sponsor": "Yahoo!", "video": "", "abstract": "A key challenge in robot grasping is detecting where in a scene to move the hand in order to grasp novel objects. Typically, this is handled using sliding window methods similar to those used in computer vision for object detection tasks. However, this approach ignores significant geometric structure in the problem. In this talk, I will introduce a new method of encoding grasp detection as a machine learning problem that leverages knowledge about the geometry of grasping. Our key insight is to recognize that if we were given a \"perfect\" point cloud that contained points on all exposed object surfaces, then it would be possible to detect grasps using geometric reasoning alone. It is only because real-world point clouds contain significant occlusions that it is necessary to use machine learning at all. This perspective enables us to use geometry to prune the hypothesis space and to focus machine learning on predicting the presence of occluded grasp geometries. This method performs well in practice. We get high accuracies on test sets and obtain grasp success rates for novel objects near 90% in real robot experiments. Of particular interest is the fact that we perform particularly well in dense clutter. Our grasping system is available as a ROS package and is among the most effective systems for novel object grasping available.", "bio": "Robert Platt is an Assistant Professor of Computer Science at Northeastern University. Prior to coming to Northeastern, he was a Research Scientist at MIT and a technical lead at NASA Johnson Space Center, where he helped lead the development of the control and autonomy subsystems of Robonaut 2, the first humanoid robot in space. He is an inventor on more than 18 US patents or patent applications. He earned his PhD in Computer Science from the University of Massachusetts, Amherst. Professor Platt is interested in developing robots that can function robustly alongside people in the uncertain everyday world. He is particularly interested in the planning, control, and perception algorithms that could enable a robot to assist people in the context of manipulation or assembly work. His work has applications in a variety of areas including human-robot interaction, health care, assisted living, personal robotics, manufacturing and package handling, and space robotics. ", "area": "", "key": "RobPlatt", "prettyDate": "April 23"}, {"semester": "Spring ", "year": "2015", "date": "2015-04-16", "speaker": "Jennifer Listgarten", "website": "", "title": "Methods for Genome and Epigenome-Wide Association Studies", "affiliation": "Microsoft Research", "sponsor": "Yahoo!", "video": "", "abstract": "Understanding the genetic underpinnings of disease is important for screening, treatment, drug development, and basic biological insight. Genome-wide associations, wherein individual or sets of genetic markers are systematically scanned for association with disease are one window into disease processes. Naively, these associations can be found by use of a simple statistical test. However, a wide variety of confounders lie hidden in the data, leading to both spurious associations and missed associations if not properly addressed. These confounders include population structure, family relatedness, cell type heterogeneity, and environmental confounders. I will discuss the state-of-the art approaches (based on linear mixed models) for conducting these analyses, in which the confounders are automatically deduced, and then corrected for, by the data and model.", "bio": "Jennifer Listgarten took a long and winding road to find her current area of interest in computational biology. She started off with a Physics degree, followed by a Master\u2019s in Computer Vision before completing a Ph.D. in Machine Learning at the University of Toronto with advisors Sam Roweis and Radford Neal. Within computational biology, Jennifer is interested in methods development, especially using insights from machine learning along with more traditional applied statistics. She also has an interest in application of these methods to discover new biological/medical insights. Jennifer has worked in a broad set of domain areas including gene expression studies, LC-MS proteomics, immunoinformatics, statistical genetics, and epigenetics. She is currently also starting to explore topics related to cancer and wearables.", "area": "", "key": "JenniferListgarten", "prettyDate": "April 16"}, {"semester": "Spring ", "year": "2015", "date": "2015-04-14", "speaker": "Dani Yogatama", "website": "", "title": "Bring Your Own Model: Model-Agnostic Improvements in NLP", "affiliation": "CMU", "sponsor": "Yahoo!", "video": "", "abstract": "The majority of NLP research focuses on improving NLP systems by designing better model classes (e.g., non-linear models, latent variable models). In this talk, I will describe a complementary approach based on incorporation of linguistic bias and optimization of text representations that is applicable to several model classes. First, I will present a structured regularizer that is suitable for the problem when only some parts of an input are relevant to the prediction task (e.g., sentences in text, entities in scenes of images) and an efficient algorithm based on the alternating direction method of multipliers to solve the resulting optimization problem. I will then show how such regularizer can be used to incorporate linguistic structures into a text classification model. In the second part of the talk, I will present our first step towards building a black box NLP system that automatically chooses the best text representation for a given dataset by treating it as a global optimization problem. I will also briefly describe an improved algorithm that can generalize across multiple datasets for faster optimization. I will conclude by discussing how such a framework can be applied to other NLP problems.", "bio": "Dani Yogatama is a fifth-year PhD student in the Language Technologies Institute of the School of Computer Science at Carnegie Mellon University. He works with Professor Noah Smith on designing better machine learning methods for natural language processing. Prior to CMU, he was a Monbukagakusho fellow at the University of Tokyo.", "area": "", "key": "DaniYogatama", "prettyDate": "April 14"}, {"semester": "Spring ", "year": "2015", "date": "2015-04-02", "speaker": "Jason Weston", "website": "", "title": "Memory Networks", "affiliation": "Facebook AI Research", "sponsor": "Yahoo!", "video": "", "abstract": "We describe a new class of learning models called memory networks. Memory networks reason with inference components combined with a long-term memory component; they learn how to use these jointly. The long-term memory can be read and written to, with the goal of using it for prediction. We investigate these models in the context of question answering (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. We evaluate them on a large-scale QA task, and a set of smaller, but more complex, toy tasks generated from a simulated world. In the latter, we show the reasoning power of such models by chaining multiple supporting sentences to answer questions that require understanding the intension of verbs.  This is joint work with Sumit Chopra, Antoine Bordes and Tomas Mikolov. ", "bio": "Jason Weston is a research scientist at Facebook, NY since February 2014. He earned his PhD in machine learning at Royal Holloway, University of London and at AT&T Research in Red Bank, NJ (advisors: Alex Gammerman, Volodya Vovk and Vladimir Vapnik) in 2000. From 2000 to 2002, he was a researcher at Biowulf technologies, New York. From 2002 to 2003 he was a research scientist at the Max Planck Institute for Biological Cybernetics, Tuebingen, Germany. From 2003 to 2009 he was a research staff member at NEC Labs America, Princeton. From 2009 to 2014 he was a research scientist at Google, NY. His interests lie in statistical machine learning and its application to text and images. Jason has published over 90 papers, including best paper awards at ICML and ECML. He was also part of the YouTube team that won a National Academy of Television Arts & Sciences Emmy Award for Technology and Engineering for Personalized Recommendation Engines for Video Discovery.", "area": "", "key": "JasonWeston", "prettyDate": "April 02"}, {"semester": "Spring ", "year": "2015", "date": "2015-03-26", "speaker": "Francesca Rossi", "website": "http://www.math.unipd.it/~frossi/", "title": "Probabilistic Conditional Preferences", "affiliation": "University of Padova + Harvard University", "sponsor": "Yahoo!", "video": "", "abstract": "Preferences are ubiquitous in our everyday life. We use them to take all our decisions, either in isolation or together with others. They change over time and they get affected by our relationship with friends. We sometimes describe them explicitly but most often we show them implicitly via our actions (like clicks, follows, tweets, blogs, choices). Being able to model them faithfully and reason with them efficiently is essential in every intelligent environment.  Several formalisms exist to handle preferences of various kinds: qualitative, quantitative, conditional, etc. However, they usually assume preferences to be certain and do not provide help for describing and reasoning with uncertain preferences. Uncertainty may be present in a single agent setting, where an individual is not sure about its preferences or some noise is present, or also in a multi-agent setting, where several individuals may have conflicting preferences and uncertainty may be used to reconcile them. Probabilistic CP-nets (PCP-nets) are a formalism to model conditional qualitative preferences with probabilistic uncertainty. Under reasonable restrictions on the topology of their dependency graph, it is computationally easy to perform various tasks in PCP-nets. Thus they provide an efficient tool to model and reason with preferences. In this talk, I will describe PCP-nets and how to respond to optimality and dominance queries over them. I will then advocate for the need of a logical language to model them, and hint at their possible use in various scenarios. I will also compare them to other frameworks and will discuss preference elicitation/learning issues. ", "bio": "Francesca Rossi is a professor of computer science at the University of Padova, Italy. Currently she is on sabbatical at Harvard with a fellowship of the Radcliffe Institute for Advanced Studiy. Her research interests include: constraint reasoning, preferences, multi-agent systems, computational social choice and artificial intelligence. She has been president of the international association for constraint programming (ACP) and is now the president of IJCAI. She has been program chair of CP 2003 and of IJCAI 2013. She is on the editorial board of Constraints, Artificial Intelligence, AMAI and KAIS, and is Associate Editor in Chief of JAIR. She has published over 160 articles in international journals, proceedings of international conferences or workshops, and as book chapters. She has co-authored a book, edited 16 volumes of conference proceedings, collections of contributions, and special issue of international journals, and has co-edited the Handbook of Constraint Programming.", "area": "", "key": "FrancescaRossi", "prettyDate": "March 26"}, {"semester": "Spring ", "year": "2015", "date": "2015-03-12", "speaker": "Marek Petrik", "website": "", "title": "Better Solutions From Inaccurate Models", "affiliation": "IBM Research", "sponsor": "Yahoo!", "video": "", "abstract": "It is very important in many application domains to compute good solutions from inaccurate models. Models in machine learning are inaccurate because they both simplify reality and are based on imperfect data. Robust optimization has emerged as a very powerful methodology for reducing solution sensitivity to model errors. In the first part of the talk, I will describe how robust optimization can mitigate data limitations in planning a large-scale disaster recovery operation. In the second part of the talk, I will discuss a novel use of robustness to substantially reducing error due to model simplification in reinforcement learning and large-scale regression.", "bio": "Marek Petrik is a Research Staff Member at the Business Services and Mathematical Sciences Department at IBM's T.J. Watson Research Center. He received his Ph.D. in Computer Science from the University of Massachusetts, Amherst. His research focuses on machine learning and optimization with a special interest in robust and risk-averse optimization and stochastic sequential optimization problems. He has worked on applications such as agricultural and environmental monitoring, supply chain optimization, revenue management, and online recommendations.", "area": "", "key": "MarekPetrik", "prettyDate": "March 12"}, {"semester": "Spring ", "year": "2015", "date": "2015-03-10", "speaker": "Bishan Yang", "website": "", "title": "Exploiting Relational Knowledge for Extraction of Opinions and Events in Text", "affiliation": "Cornell University", "sponsor": "Yahoo!", "video": "", "abstract": "The richness and diversity of natural language makes automatic extraction of opinions and events from texts difficult. An automatic system designed for this task would need to identify complex linguistic expressions, interpret their meanings in context, and integrate information that is often distributed over long distances. While machine learning techniques have been widely applied for information extraction, they often make strong independence assumptions about linguistic structure and make decisions myopically based on local and partial information in the text. In this talk, I argue that accurate information extraction needs machine learning algorithms that can exploit relationships within and across multiple levels --- between words, phrases and sentences --- facilitating globally-informed decisions.  In the first part of my talk, I will introduce the task of fine-grained opinion extraction --- discovering opinions, their sources, targets and sentiment from text. I will present a joint inference approach that can account for the dependencies among different opinion entities and relations, and a context-aware learning approach that is capable of exploiting intra- and inter-sentential discourse relations for improving sentiment prediction. In the second part of my talk, I will present my recent work on event extraction and event coreference resolution --- the task of extracting event mentions and integrating them within and across documents by exploiting context. I propose a novel Bayesian model that allows generative modeling of event mentions, while simultaneously accounting for event-specific similarity. ", "bio": "Bishan Yang is a Ph.D. candidate at Cornell University. Her research interests lie in natural language processing and machine learning. She earned her M.S. and B.S. in Computer Science from Peking University. During her graduate studies, she has completed internships at Microsoft Research, Google Research and eBay Research Labs.", "area": "", "key": "BishanYang", "prettyDate": "March 10"}, {"semester": "Spring ", "year": "2015", "date": "2015-03-05", "speaker": "Karthik Raman", "website": "", "title": "Man+Machine: Machine learning with Humans-in-the-Loop", "affiliation": "Cornell University", "sponsor": "Yahoo!", "video": "", "abstract": "Intelligent systems, ranging from internet search engines and online retailers to personal robots and MOOCs, live in a symbiotic relationship with their users - or at least they should. On the one hand, users greatly benefit from the services provided by these systems. On the other hand, these systems can greatly benefit from the world knowledge that users communicate through their interactions with the system. These interactions -- queries, clicks, votes, purchases, answers, demonstrations, etc. -- provide enormous potential for economically and autonomously optimizing these systems and for gaining unprecedented amounts of world knowledge required to solve some of the hardest AI problems.  In this talk I discuss the challenges of learning from data that results from human behavior. I will present new machine learning models and algorithms that explicitly account for the human decision making process and factors underlying it such as human expertise, skills and needs. The talk will also explore how we can look to optimize human interactions to build robust learning systems with provable performance guarantees. I will also present examples, from the domains of search, recommendation and educational analytics, where we have successfully deployed systems for cost-effectively learning with humans in the loop. ", "bio": "Karthik Raman is a PhD student at Cornell University working with Prof. Thorsten Joachims. Motivated by applications such as search, recommendation and educational analytics, his research aims to tackle learning problems with a human-in-the-loop. His work on understanding the role of diversity in complex search tasks won a best paper award at SIGIR. He is supported by a Google PhD Fellowship and a Yahoo Key Scientific Challenge Award.", "area": "", "key": "KarthikRaman", "prettyDate": "March 05"}, {"semester": "Spring ", "year": "2015", "date": "2015-02-26", "speaker": "Jean-Baptiste Tristan", "website": "", "title": "Efficient Training of LDA on a GPU by Mean-for-Mode Gibbs Sampling", "affiliation": "Oracle Labs", "sponsor": "Yahoo!", "video": "", "abstract": "We introduce Mean-for-Mode Gibbs sampling, a variant of an uncollapsed Gibbs sampler that we use to train LDA on a GPU. The algorithm combines benefits of both uncollapsed and collapsed Gibbs samplers. Like a collapsed Gibbs sampler --- and unlike an uncollapsed Gibbs sampler --- it has good statistical performance, and can use sampling complexity reduction techniques such as sparsity. Meanwhile, like an uncollapsed Gibbs sampler --- and unlike a collapsed Gibbs sampler --- it is embarrassingly parallel, and can use approximate counters.", "bio": "Jean-Baptiste Tristan studied computer science and mathematics at the Ecole Normale Superieure of Paris. He received a Ph.D. in computer science from the Paris Diderot University in 2009. He then worked as a postdoctoral-fellow at Harvard University before joining Oracle Labs in 2011.  Jean-Baptiste previously worked in the field of formal software verification by interactive theorem proving. He received the 2011 \"La recherche\" award for his work on formally verified software equivalence checking algorithms. He currently works on the design and implementation of scalable machine learning algorithms for distributed and parallel architectures. ", "area": "", "key": "Jean-BaptisteTristan", "prettyDate": "February 26"}, {"semester": "Spring", "year": "2015", "date": "2015-02-19", "speaker": "Ari Kobren", "website": " ", "title": "Getting More for Less: Optimized Crowdsourcing with Dynamic Tasks and Goals", "affiliation": "UMass CS", "sponsor": "Yahoo!", "video": "", "abstract": "In crowdsourcing systems, the interests of contributing participants and system designers are often at odds. Participants seek to perform easy tasks, which offer them instant gratification, while system designers want them to complete more difficult tasks, which bring higher value to the crowdsourced application. Here we present techniques that optimize the crowdsourcing process for both parties involved, by jointly maximizing the worker longevity in the system and the true value that the system derives from worker participation.  We first present models that predict the \u201csurvival probability\u201d of a worker at any given moment, that is, the probability that she will proceed to the next task offered by the system. We then leverage this survival model to dynamically decide what task to assign and what motivating goals to present to the worker. This allows us to jointly optimize for the short-term (getting a difficult task done) and for the long-term (keeping workers engaged for longer periods of time).  We show that dynamically assigning tasks significantly increases the value of a crowdsourcing system. In an extensive empirical evaluation, we observed that our task allocation strategy increases the amount of information collected by up to 117.8%. We also explored the utility of motivating workers with goals. We demonstrate that setting specific, static goals can be highly detrimental to the long-term worker participation, as the completion of a goal (e.g., earning a badge) is also a common drop-off point for many workers. We show that setting the goals dynamically, in conjunction with judicious allocation of tasks, increases the amount of information collected by the crowdsourcing system by up to 249%, compared to the existing baselines that use fixed objectives. ", "bio": "  Ari is a computer science M.S./Ph.D. student at UMass Amherst where he is advised by Dr. Andrew McCallum and is a member of the Information Extraction and Synthesis Laboratory. Ari works at the intersection of machine learning and crowdsourcing and is primarily interested in methods for constructing and maintaining domain specific knowledge bases. In his research, Ari often works on different varieties of coreference resolution and data integration with and without humans in the loop.  Ari completed his B.S. in computer science at Tufts University in 2010. Before enrolling in graduate school, Ari worked for two years at MIT Lincoln Laboratory on decision support technology for United States intelligence analysts. ", "area": "", "key": "AriKobren", "prettyDate": "February 19"}, {"semester": "Spring ", "year": "2015", "date": "2015-02-12", "speaker": "Scott Linderman", "website": "", "title": "Discovering Latent Network Structure in Neural Spike Train Recordings", "affiliation": "Harvard University", "sponsor": "Yahoo!", "video": "", "abstract": "The steady expansion of neural recording capability provides exciting opportunities to discover unexpected patterns and gain new insights into neural computation. Realizing these gains requires statistical methods for extracting interpretable network structure from large-scale neural recordings. In this talk I will present our recent work on methods that reveal such structure in simultaneously recorded multi-neuron spike trains. We combine random network models with Hawkes processes, a type of multivariate point process, in a joint probabilistic model, and derive efficient fully-Bayesian inference algorithms. We extend these models to handle nonlinear interactions by leveraging recent innovations in Bayesian inference for logistic models. Interpretable properties such as latent cell types and features, hidden states of the network, and unknown synaptic plasticity rules are incorporated into the model as latent variables that govern the network. We apply our models to neural recordings from primate retina, rat hippocampal place cells, and neural simulators to discover latent structure in population recordings.", "bio": "Scott a Computer Science Ph.D. candidate at Harvard University where he is advised by Leslie Valiant and Ryan Adams and is a member of the HIPS group. His research is focused on computational neuroscience, machine learning, and the general question of how computer science can help us decipher neural computation. This includes bottom-up methods for inferring statistical patterns in large-scale neural recordings as well as top-down models of probabilistic reasoning in neural circuits.  He completed by B.S. in Electrical and Computer Engineering at Cornell University in 2008. Prior to beginning graduate school, he worked for three years as a software development engineer at Microsoft, specifically working on the Windows networking stack. ", "area": "", "key": "ScottLinderman", "prettyDate": "February 12"}, {"semester": "Fall", "year": "2014", "date": "2014-12-15", "speaker": "Charles Sutton", "website": "", "title": "Statistical Analysis of Computer Program", "affiliation": "University of Edinburgh", "sponsor": "Yahoo!", "video": "", "abstract": "Billions of lines of source code have been written, many of which are freely available on the Internet. This code contains a wealth of implicit knowledge about how to write software that is easy to read, avoids common bugs, and uses popular libraries effectively.  We want to extract this implicit knowledge by analyzing source code text. To do this, we employ the same tools from machine learning and natural language processing that have been applied successfully to natural language text. After all, source code is also a means of human communication.  We present three new software engineering tools inspired by this insight:      Naturalize, a system that learns local coding conventions.   It proposes revisions to names and to formatting so as to make code more consistent.      TASSAL, a system that summarizes code by automatically folding   the blocks that are least informative according to a topic model;      HAGGIS, a system that learns local recurring syntactic patterns,   which we call idioms. HAGGIS accomplishes this using a nonparametric Bayesian tree substitution grammar, and is delicious with whisky sauce. ", "bio": "Charles Sutton is a Reader (equivalent to Associate Professor) at the University of Edinburgh. He is interested in a broad range of applications of probabilistic machine learning, including NLP, analysis of computer systems, software engineering, sustainable energy, and exploratory data analysis.  Dr Sutton completed his PhD in 2008 from the University of Massachusetts Amherst, working with Andrew McCallum. He did posdoctoral research at the University of California Berkeley, working with Michael I Jordan.  He is Deputy Director of the EPSRC Centre for Doctoral Training in Data Science at the University of Edinburgh. ", "area": "", "key": "CharlesSutton", "prettyDate": "December 15"}, {"semester": "Fall", "year": "2014", "date": "2014-12-04", "speaker": "Sridhar Mahadevan", "website": "", "title": "Deep Reasoning about Word Embeddings and Linguistic Regularities using Kernels on Lie Groups", "affiliation": "UMass CS + IBM Research", "sponsor": "Yahoo!", "video": "", "abstract": "It is estimated that it would take an average adult human more than a decade to read through all the pages of Wikipedia. Exploiting the many advances in computing hardware, optimization methods, programming paradigms and storage technology, it is now possible to process all of Wikipedia (roughly 3.5 billion words) in about half a day on a personal workstation. Recent work over the past few years has shown that recursive deep learning neural nets can learn continuous vector space word representations reflecting the underlying semantics of words from a large corpus like Wikipedia. Simple vector space arithmetic using cosine distances has been shown to capture certain types of analogies, such as reasoning about plurals from singulars, past tense from present tense, family relationships etc.  In this talk, I will present a new approach to reasoning about linguistic regularities from continuous word representations, based on modeling the vector subspaces spanned by groups of related words. We exploit the property that the set of k-dimensional subspaces in an ambient n-dimensional Euclidean space forms a curved matrix manifold called the Grassmannian, and is a quotient subgroup of the Lie group of rotations in n-dimensions. Based on this mathematical model, I will introduce a modified cosine distance based on computing one-parameter exponential flows across the shortest-path geodesics between subspaces representing related word groups. I will show how to learn kernels on Lie groups that capture relation-specific distances across word categories. Testing this approach using learned word embeddings on a 3 billion word Wikipedia corpus using the word analogy tasks studied by Mikolov et al. at Google reveals substantial improvements in performance compared to previous work. I will discuss applications of the matrix manifold framework to other topics in IR and NLP, such as deep QA, ranking, relational knowledge-base completion, and machine translation. If time permits, I will describe the application of new machine learning algorithms based on variational inequalities to various problems in NLP. ", "bio": "BIO: Sridhar Mahadevan is a professor and Director of the Autonomous Learning Laboratory at the School of Computer Science, University of Massachusetts, Amherst. He was elected AAAI Fellow in 2014 for \u201csignificant contributions to machine learning\u201d. He is on sabbatical for the year 2014-2015 at IBM Research in New York, where he is working on machine learning methods for the Watson project. He will present a tutorial at AAAI 2015 in January entitled: \u201cGeneralizing Optimization to Equilibration: A New Foundation for AI in the 21st century\u201d.", "area": "", "key": "SridharMahadevan", "prettyDate": "December 04"}, {"semester": "Fall", "year": "2014", "date": "2014-11-20", "speaker": "Kriste Krstovski", "website": "https://scholar.harvard.edu/kriste", "title": "Evaluating Topic Models through Histogram Analysis", "affiliation": "UMass", "sponsor": "Yahoo!", "video": "", "abstract": "Unsupervised methods are evaluated in one of two different ways - intrinsically and extrinsically. By intrinsic evaluations we mean methods such as perplexity that require access only to more raw data without additional human annotations. Unfortunately, these methods are often weakly correlated to a model\u2019s performance on a particular task. Extrinsic metrics, on the other hand, evaluate the model on a particular task but are dependent on ground truth annotations and often involve traversing over ranked lists.  In this talk, I will present a new extrinsic evaluation metric that compares histograms, computed over model\u2019s similarity metric, between human and randomly generated document pairs in log space. We call this approach Histogram Slope Analysis (HSA). Across two families of topic models I will demonstrate that HSA, unlike perplexity, achieves very high correlation with traditional performance metrics such as Mean Average Precision (MAP), while being more efficient to compute. As this is work in progress any feedback is welcome. ", "bio": "Kriste Krstovski is a Ph.D candidate in the School of Computer Science, at the University of Massachusetts Amherst and a Predoctoral Fellow at the Harvard-Smithsonian Center for Astrophysics. An advisee of Prof. David A. Smith, he is a member of the Information Retrieval (IR) and Information Extraction and Synthesis (IESL) Laboratories. Before starting his PhD studies Kriste was a Staff Scientist in the Speech and Language Processing Department at BBN Technologies for four years. He finished his B.S. and M.S. in Electrical Engineering at the University of New Hampshire while being a member of the Project54 team under the supervision of Andrew L. Kun and W. Tom Miller III. ", "area": "", "key": "KristeKrstovski", "prettyDate": "November 20"}, {"semester": "Fall", "year": "2014", "date": "2014-11-06", "speaker": "Jen Pan", "website": "", "title": "Reverse Engineering Chinese Censorship", "affiliation": "Harvard", "sponsor": "Yahoo!", "video": "", "abstract": "Chinese government censorship of social media constitutes the largest selective suppression of human communication in the history of the world. Three approaches are taken to learn about this system. First is an observational study where millions of social media posts are downloaded before the Chinese government can read and censor those they deem objectionable. Second, to make causal inferences, a large scale randomized experimental study is conducted. And finally, for descriptive inferences, the current approach of conducting confidential interviews is supplemented by setting up a own social media site inChina, contracting with Chinese firms to install the same censoring technologies as existing sites, and reverse engineering how it all works. Results offer unambiguous support for, and clarification of, the view that criticism of the state, its leaders, and their policies are routinely published whereas posts with collective action potential are much more likely to be censored. This approach also clarifies the internal mechanisms of the Chinese censorship apparatus and show that local social media sites have far more flexibility than was previously understood in how (but not what) they censor. This talk is based on two papers, available at http://bit.ly/CensorObsn and http://bit.ly/CensorExpt. ", "bio": "I'm a PhD candidate in the Department of Government at Harvard University. I study the strategies authoritarian regimes employ to perpetuate their rule, including censorship, redistribution, and reponsiveness, and how technology facilitates and hinders these strategies. I focus primarily on China, and use methods of automated content analysis and experiments to measure and examine different components of these strategies. My work has appeared or is forthcoming in the American Political Science Review, Comparative Political Studies, and Science.  I graduated from Princeton University, summa cum laude, in 2004, and until 2009, I was a business analyst, then associate, then engagement manager at McKinsey & Company based in New York and Beijing. I have also worked for the Chinese Center for Disease Control, the Clinton Foundation HIV/AIDS Initiative as well as the Clinton Global Initiative.  Beginning in 2015, I will be an assistant professor in the Department of Communication at Stanford University. ", "area": "", "key": "JenPan", "prettyDate": "November 06"}, {"semester": "Fall", "year": "2014", "date": "2014-10-23", "speaker": "David Weiss", "website": "", "title": "Lazy Structured Prediction", "affiliation": "Google", "sponsor": "Yahoo!", "video": "", "abstract": "Machine learning practitioners often face a fundamental trade-off between expressiveness and computation time: on average, more accurate, expressive models tend to be more computationally intensive both at training and test time. This tradeoff is acutely present in the setting of structured prediction, where the joint prediction of multiple output variables creates two inter-related bottlenecks: inference and feature computation time. In this talk, I will discuss my efforts to address the latter bottleneck in my PhD research. The key question I will discuss is, \"Can we learn to compute features only as needed for maximum efficiency?\"  I propose an architecture that uses a rich feedback loop between extraction and prediction. The run-time control policy is learned using efficient value-function approximation, which adaptively determines the value of information of features at the level of individual variables for each input. We demonstrate significant speedups over state-of-the-art methods on two challenging datasets. For articulated pose estimation in video, we achieve a more accurate state-of-the-art model that is simultaneously 4X faster while using only a small fraction of possible features, with similar results on an OCR task. Finally, I'll discuss my recent efforts to apply these techniques to natural language processing.  ", "bio": "David Weiss joined Google as a Research Scientist in 2014 after graduating with a Ph.D from the University of Pennsylvania under the supervision of Ben Taskar, receiving the Rubinoff Award for best CIS dissertation for his work on improving the efficiency and accuracy of structured prediction methods. Previously, he has worked on a variety of research problems in machine learning, statistics, neuroscience, recommender systems, computer vision, and natural language processing, finishing in 2nd place in the Netflix Prize competition and the CHALEARN One-Shot Learning Challenge. A recipient of an NSF Graduate Research Fellowship, he graduated in 2007 from Princeton University with a degree in Computer Science and a certificate in Neuroscience.", "area": "", "key": "DavidWeiss", "prettyDate": "October 23"}, {"semester": "Fall", "year": "2014", "date": "2014-10-16", "speaker": "James Hays", "website": "", "title": "Recognizing and Editing Scene Attributes", "affiliation": "Brown", "sponsor": "Yahoo!", "video": "", "abstract": "In computer vision it is common to organize visual concepts (e.g. objects, scenes, materials, and actions) into non-overlapping categories. In recent years, attributes (nameable high-level properties) have been explored as an alternative to categorical taxonomies. I will first discuss the SUN attribute database in which images are described by over one hundred attribute labels related to materials, surface properties, lighting, affordances, and spatial layout of scenes. Then I will present more recent work which focuses on \"transient attributes\" -- dynamic properties of outdoor scenes. We manipulate photos so that they exhibit novel attributes related to weather, season, and lightning. For example, we might change a midday photo to sunset or add snow to a summer scene.", "bio": "James Hays is the Manning assistant professor of computer science at Brown University. His research interests span computer graphics, computer vision, and computational photography. His research focuses on using \"Internet-scale\" data and crowds-sourcing to improve scene understanding and allow smarter image synthesis and manipulation. Before joining Brown, James worked with Antonio Torralba as a post-doc at Massachusetts Institute of Technology. He received a Ph.D. in Computer Science from Carnegie Mellon University in 2009 while working with Alexei Efros. He has a B.S. in Computer Science from Georgia Institute of Technology. James is funded by an NSF CAREER award and gifts from Microsoft, Adobe, Pixar, and Google.", "area": "", "key": "JamesHays", "prettyDate": "October 16"}, {"semester": "Fall", "year": "2014", "date": "2014-10-02", "speaker": "David Belanger", "website": "", "title": "A Latent Gaussian Model For Text", "affiliation": "UMass", "sponsor": "Yahoo!", "video": "", "abstract": "NLP researchers are often struggle with the limited amounts annotated data available for training their models. On the other hand, massive quantities of raw text data are available from archives of news outlets, digitized books, the internet, etc. Consequently, a trend in NLP is to perform the following two-stage semi-supervised learning procedure: (1) learn some unsupervised model on a very large corpus that passes inputs through some low dimensional bottleneck, (2) map the annotated training examples to a low dimensional representation using the first model, (3) train a supervised predictive model in the reduced dimensional space. Models trained in this way perform well because in general it is easier to train high quality models on lower dimensional data.  I will discuss my current work on a version of step (1) above, based on linear dynamical systems. First, I will provide motivation for such a latent Gaussian model for text and how to apply it efficiently in step (2). The learning algorithm I will present, based on a two-stage estimation procedure of the method of moments followed by EM, is extremely scalable. Namely, after collecting some simple co-occurrence statistics from a large corpus, which can be parallelized, the algorithm's cost is independent of the amount of training data. The talk will conclude with a discussion of the benefits of extending the model using a Gaussian Copula process rather than a linear Gaussian process. ", "bio": "I am a fourth year graduate student advised by Professor Andrew McCallum. Before that, I was an Associate Scientist in the Speech, Language, and Multimedia Department at Raytheon BBN Technologies, where I worked on multilingual optical handwriting recognition. I received a B.A. in mathematics from Harvard University, where I worked with Eric Dunham and Jim Rice. We developed methods for numerically simulating earthquake ruptures along rough fault surfaces. Currently, my research focus is on machine learning and natural language processing. This summer, I am interning with Sham Kakade at Microsoft Research New England. ", "area": "", "key": "DavidBelanger", "prettyDate": "October 02"}, {"semester": "Fall", "year": "2014", "date": "2014-09-25", "speaker": "Ian Gemp", "website": "", "title": "Bridging the Gap: Optimization and Dynamical Systems", "affiliation": "UMass", "sponsor": "Yahoo!", "video": "", "abstract": "Optimization forms the backbone to many machine learning algorithms. In this talk, I\u2019ll argue that optimization theory exists within a much larger framework of dynamical systems. This perspective is primarily motivated by recent work with variational inequalities and brings with it a wealth of benefits including new algorithms, explanations for pre-existing ones, and avenues for potentially new formulations.  The talk is structured to trace the path I took to arrive at this conclusion. First, I\u2019ll describe the theory of variational inequalities (VIs), some fundamental methods, and a few domains. Next, I will explain how VIs relate to differential equations (DEs) through its alternate perspective as projected dynamical systems (PDS). This will provide the gateway to what I find is an eye-opening discussion of the stability of fixed points as well as algorithms commonly used to solve ordinary differential equations (ODEs). I\u2019ll follow this discussion with the presentation of several examples where techniques borrowed from VIs and ODEs have already been successfully applied. In order to fully take advantage of these ideas, we\u2019ll need to formulate new models, specifically ones that don\u2019t share an equivalent optimization formulation. To that end, I will pose a novel embedding problem that possesses the flexibility to represent solutions beyond optima. Finally, I will conclude the talk with a lofty conversation that considers dynamical systems and cognitive states within the brain in order to point out the progression from optimization to VI\u2019s concept of equilibration as a potentially fruitful research direction in AI. ", "bio": "Ian Gemp is currently pursuing his M.S./Ph.D. in Computer Science at the University of Massachusetts, Amherst. He graduated Northwestern University in 2011 with a B.S. in Mechanical Engineering and a B.S./M.S. in Applied Math. Before arriving in Amherst, he worked for two years as a project management consultant for Capgemini. His research interests include optimization, equilibration, reinforcement learning, multi-agent systems, and dimensionality reduction. ", "area": "", "key": "IanGemp", "prettyDate": "September 25"}, {"semester": "Fall", "year": "2014", "date": "2014-09-18", "speaker": "Jayant Krishnamurthy 2014", "website": "", "title": "Learning to Understand Natural Language with Less Supervision", "affiliation": "CMU", "sponsor": "Yahoo!", "video": "", "abstract": "Language understanding is the problem of mapping natural language text to a semantic representation connected with the real world. Many real-world applications depend on language understanding, including information extraction, robot command understanding, and natural language interfaces.  Obtaining labeled training data is a major challenge in language understanding. Web-scale knowledge bases have hundreds or thousands of predicates, and we further expect their predicate vocabularies to grow over time. Annotating even a few examples per predicate is therefore a substantial burden. Systems incorporating environmental context must, for example, learn the name of every object in their environment. Manually annotating a corpus of thousands of semantic parses or object names is expensive. What is needed for these applications are training procedures that use readily available data to train language understanding systems.  In this talk, I present two methods for training language understanding systems using readily available data. The first method uses distant supervision to train a semantic parser from a corpus of unlabeled text and a web-scale knowledge base, eliminating the need for per-sentence semantic annotations. We find that a semantic parser trained in this fashion outperforms a state-of-the-art relation extractor in an information extraction task. The second method trains a semantic parser to understand natural language referencing a situated environment, such as an image, in order to answer queries such as \"is the blue mug to the left of the monitor?\" We develop a weakly-supervised learning algorithm for this task that has similar performance to a fully-supervised algorithm, while using significantly simpler annotations. ", "bio": "Jayant Krishnamurthy is a Ph.D. student in the Computer Science Department at Carnegie Mellon University. Prior to attending Carnegie Mellon, he received an M.Eng and S.B. from the Massachusetts Institute of Technology. Jayant's research is on machine learning and natural language processing, with a focus on understanding the semantics of natural language. His work is part of the Never-Ending Language Learner (NELL) project at Carnegie Mellon, directed by Tom Mitchell. ", "area": "", "key": "JayantKrishnamurthy2014", "prettyDate": "September 18"}, {"semester": "Spring", "year": "2014", "date": "2014-04-29", "speaker": "Cynthia Rudin", "website": "", "title": "Algorithms for Interpretable Machine Learning", "affiliation": "MIT", "sponsor": "Yahoo!", "video": "", "abstract": "It is extremely important in many application domains to have transparency in predictive modeling. Domain experts do not tend to prefer \"black box\" predictive model models. They would like to understand how predictions are made, and possibly, prefer models that emulate the way a human expert might make a decision, with a few important variables, and a clear convincing reason to make a particular prediction. I will discuss recent work on interpretable predictive modeling with decision lists. I will describe several approaches, including an algorithm based on discrete optimization, and an algorithm based on Bayesian analysis.  Collaborators are: Ben Letham, Allison Chang, Tyler McCormick, David Madigan and Shawn Qian.  Links: -Building Interpretable Classifiers with Rules using Bayesian Analysis http://web.mit.edu/rudin/www/LethamRuMcMa12.pdf -Ordered Rules for Classification http://web.mit.edu/rudin/www/BertsimasChRuOR38611.pdf -Bayesian Hierarchical Rule Modeling For Predicting Medical Conditions http://web.mit.edu/rudin/www/McCormickRuMa12.pdf", "bio": "Cynthia Rudin is an associate professor of statistics at the Massachusetts Institute of Technology associated with CSAIL and the Sloan School of Management, and directs the Prediction Analysis Lab. Previously, Prof. Rudin was an associate research scientist at the Center for Computational Learning Systems at Columbia University, and prior to that, an NSF postdoctoral research fellow at NYU. She holds an undergraduate degree from the University at Buffalo where she received the College of Arts and Sciences Outstanding Senior Award in Sciences and Mathematics, and she received a PhD in applied and computational mathematics from Princeton University in 2004. She is the recipient of the 2013 INFORMS Innovative Applications in Analytics Award. She was given an NSF CAREER award in 2011. Her work has been featured in IEEE Computer, Businessweek, The Wall Street Journal, the Boston Globe, the Times of London, Fox News (Fox & Friends), the Toronto Star, WIRED Science, Yahoo! Shine, U.S. News and World Report, Slashdot, CIO magazine, and on Boston Public Radio.", "area": "", "key": "CynthiaRudin", "prettyDate": "April 29"}, {"semester": "Spring", "year": "2014", "date": "2014-04-17", "speaker": "Sridhar Mahadevan 2014", "website": "", "title": "Rethinking Machine Learning for the 21st Century: From Optimization to Equilibration", "affiliation": "UMass CS", "sponsor": "Yahoo!", "video": "", "abstract": "The past two decades has seen machine learning (ML) transformed from an academic curiosity to a multi-billion dollar industry, becoming a centerpiece of our entertainment, national security, scientific, and social infrastructures. Increasingly, ML research is driven by applications requiring analysis of massive datasets in highly distributed networked cloud environments. In this talk, I\u2019ll argue that this reality requires a fundamental rethinking of our basic analytic tools. My thesis will be that ML needs to shift from its current focus on optimization to equilibration, from modeling the world as uncertain, but stationary and benign, to one where the world is non-stationary, competitive, and potentially malicious. Adapting to this new world will require developing new ML frameworks and algorithms. My talk will introduce one such framework \u2014 equilibration using variational inequalities and projected dynamical systems \u2014which not only generalizes optimization, but is better suited to the distributed networked cloud-oriented future that ML faces.  To explain this paradigm change, I\u2019ll begin by summarizing the au courant optimization-based approach to ML using recent research in the ALL lab on finding low-dimensional representations of high-dimensional data, and doing scalable gradient optimization in non-Euclidean spaces. I will then present an equilibration-based framework using variational inequalities and projected dynamical systems, which originated in mathematics for solving partial differential equations in physics, but has been since been widely applied in its finite-dimensional formulation to network equilibrium problems in economics, transportation, and other areas. I\u2019ll describe a range of algorithms for solving variational inequalities, showing their scope allows ML to extend beyond optimization, to finding game-theoretic equilibria, solving complementarity problems, and many other areas. ", "bio": "", "area": "", "key": "SridharMahadevan2014", "prettyDate": "April 17"}, {"semester": "Spring", "year": "2014", "date": "2014-04-10", "speaker": "Brandon Stewart", "website": "", "title": "The Structural Topic Model and Applied Social Science", "affiliation": "Harvard", "sponsor": "Yahoo!", "video": "", "abstract": "Statistical models of text have become increasingly popular in statistics and computer science as a method of exploring large document collections. Social scientists often want to move beyond exploration, to measurement and experimentation, and make inference about social and political processes that drive discourse and content. In this talk, I will overview our recent work developing a novel topic model which supports this type of substantive research by modeling the relationships between observed covariates and latent topics. Our approach uses a simple generalized linear model framework to allow the analyst to condition on arbitrary structure affecting topic prevalence and content. I discuss applications from across the social sciences: the analysis of survey experiments, end of course surveys in MOOCs and media reporting in China. In each case we show how to leverage problem specific structure and perform inference on the resulting covariate relationships. All the methods described are available as part of the open source R package, stm, available at structuraltopicmodel.com.", "bio": "Brandon Stewart is a Ph.D. Candidate in the department of Government at Harvard University. His work centers on methods for automated content analysis in the social sciences with a particular focus on international relations.", "area": "", "key": "BrandonStewart", "prettyDate": "April 10"}, {"semester": "Spring", "year": "2014", "date": "2014-04-03", "speaker": "Boulat Bash", "website": "", "title": "Low Probability of Detection Communication over Optical Channels: Theory and Practice", "affiliation": "UMass CS", "sponsor": "Yahoo!", "video": "", "abstract": "The ubiquity of high-speed optical networks as well as the specific breaches in privacy of these networks described in the documents released by Edward Snowden necessitates the study of low probability of detection (LPD) communication systems in this domain. Such systems would not just protect the information content of the user's message from being accessed, but prevent the detection of its transmission in the first place. Square root law has been proven achievable for optical LPD communications systems if the adversary's channel measurements are subject to noise (either from the environment or his detection equipment), that is, a transmitter can transmit no more than O(\\sqrt{n}) bits in n uses of the channel to the legitimate receiver reliably (i.e. with arbitrarily low probability of decoding error) and covertly (i.e. limiting the adversary\u2019s probability of detecting the transmission arbitrarily close to zero). However, these proofs rely on the on-off keying modulation and random coding schemes that are impractical. We present analysis of LPD communication using pulse position modulation (PPM) and Reed-Solomon error correction codes, which are widely deployed in modern optical communication systems. We first prove that the square root law holds under these constraints and then demonstrate practical viability of optical LPD communication systems by presenting the experimental results from a physical implementation of such a system in a laboratory. ", "bio": "Boulat Bash is currently pursuing his Ph.D. in Computer Science from the University of Massachusetts, Amherst. He received his B.A. in Economics from Dartmouth College in 2001 and his M.S. in Computer Science from the University of Massachusetts, Amherst in 2008. He spent the summer of 2013 as a graduate intern and visiting scientist with the Quantum Information Processing Group at Raytheon BBN Technologies. His research interests include signal processing, communications, information theory and privacy.", "area": "", "key": "BoulatBash", "prettyDate": "April 03"}, {"semester": "Spring", "year": "2014", "date": "2014-03-06", "speaker": "Rick Freedman", "website": "", "title": "Getting the Big Idea: Recognizing Plans and Activities by Reading People Like a Book", "affiliation": "UMass CS", "sponsor": "Yahoo!", "video": "", "abstract": "t has been suggested that plan recognition (PR) and natural language processing (NLP) have much in common and are amenable to similar analyses. PR techniques often focus on the structural relationships between consecutive observations and ordered activities that comprise plans. However, NLP sometimes treats text as a bag-of-words, omitting such structural relationships and using topic models to get the overall distribution of concepts discussed in documents. We examine an analogous treatment of plans as distributions of activities through the application of Latent Dirichlet Allocation topic models to human skeletal data of plan execution traces obtained from a RGB-D sensor. This talk focuses on how to represent the sensor data as text and explores early work into how LDA performs integrated PR and activity recognition. We will also introduce variants of LDA for lifted recognition and propose future variants that will be practical for general-purpose applications including human-robot interaction.  ", "bio": "Rick Freedman is a second-year MS/Ph.D. student in the School of Computer Science at the University of Massachusetts Amherst. He received his BS in computer science and mathematics from Wake Forest University. As a member of Dr. Shlomo Zilberstein's Resource Bounded Reasoning Lab, his research interests in artificial intelligence include plan recognition and generalized planning. He participates in interdisciplinary research and often integrates these areas with research in statistical-relational artificial intelligence, human-robot interaction, and natural language.  ", "area": "", "key": "RickFreedman", "prettyDate": "March 06"}, {"semester": "Spring", "year": "2014", "date": "2014-02-20", "speaker": "Krzysztof Choromanski & Kui Tang", "website": "", "title": "Adaptive Anonymity via b-Matching", "affiliation": "Google Research", "sponsor": "Yahoo!", "video": "", "abstract": "In this talk we will focus on the adaptive anonymity problem and the way it can be handled by the so-called b-matching graphs. The adaptive anonymity problem is formalized where each individual shares their data along with an integer value to indicate their personal level of desired privacy. This problem leads to a generalization of k-anonymity to the b-matching setting. Novel algorithms and theory are provided to implement this type of anonymity. The relaxation achieves better utility, admits theoretical privacy guarantees that are as strong, and, most importantly, accommodates a variable level of anonymity for each individual. Empirical results confirm improved utility on benchmark and social data-sets.", "bio": "Krzysztof Choromanski currently working with Sanjiv Kumar - obtained his Ph.D degree from Columbia University in May 2013. He works on scalable matching project right now. He is interested in many branches of computer science and mathematics. Among them are: structural, spectral and random graph theory, machine learning and cryptography. He earned his double master degree from University of Warsaw (in both mathematics and computer science). He received several awards such as bronze medal at the International Olympiad in Physics in 2004 (Pohang, South Korea), gold medal at the International Team Regional Mathematical Contest in 2003 (Graz, Austria) and many national awards (such as: two gold medals at Polish Mathematical Olympiad, one gold medal at Polish Physics Olympiad, First Grand Prize at the Warsaw University of Technology Physics Competition). Recently he managed to prove the celebrated Erdos-Hajnal Conjecture for all tournaments on at most five vertices (the undirected analogous version is still open). He gave talks regarding structural graph theory and the Erdos-Hajnal Conjecture in several research institutions such as: Princeton University, Yale University, Rutgers University, Renyi Institute in Budapest and Google (tech talk at Mountain View).He is playing piano for more than 20 years now (Chopin being his favorite composer) and is an avid salsa dancer that started performing recently.", "area": "", "key": "KrzysztofChoromanski&KuiTang", "prettyDate": "February 20"}, {"semester": "Spring", "year": "2014", "date": "2014-02-06", "speaker": "Amit Nithianandan", "website": "", "title": "Introduction to Wibidata and Kiji", "affiliation": "WibiData", "sponsor": "Yahoo!", "video": "", "abstract": "Kiji is an open source framework that allows developers to build big data applications (focused around personalization and recommendations) on top of HBase and Hadoop. Solr is an open source enterprise grade search engine that makes it easy for developers to quickly deploy a high quality search engine. In this talk, I will demonstrate how the combination of the two can help implement personalized search that can also respond to user interactions in \"real-time\".", "bio": "Amit Nithianandan is a Member of the Technical Staff on the platform engineering team at WibiData and is a contributor to the Kiji Project. Prior to WibiData, Amit was the lead search and analytics engineer at Zvents.com (now a part of eBay) where he worked on search infrastructure, relevance and the integration of access log analytics into the search engine.", "area": "", "key": "AmitNithianandan", "prettyDate": "February 06"}, {"semester": "Spring", "year": "2014", "date": "2014-01-30", "speaker": "David Sarne", "website": "", "title": "The Devastating Effect of Information Brokers in MAS", "affiliation": "Bar-Ilan University", "sponsor": "Yahoo!", "video": "", "abstract": "In many multi-agent systems we find information brokers \u2013 agents that can disambiguate noisy signals upon payment of a fee (e.g., Carfax that provides reports on car histories, credit report companies, experts that provide accurate estimates on auctioned items). In this talk I will show that better information can hurt: the presence of the expert, even if the use of her services is optional, can degrade both individual agents\u2019 utilities and overall social welfare. The talk will focus on information brokers in two specific domains: auctions (where the provided information relates to the common value of the auctioned item) and distributed agent matching. For the first, I\u2019ll show that with the existence of the information provider, in conflict with classic auction theory, the auctioneer will not necessarily find it beneficial to have more bidders participate in the auction and similarly bidders will not necessarily prefer less competition. Also, bidders' unawareness of the auctioneer's option to purchase the information does not necessarily play into the hands of the auctioneer and, similarly, bidders may sometimes benefit from not knowing that the auctioneer has the option to purchase such information. For the distributed matching application I\u2019ll show that the externality imposed by the fact that others are consulting the expert can lead to a situation where the equilibrium outcome is that everyone consults the expert, even though all agents would be better off if the expert were not present. In both cases the agents may find it beneficial to pay the information-provider in order to leave the market (or alternatively publicly increase the price of the information she offers).  ", "bio": "David Sarne is a senior lecturer in the Department of Computer Science at Bar-Ilan University. He is also the head of the Intelligent Information Agents (IIA) group. Before joining Bar-Ilan he was a Post-Doc at Harvard University for two years, following several years in the Israeli hi-tech industry. He holds a B.Sc. in Industrial Engineering and an M.Sc. in Information Systems (both from Tel-Aviv University) and a Ph.D. in Computer Science from Bar-Ilan University. His main research interest is in the role that information plays in complex, uncertain multi-agent sequential decision settings, encompassing various types of environments, distinguished by the agent's goals (fully-cooperative or self-interested) and design (fully rational or bounded rational).", "area": "", "key": "DavidSarne", "prettyDate": "January 30"}, {"semester": "Spring", "year": "2014", "date": "2014-01-23", "speaker": "Nick Ruozzi", "website": "", "title": "Dynamic Programming, Lifts of Graphs, and Counting Problems", "affiliation": "Columbia", "sponsor": "Yahoo!", "video": "", "abstract": "Recent advances in the study of approximate inference algorithms in the machine learning community have led to provable lower bounds on the partition function for certain families of graphical models. I'll explain how simple dynamic programming algorithms combined with \"lifts\" of graphs have led to these new lower bounds and how lifts of graphs can lead to better algorithms for approximate inference. I'll conclude by discussing a number of interesting conjectures related to classic counting problems in computer science.", "bio": "Nicholas Ruozzi graduated from Yale University in 2011 with a Ph.D. in computer science. He was a postdoctoral researcher at Ecole Polytechnique Federale de Lausanne (EPFL) from 2011-2013. He is currently a postdoc and adjunct assistant professor at Columbia University. He is primarily interested in graphical models, approximate inference, and optimization.", "area": "", "key": "NickRuozzi", "prettyDate": "January 23"}]}