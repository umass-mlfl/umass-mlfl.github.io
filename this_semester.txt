{"data": [{"semester": "Fall", "year": "2022", "date": "2022-09-15", "speaker": "Xiang Lorraine Li", "website": "https://people.cs.umass.edu/~xiangl/", "title": "Probabilistic Commonsense Knowledge in Language", "affiliation": "AI2", "sponsor": "Oracle Labs", "video": "", "abstract": "Commonsense knowledge is critical to achieving artificial general intelligence. This shared common background knowledge is implicit in all human communication, facilitating efficient information exchange and understanding. However, commonsense research is hampered by its immense quantity of knowledge because an explicit categorization is impossible. Furthermore, a plumber could repair a sink in a kitchen or a bathroom, indicating that common sense reveals a probable assumption rather than a definitive answer. To align with these properties of commonsense fundamentally, we want to model and evaluate such knowledge human-like using probabilistic abstractions and principles.  This talk will introduce a probabilistic model representing commonsense knowledge using a learned latent space of geometric embeddings -- probabilistic box embeddings. Using box embeddings makes it possible to handle commonsense queries with intersections, unions, and negations in a way similar to Venn diagram reasoning. Meanwhile, existing evaluations do not reflect the probabilistic nature of commonsense knowledge. To fill in the gap, I will discuss a method of retrieving commonsense related question answer distributions from human annotators and a novel method of generative evaluation. We utilize these approaches in two new commonsense datasets (ProtoQA, Commonsense frame completion). The combination of modeling and evaluation methods based on probabilistic principles sheds light on how commonsense knowledge can be incorporated into artificial intelligence models in the future.", "bio": "Xiang Li (Lorraine) is a young investigator with the Mosaic team at Allen Institute of AI and will become an assistant professor at University of Pittsburgh starting Fall 2023. She defended her Ph.D. in Computer Science from UMass Amherst, advised by Andrew McCallum. Previously, she obtained an M.S. in Computer Science from The University of Chicago while conducting research at TTIC. Her research is at the intersection of natural language processing, commonsense reasoning, knowledge representation, and machine learning. More specifically, her research focuses on designing probabilistic models and evaluation methods for implicit commonsense knowledge in language.", "area": "NLP, commonsense, knowledge representation", "key": "XiangLorraineLi", "prettyDate": "September 15"}, {"semester": "Fall", "year": "2022", "date": "2022-09-22", "speaker": "Nicholas Sharp", "website": "https://nmwsharp.com/", "title": "The Computational Geometry of Neural Implicit Surfaces", "affiliation": "NVIDIA", "sponsor": "Oracle Labs", "video": "", "abstract": "Neural implicit surfaces describe a 3D shape as the level set of a neural network applied to spatial coordinates, and have proven remarkably effective for applications in computer graphics and vision. However, although these representations make learning and fitting tasks straightforward, basic geometric queries such as intersecting a ray against a surface or testing whether two surfaces intersect become much more difficult. This talk will first introduce some core concepts in neural shape representations, and then describe a new approach for geometric queries on neural implicit surfaces by applying a classic numerical technique called range analysis to compute guaranteed bounds on the output of a given neural network. The resulting algorithms enable geometric analysis of neural shape representations for applications in 3D geometry and machine learning.", "bio": "Nicholas Sharp is a Senior Research Scientist in NVIDIA's Toronto AI Lab. His research develops new algorithms and representations for processing geometric data robustly and efficiently, with applications in computer graphics/vision and geometric machine learning. He received his PhD from Carnegie Mellon University advised by Prof. Keenan Crane, and was a postdoc at the University of Toronto with Prof. Alec Jacobson, affiliated with the Fields Institute for Mathematics and the Vector Institute for AI. Nick's work has been recognized with best paper awards (SIGGRAPH & SGP), a software award (SGP), an NSF graduate research fellowship, and a Fields Institute postdoctoral fellowship. He also happily leads several open-source software libraries for 3D computing, including Polyscope and geometry-central.  www.nmwsharp.com", "area": "Computer Graphics and Vision", "key": "NicholasSharp", "prettyDate": "September 22"}, {"semester": "Fall", "year": "2022", "date": "2022-10-06", "speaker": "Karthik Narasimhan", "website": "https://www.cs.princeton.edu/~karthikn/", "title": "Language-guided machine learning", "affiliation": "Princeton", "sponsor": "Oracle Labs", "video": "", "abstract": "In modern machine learning, language has predominantly been treated as just another modality for applying statistical techniques. The question of \u2018what can natural language provide for machine learning\u2019 remains relatively underexplored. Humans have used language for centuries as a means of encoding and communicating task and domain knowledge \u2013 how can we similarly leverage such knowledge to train machines? In this talk, I will describe some of our recent attempts at language-guided machine learning for the paradigms of both supervised and reinforcement learning (RL). Specifically, I will show how language can be used to provide more semantic supervision to improve generalization and to help RL agents learn efficiently and safely.", "bio": "Karthik Narasimhan is an assistant professor in the Computer Science department at Princeton University. His research spans the areas of natural language processing and reinforcement learning, with the goal of building intelligent agents that learn to operate in the world through both their own experience (\u201ddoing things\u201d) and leveraging existing human knowledge (\u201dreading about things\u201d). Karthik received his PhD from MIT in 2017, and spent a year as a visiting research scientist at OpenAI, contributing to the development of the GPT language model, prior to joining Princeton in 2018. He is the recipient of a Google Research Scholar Award (2022), an Amazon research award (2019) and best paper awards/nominations at EMNLP (2015, 2016).", "area": "NLP, Reinforcement Learning", "key": "KarthikNarasimhan", "prettyDate": "October 06"}, {"semester": "Fall", "year": "2022", "date": "2022-10-13", "speaker": "Daniel Munoz Huerta", "website": "https://www.microsoft.com/en-us/research/people/dmunozhuerta/", "title": " Assistant In a Box: Leveraging The Power of Large Language Models", "affiliation": "Microsoft New England", "sponsor": "Microsoft New England", "video": "", "abstract": "Large Language Models (LLMs) are larger and more accessible than ever with more capabilities being discovered on a daily basis. Applications that were previously infeasible are now becoming possible due to the development of and access to LLMs. Join me in this demo rich presentation on the paradigm shift involved with going from writing complicated code to engineered prompts. We will be discussing how to save time through rapid prototyping of features by leveraging the zero and few shot capabilities of LLMs. We will be discussing the different ways to use LLMs for time consuming tasks that previously would have required manual input. The talk will also go over practical aspects of working with LLMs such as prompt engineering and combining LLMs with other NLP techniques, Common pitfalls and limitations such as bias, hallucinations, and cost. We\u2019ll also be talking about the responsible use of this technology.", "bio": "Daniel is currently working at Microsoft\u2019s Artificial Intelligence Development Accelerator Program in the New England Research and Development center otherwise known as the NERD center. His work revolves around leveraging AI to develop AI powered applications from zero to MVP across all kinds of verticals inside of Microsoft. In concrete terms his work touches on all the components of creating AI enabled applications from model development, serving and integration. Daniel has a background in AI through his previous work at AI startups as well as his time at the University of Rochester where he graduated with a BS in Computer Science.", "area": "NLP Applications", "key": "DanielMunozHuerta", "prettyDate": "October 13"}, {"semester": "Fall", "year": "2022", "date": "2022-10-20", "speaker": "Dimitris Tsipras", "website": "https://dtsipras.com/", "title": "Opening the black box of deep learning models by digging into their successes and failures", "affiliation": "Stanford", "sponsor": "Oracle Labs", "video": "", "abstract": "Modern machine learning is powered by a simple recipe: train large models on vast datasets. But while these models can be potent, a lot remains to be understood about how they actually work. In this talk, I will demonstrate how probing some of the striking successes and failures of these models can allow us to peek inside the black box. First, I will look at the phenomenon of adversarial examples\u2014highly accurate models are severely brittle to imperceptible perturbations. I will discuss findings that shed light into the origins of this phenomenon and their implications for learning in general. Then, I will focus on the emergent capability of in-context learning\u2014large language models are able to adapt to new tasks on-the-fly, by conditioning on a few input-output examples. I will present a methodology that allows us to rigorously study this capability and probe its limits. Overall, these explorations exemplify how we can understand a lot about the inner workings of these models by dissecting their behavior outside typical conditions.", "bio": "Dimitris Tsipras is a postdoctoral scholar at Stanford University, advised by Percy Liang and Greg Valiant. He obtained his PhD from MIT, advised by Aleksander Madry. His research is aimed towards understanding and improving the modern machine learning toolkit, focusing on topics such as reliability, benchmarks, and interpretability. ", "area": "Reliability and interpretability of ML Systems", "key": "DimitrisTsipras", "prettyDate": "October 20"}, {"semester": "Fall", "year": "2022", "date": "2022-10-27", "speaker": "Arman Cohan", "website": "http://armancohan.com/", "title": "Beyond Sentences and Paragraphs, Making Progress Towards Document-Level NLP", "affiliation": "AI2", "sponsor": "Oracle Labs", "video": "", "abstract": "The field of NLP has seen tremendous recent progress towards tasks that deal with relatively short sequences of text. However, there are still notable performance gaps between model and human performance on certain tasks that require processing longer context. In this talk, I will describe a few of our works on exploring models that target NLP tasks beyond sentence and paragraph-level context. I will first briefly discuss Longformer, an efficient transformer model that can process and contextualize information across inputs of several thousands of tokens. I will then discuss how such sparse and efficient transformers can be used to address multi-document tasks. Particularly, I will discuss CDLM as an encoder-only multi-document model and PRIMERA, an encoder-decoder general pre-trained model for generation tasks. Finally, I will discuss some of our other efforts on creating challenging benchmarks to help make more progress in document-level NLP.", "bio": "Arman Cohan is an incoming Assistant Professor at Yale University and a Research Scientist at the Allen Institute for AI (AI2). His broad research interest is developing natural language processing (NLP) methods towards addressing information overload particularly for language tasks that require processing significant amounts of information. This includes tasks that require document and multi-document understanding, natural language generation and summarization, as well as information discovery and filtering. His research has been recognized with multiple awards, including a best paper award at EMNLP 2017, an honorable mention at COLING 2018, and the 2019 Harold N. Glassman Distinguished Doctoral Dissertation award.", "area": "NLP, information discovery and summarization", "key": "ArmanCohan", "prettyDate": "October 27"}, {"semester": "Fall", "year": "2022", "date": "2022-11-03", "speaker": "Rachel Rudinger", "website": "https://rudinger.github.io/", "title": "\u201cNot so fast!\u201d: Revisiting assumptions in (and about) Natural Language Reasoning", "affiliation": "UMaryland", "sponsor": "Oracle Labs", "video": "", "abstract": "In recent years, the field of Natural Language Processing has seen a profusion of tasks, datasets, and systems that facilitate reasoning about real-world situations through language (e.g., RTE, MNLI, COMET). Such systems might, for example, be trained to consider a situation where \u201csomebody dropped a glass on the floor,\u201d and conclude it is likely that \u201cthe glass shattered\u201d as a result. In this talk, I will discuss three pieces of work that revisit assumptions made by or about these systems. In the first work, I develop a Defeasible Inference task, which enables a system to recognize when a prior assumption it has made may no longer be true in light of new evidence it receives. The second work I will discuss revisits partial-input baselines, which have highlighted issues of spurious correlations in natural language reasoning datasets and led to unfavorable assumptions about models\u2019 reasoning abilities. In particular, I will discuss experiments that show models may still learn to reason in the presence of spurious dataset artifacts. Finally, I will touch on work analyzing harmful assumptions made by reasoning models in the form of social stereotypes, particularly in the case of free-form generative reasoning models.", "bio": "Rachel Rudinger is an Assistant Professor in the Department of Computer Science at the University of Maryland, College Park. She holds joint appointments in the Department of Linguistics and the Institute for Advanced Computer Studies (UMIACS). In 2019, Rachel completed her Ph.D. in Computer Science at Johns Hopkins University in the Center for Language and Speech Processing. From 2019-2020, she was a Young Investigator at the Allen Institute for AI in Seattle, and a visiting researcher at the University of Washington. Her research interests include computational semantics, common-sense reasoning, and issues of social bias and fairness in NLP.", "area": "Computational semantics, common-sense reasoning, social bias and fairness in NLP", "key": "RachelRudinger", "prettyDate": "November 03"}, {"semester": "Fall", "year": "2022", "date": "2022-11-17", "speaker": "Rana Hanocka", "website": "https://people.cs.uchicago.edu/~ranahanocka/", "title": "Data-Driven Geometry Processing - without 3D Data", "affiliation": "UChicago", "sponsor": "Oracle Labs", "video": "", "abstract": "Much of the current success of deep learning has been driven by massive amounts of curated data, whether annotated and unannotated. Compared to image datasets, developing large-scale 3D datasets is either prohibitively expensive or impractical. In this talk, I will present several works which harness the power of data-driven deep learning for tasks in geometry processing, without any 3D datasets. I will discuss works which reconstruct surfaces from noisy point cloud data without any 3D datasets. In addition, I will demonstrate that it is possible to learn to edit 3D geometry using large image datasets.", "bio": "Rana Hanocka is an Assistant Professor at the University of Chicago and holds a courtesy appointment at the Toyota Technological Institute at Chicago (TTIC). Rana founded and directs the 3DL (Threedle) research collective, comprised of enthusiastic researchers passionate about 3D, machine learning, and visual computing. Rana\u2019s research interests span computer graphics, computer vision, and machine learning. Rana completed her Ph.D. at Tel Aviv University under the supervision of Daniel Cohen-Or and Raja Giryes. Her Ph.D. research focused on building neural networks for irregular 3D data and applying them to problems in geometry processing.", "area": "Computer Graphics and Vision", "key": "RanaHanocka", "prettyDate": "November 17"}, {"semester": "Fall", "year": "2022", "date": "2022-12-01", "speaker": "Virginia Smith", "website": "https://www.cs.cmu.edu/~smithv/", "title": "TBA", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "ML, Optimization, Distributed Systems", "key": "VirginiaSmith", "prettyDate": "December 01"}, {"semester": "Fall", "year": "2022", "date": "2022-12-08", "speaker": "Yue Wang", "website": "https://people.csail.mit.edu/yuewang/", "title": "TBA", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "Computer Vision, Geometric Data Processing", "key": "YueWang", "prettyDate": "December 08"}]}