{"data": [{"semester": "Fall", "year": "2024", "date": "2024-11-14", "speaker": "Andrew Wu", "website": "https://wu-haoze.github.io/", "title": "Marabou 2.0: A Versatile Formal Analyzer of Neural Networks", "affiliation": "Amherst College", "sponsor": "", "video": "", "abstract": "Deep neural networks are revolutionizing the way complex systems are designed. Consequently, there is a pressing need for tools and techniques to obtain formal guarantees on the behaviors of neural networks. To address that need, we present version 2.0 of Marabou, a toolkit for formally verifying user-defined properties on deep neural networks. We discuss the tool\u2019s architectural design and highlight a few of its many recent applications, in robotics, vision, and systems domains.", "bio": "", "area": "", "date past": "", "key": "AndrewWu", "prettyDate": "November 14"}, {"semester": "Fall", "year": "2024", "date": "2024-11-07", "speaker": "Claudia Shi", "website": "https://www.claudiashi.com/", "title": "Novel Problems, Classic Solutions: Understanding LLMs Through the Lens of Statistics", "affiliation": "Columbia", "sponsor": "", "video": "", "abstract": "In this talk, I will present two recent projects that use statistical methods to deepen our understanding of LLMs. First, I investigate the moral beliefs encoded within LLMs, focusing on the advice they offer in morally ambiguous scenarios. To quantify this, I developed statistical measures and metrics that define what it means for a model to make a choice and evaluate the uncertainty associated with that choice. By conducting a large-scale survey with 26 LLMs, we analyzed their responses to various morally ambiguous situations. Our findings reveal that frontier LLMs often provide similar responses, even when they differ from those of human annotators. Second, I explore how LLMs implement tasks by examining the circuit hypothesis\u2014the idea that specific tasks are executed by subnetworks within the model, known as circuits. I developed a suite of hypothesis tests based on criteria such as mechanism preservation, localization, and minimality to evaluate these circuits. Applying these tests to several circuits identified in existing research, I assess the extent to which these circuits align with the idealized concept proposed by the hypothesis.", "bio": "", "area": "", "date past": "", "key": "ClaudiaShi", "prettyDate": "November 07"}, {"semester": "Fall", "year": "2024", "date": "2024-10-31", "speaker": "Boqing Gong", "website": "http://boqinggong.info/", "title": "From Domain Adaptation to VideoPrism: A Decade-Long Quest for Out-of-Domain Visual Generalization", "affiliation": "Boston University", "sponsor": "", "video": "", "abstract": "This talk explores the challenges of out-of-domain (OOD) generalization in computer vision, encompassing tasks like domain adaptation, webly-supervised learning, and long-tailed recognition. I will review some principles and techniques underlying the seemingly diverse tasks and then connect them to the recent development of generalist vision systems, showcasing VideoPrism --- a state-of-the-art generalist video encoding model --- and ongoing research into image and video generation models.", "bio": "", "area": "", "date past": "", "key": "BoqingGong", "prettyDate": "October 31"}, {"semester": "Fall", "year": "2024", "date": "2024-10-24", "speaker": "Alex Wong", "website": "https://vision.cs.yale.edu/members/alex-wong.html", "title": "The Know-How of Multimodal Depth Perception", "affiliation": "Yale", "sponsor": "", "video": "https://www.youtube.com/watch?v=sYjTx26VUVQ", "abstract": "Training deep neural networks requires tens of thousands to millions of examples, so curating multimodal vision datasets amounts to numerous man-hours; tasks like depth estimation require an even more massive effort. I will introduce an alternative form of supervision that leverages multi-sensor validation as an unsupervised (or self-supervised) training objective for depth estimation. To address its ill-posedness, I will show how one can leverage multimodal inputs in the choice of regularizers, which can play a role in model complexity, speed, generalization, as well as adaptation to test-time (possibly adverse) environments. Additionally, I will discuss the current limitations of data augmentation procedures used during unsupervised training, which involves reconstructing the inputs as the supervision signal, and detail a method that allows one to scale up and introduce previously inviable augmentations to boost performance. Finally, I will show how one can scalably expand the number of modalities supported by multimodal models and demonstrate their use in a number of downstream semantic tasks.", "bio": "", "area": "", "date past": "", "key": "AlexWong", "prettyDate": "October 24"}, {"semester": "Fall", "year": "2024", "date": "2024-10-17", "speaker": "Agustinus Kristiadi", "website": "https://agustinus.kristia.de/", "title": "Probabilistic Inference and Decision-Making With and For Foundation Models", "affiliation": "Vector Institute", "sponsor": "", "video": "https://www.youtube.com/watch?v=ZxUBIVvSP6U", "abstract": "apturing our belief about an unknown given observations. Central in this paradigm are probabilistic models and approximate inference methods. The former models one\u2019s prior belief and encodes the data, while the latter produces posterior distributions based on the former. In the era of large-scale neural networks and foundation models, leveraging them in probabilistic modeling or improving them using probabilistic inference is challenging due to their sheer size. In this talk, I will discuss recent works in (i) developing efficient probabilistic models with and for large foundation models, (ii) leveraging the resulting powerful, calibrated beliefs to improve decision-making and planning, and (iii) applying the resulting probabilistic decision-making/planning systems for improving scientific discovery, and improving the neural networks themselves.", "bio": "", "area": "", "date past": "", "key": "AgustinusKristiadi", "prettyDate": "October 17"}, {"semester": "Fall", "year": "2024", "date": "2024-10-10", "speaker": "Xiaolong Wang", "website": "https://xiaolonw.github.io/", "title": "Learning Humanoid Robots", "affiliation": "UCSD", "sponsor": "", "video": "https://www.youtube.com/watch?v=lBgdDY1VBkY", "abstract": "Having a humanoid robot operating like a human has been a long-standing goal in robotics. The humanoid robot provides a generalized purpose platform to conduct diverse tasks we do in our daily lives. In this talk, we study learning-based approaches for both the mobility and manipulation skills of the humanoid robot, with the goal of generalization to diverse tasks, objects, and scenes. I will discuss how to perform whole-body control in humanoids with rich, diverse, and expressive motions. I will also share some lessons we learned from developing teleoperation systems to operate humanoid robots and collect training data. With the collected data, we aim to build the robot foundation model using a novel RNN architecture with Test-Time Training (TTT).", "bio": "", "area": "", "date past": "", "key": "XiaolongWang", "prettyDate": "October 10"}, {"semester": "Fall", "year": "2024", "date": "2024-10-03", "speaker": "Silvia Sell\u00e1n", "website": "https://www.silviasellan.com/", "title": "Stochastic Computer Graphics", "affiliation": "MIT", "sponsor": "", "video": "https://www.youtube.com/watch?v=ZhC11_xA7BQ", "abstract": "Computer Graphics research has long been dominated by the interests of large film, television and social media companies, forcing other, more safety-critical applications (e.g., medicine, engineering, security) to repurpose Graphics algorithms originally designed for entertainment. In this talk, I will advocate for a perspective shift in our field that allows us to design algorithms directly for these safety-critical application realms. I will show that this begins by reinterpreting traditional Graphics tasks (e.g., 3D modeling and reconstruction) from a statistical lens and quantifying the uncertainty in our algorithmic outputs, as exemplified by the research I have conducted for the past five years. I will end by mentioning several ongoing and future research directions that carry this statistical lens to entirely new problems in Graphics and Vision and into specific applications.", "bio": "", "area": "", "date past": "", "key": "SilviaSell\u00e1n", "prettyDate": "October 03"}, {"semester": "Fall", "year": "2024", "date": "2024-09-26", "speaker": "Xinya Du", "website": "https://xinyadu.github.io/", "title": "Synergizing Knowledge and  Large Language Models", "affiliation": "UT Dallas", "sponsor": "", "video": "", "abstract": "Large Language Models (LLMs) have revolutionized the field of natural language processing and reshaped how humans acquire and interact with knowledge. In this talk, I will discuss my research on synergizing LMs and knowledge \u2014 where LLMs not only extract and discover knowledge, but also continually improve by integrating new knowledge. First, I will cover our work on improving knowledge extraction from the vast amount of existing literature, with a particular focus on enabling models to better understand long documents in a cost-efficient and comprehensive manner. I will describe a novel paradigm for representing document-level structured information as question answer pairs, and how we extract them by leveraging global context. Next, I will introduce our pioneering investigation into using LLMs for new scientific knowledge discovery. We explore a multi-stage, LLM-based framework to generate and iteratively refine natural language scientific hypotheses. Finally, building on the above efforts, I will complete the virtuous cycle by demonstrating how LLMs can integrate the knowledge they acquire to continuously enhance their reasoning capabilities and their ability to learn new knowledge.", "bio": "", "area": "", "date past": "", "key": "XinyaDu", "prettyDate": "September 26"}, {"semester": "Fall", "year": "2024", "date": "2024-09-12", "speaker": "Yixin Wang", "website": "https://yixinwang.github.io/", "title": "Causal Inference with Unstructured Data", "affiliation": "University of Michigan", "sponsor": "", "video": "", "abstract": "Causal inference traditionally involves analyzing tabular data where variables like treatment, outcome, covariates, and colliders are manually labeled by humans. However, many complex causal inference problems rely on unstructured data sources such as images, text and videos that depict overall situations. These causal problems require a crucial first step - extracting the high-level latent causal factors from the low-level unstructured data inputs, a task known as \"causal representation learning\". In this talk, we explore how to identify latent causal factors from unstructured data, whether from passive observations, interventional experiments, or multi-domain datasets. While latent factors are classically uncovered by leveraging their statistical independence, causal representation learning grapples with a thornier challenge: the latent causal factors are often correlated, causally connected, or arbitrarily dependent.", "bio": "", "area": "", "date past": "", "key": "YixinWang", "prettyDate": "September 12"}]}