---
layout: post
title: "Dimitris Tsipras -- Opening the black box of deep learning models by digging into their successes and failures"
---

{% include youtubePlayer.html yturl="https://youtu.be/0iNb3b9Kr0c" %}

## Bio

Dimitris Tsipras is a postdoctoral scholar at Stanford University, advised by Percy Liang and Greg Valiant. He obtained his PhD from MIT, advised by Aleksander Madry. His research is aimed towards understanding and improving the modern machine learning toolkit, focusing on topics such as reliability, benchmarks, and interpretability. 

## Abstract

Modern machine learning is powered by a simple recipe: train large models on vast datasets. But while these models can be potent, a lot remains to be understood about how they actually work. In this talk, I will demonstrate how probing some of the striking successes and failures of these models can allow us to peek inside the black box. First, I will look at the phenomenon of adversarial examples—highly accurate models are severely brittle to imperceptible perturbations. I will discuss findings that shed light into the origins of this phenomenon and their implications for learning in general. Then, I will focus on the emergent capability of in-context learning—large language models are able to adapt to new tasks on-the-fly, by conditioning on a few input-output examples. I will present a methodology that allows us to rigorously study this capability and probe its limits. Overall, these explorations exemplify how we can understand a lot about the inner workings of these models by dissecting their behavior outside typical conditions.
